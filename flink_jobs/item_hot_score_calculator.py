"""
Flink Job 2: ç‰©å“çƒ­åº¦å®æ—¶è®¡ç®—ï¼ˆé…ç½®é©±åŠ¨ç‰ˆï¼‰
åŠŸèƒ½ï¼šä»Kafkaæ¶ˆè´¹ç”¨æˆ·è¡Œä¸ºæ•°æ®ï¼Œå®æ—¶è®¡ç®—ç‰©å“çƒ­åº¦ï¼Œå†™å…¥Redis
ç‰¹æ€§ï¼šæ ¹æ® MongoDB Scenario é…ç½®åŠ¨æ€åº”ç”¨è®¡ç®—å‚æ•°
"""
import json
import sys
import os
import math
import threading
import time
from datetime import datetime, timedelta
from collections import defaultdict
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

try:
    from pyflink.datastream import StreamExecutionEnvironment
    from pyflink.datastream.window import SlidingProcessingTimeWindows
    from pyflink.common import Time, WatermarkStrategy
    from pyflink.datastream.functions import ProcessWindowFunction
    from pyflink.datastream.connectors.kafka import KafkaSource, KafkaOffsetsInitializer
    from pyflink.common.serialization import SimpleStringSchema
    PYFLINK_AVAILABLE = True
except ImportError:
    PYFLINK_AVAILABLE = False
    print("âš ï¸  PyFlinkæœªå®‰è£…ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")

# å¯¼å…¥é…ç½®åŠ è½½å™¨
try:
    from app.services.realtime.config_loader import RealtimeConfigLoader
except ImportError:
    print("âš ï¸  æ— æ³•å¯¼å…¥ RealtimeConfigLoaderï¼Œè¯·æ£€æŸ¥é¡¹ç›®è·¯å¾„")
    RealtimeConfigLoader = None


class HotScoreCalculator(ProcessWindowFunction):
    """ç‰©å“çƒ­åº¦è®¡ç®—å‡½æ•°ï¼ˆé…ç½®é©±åŠ¨ç‰ˆï¼‰"""
    
    def __init__(self, config_loader):
        """
        Args:
            config_loader: RealtimeConfigLoader å®ä¾‹ï¼Œç”¨äºåŠ¨æ€è·å–é…ç½®
        """
        self.config_loader = config_loader
    
    def process(self, key, context, elements):
        """
        è®¡ç®—çª—å£å†…ç‰©å“çš„çƒ­åº¦åˆ†æ•°
        
        Args:
            key: (tenant_id, scenario_id, item_id)
            context: çª—å£ä¸Šä¸‹æ–‡
            elements: çª—å£å†…çš„æ‰€æœ‰è¡Œä¸º
        """
        tenant_id, scenario_id, item_id = key
        
        # ğŸ”¥ åŠ¨æ€è·å–é…ç½®ï¼ˆæ ¹æ®ç§Ÿæˆ·å’Œåœºæ™¯ï¼‰
        action_weights = self.config_loader.get_action_weights(tenant_id, scenario_id)
        decay_lambda = self.config_loader.get_decay_lambda(tenant_id, scenario_id)
        
        # ç»Ÿè®¡å„ç±»è¡Œä¸ºæ•°é‡
        action_counts = defaultdict(int)
        total_duration = 0
        user_set = set()
        
        for behavior in elements:
            action_type = behavior.get('action_type')
            action_counts[action_type] += 1
            
            # ç»Ÿè®¡ç”¨æˆ·æ•°ï¼ˆå»é‡ï¼‰
            user_set.add(behavior.get('user_id'))
            
            # ç»Ÿè®¡è§‚çœ‹æ—¶é•¿
            extra = behavior.get('extra', {})
            if 'duration' in extra:
                try:
                    total_duration += float(extra['duration'])
                except:
                    pass
        
        # è®¡ç®—åŸºç¡€çƒ­åº¦åˆ†æ•°ï¼ˆä½¿ç”¨åŠ¨æ€é…ç½®ï¼‰
        base_score = 0
        for action_type, count in action_counts.items():
            weight = action_weights.get(action_type, 1.0)
            base_score += count * weight
        
        # æ—¶é—´è¡°å‡ï¼ˆåŸºäºçª—å£ç»“æŸæ—¶é—´ï¼Œä½¿ç”¨åŠ¨æ€é…ç½®ï¼‰
        now = datetime.now()
        window_end = datetime.fromtimestamp(context.window().end / 1000)
        days_ago = (now - window_end).days
        decay_factor = math.exp(-decay_lambda * days_ago)
        
        # æœ€ç»ˆçƒ­åº¦åˆ†æ•°
        hot_score = base_score * decay_factor
        
        # æ„é€ ç»“æœ
        result = {
            'tenant_id': tenant_id,
            'scenario_id': scenario_id,
            'item_id': item_id,
            'hot_score': round(hot_score, 2),
            'stats': {
                'view_count': action_counts.get('view', 0),
                'click_count': action_counts.get('click', 0),
                'like_count': action_counts.get('like', 0),
                'share_count': action_counts.get('share', 0),
                'unique_users': len(user_set),
                'avg_duration': round(total_duration / len(list(elements)), 2) if elements else 0
            },
            'window_start': context.window().start,
            'window_end': context.window().end,
            'calculated_at': datetime.utcnow().isoformat()
        }
        
        yield json.dumps(result, ensure_ascii=False)


class ItemHotScoreCalculator:
    """ç‰©å“çƒ­åº¦å®æ—¶è®¡ç®—ï¼ˆé…ç½®é©±åŠ¨ç‰ˆï¼‰"""
    
    def __init__(
        self,
        kafka_servers: str = "localhost:9092",
        redis_url: str = "redis://:redis_password@localhost:6379/0",
        mongodb_url: str = "mongodb://localhost:27017/",
        mongodb_database: str = "lemo_recommender"
    ):
        self.kafka_servers = kafka_servers
        self.redis_url = redis_url
        self.mongodb_url = mongodb_url
        self.mongodb_database = mongodb_database
        
        # é…ç½®åŠ è½½å™¨
        if RealtimeConfigLoader:
            self.config_loader = RealtimeConfigLoader(mongodb_url, mongodb_database)
            print(f"âœ… é…ç½®åŠ è½½å™¨å·²åˆå§‹åŒ–")
            
            # åŠ è½½é…ç½®
            self.config_loader.load_configs()
            
            # å¯åŠ¨é…ç½®åˆ·æ–°çº¿ç¨‹
            self._start_config_refresh_thread()
        else:
            print("âš ï¸  RealtimeConfigLoader ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨é»˜è®¤é…ç½®")
            self.config_loader = None
    
    def _start_config_refresh_thread(self):
        """å¯åŠ¨é…ç½®åˆ·æ–°çº¿ç¨‹ï¼ˆæ¯5åˆ†é’Ÿåˆ·æ–°ä¸€æ¬¡ï¼‰"""
        def refresh():
            while True:
                try:
                    time.sleep(300)  # 5åˆ†é’Ÿ
                    self.config_loader.load_configs()
                    print("ğŸ”„ é…ç½®å·²åˆ·æ–°")
                except Exception as e:
                    print(f"âš ï¸  é…ç½®åˆ·æ–°å¤±è´¥: {e}")
        
        thread = threading.Thread(target=refresh, daemon=True)
        thread.start()
        print("âœ… é…ç½®åˆ·æ–°çº¿ç¨‹å·²å¯åŠ¨ï¼ˆæ¯5åˆ†é’Ÿï¼‰")
    
    def run(self):
        """è¿è¡ŒFlinkä½œä¸š"""
        
        if not PYFLINK_AVAILABLE:
            print("=" * 70)
            print("  Flink Job: ç‰©å“çƒ­åº¦å®æ—¶è®¡ç®—ï¼ˆé…ç½®é©±åŠ¨ç‰ˆï¼‰ - æ¨¡æ‹Ÿæ¨¡å¼")
            print("=" * 70)
            print()
            print("ğŸ“Š ä½œä¸šé…ç½®:")
            print(f"  - Kafka: {self.kafka_servers}")
            print(f"  - Redis: {self.redis_url}")
            print(f"  - MongoDB: {self.mongodb_url}")
            print(f"  - Database: {self.mongodb_database}")
            if self.config_loader:
                print(f"  - å·²åŠ è½½åœºæ™¯æ•°: {len(self.config_loader.configs)}")
                self.config_loader.print_summary()
            print()
            print("âš ï¸  è¯·å®‰è£…PyFlink:")
            print("  pip install apache-flink")
            print()
            return
        
        print("=" * 70)
        print("  Flink Job: ç‰©å“çƒ­åº¦å®æ—¶è®¡ç®—ï¼ˆé…ç½®é©±åŠ¨ç‰ˆï¼‰")
        print("=" * 70)
        
        # æ‰“å°é…ç½®æ‘˜è¦
        if self.config_loader:
            self.config_loader.print_summary()
        
        # 1. åˆ›å»ºæ‰§è¡Œç¯å¢ƒ
        env = StreamExecutionEnvironment.get_execution_environment()
        env.set_parallelism(4)
        
        # 2. ä»Kafkaè¯»å–ç”¨æˆ·è¡Œä¸ºæ•°æ®
        kafka_source = KafkaSource.builder() \
            .set_bootstrap_servers(self.kafka_servers) \
            .set_topics("user-behaviors-.*") \
            .set_group_id("item-hot-score-calculator") \
            .set_starting_offsets(KafkaOffsetsInitializer.latest()) \
            .set_value_only_deserializer(SimpleStringSchema()) \
            .build()
        
        behaviors = env.from_source(
            kafka_source,
            WatermarkStrategy.no_watermarks(),
            "Kafka User Behaviors Source"
        )
        
        # 3. è§£æJSON
        parsed_behaviors = behaviors.map(
            lambda x: json.loads(x),
            output_type=dict
        )
        
        # 4. æŒ‰ç‰©å“åˆ†ç»„ï¼Œæ»‘åŠ¨çª—å£èšåˆï¼ˆä½¿ç”¨é…ç½®é©±åŠ¨çš„è®¡ç®—å™¨ï¼‰
        hot_scores = (
            parsed_behaviors
            .key_by(lambda x: (x['tenant_id'], x['scenario_id'], x['item_id']))
            .window(SlidingProcessingTimeWindows.of(
                Time.hours(1),      # çª—å£å¤§å°: 1å°æ—¶ï¼ˆå¯é€šè¿‡é…ç½®è°ƒæ•´ï¼‰
                Time.minutes(15)    # æ»‘åŠ¨æ­¥é•¿: 15åˆ†é’Ÿï¼ˆå¯é€šè¿‡é…ç½®è°ƒæ•´ï¼‰
            ))
            .process(HotScoreCalculator(self.config_loader))
        )
        
        # 5. å†™å…¥Redis ZSET
        def write_to_redis(score_json):
            """å†™å…¥Redisçš„å‡½æ•°"""
            try:
                import redis
                score_data = json.loads(score_json)
                
                r = redis.from_url(self.redis_url)
                
                # ZSET key: hot:items:{tenant_id}:{scenario_id}
                redis_key = f"hot:items:{score_data['tenant_id']}:{score_data['scenario_id']}"
                
                # æ·»åŠ åˆ°æœ‰åºé›†åˆ
                r.zadd(redis_key, {score_data['item_id']: score_data['hot_score']})
                
                # åªä¿ç•™Top 1000
                r.zremrangebyrank(redis_key, 0, -1001)
                
                # è®¾ç½®è¿‡æœŸæ—¶é—´ï¼ˆ2å°æ—¶ï¼‰
                r.expire(redis_key, 7200)
                
                print(f"[Redis] æ›´æ–°ç‰©å“çƒ­åº¦: {score_data['item_id']} = {score_data['hot_score']}")
                
            except Exception as e:
                print(f"[Redis] å†™å…¥å¤±è´¥: {e}")
        
        hot_scores.map(write_to_redis)
        
        # 6. æ‰“å°åˆ°æ§åˆ¶å°ï¼ˆè°ƒè¯•ç”¨ï¼‰
        hot_scores.print()
        
        # 7. æ‰§è¡Œä½œä¸š
        print("\nğŸš€ å¯åŠ¨Flinkä½œä¸š...")
        env.execute("Item Hot Score Real-time Calculator")


def main():
    """ä¸»å‡½æ•°"""
    kafka_servers = os.getenv('KAFKA_BOOTSTRAP_SERVERS', 'localhost:9092')
    redis_url = os.getenv('REDIS_URL', 'redis://:redis_password@localhost:6379/0')
    mongodb_url = os.getenv('MONGODB_URL', 'mongodb://localhost:27017/')
    mongodb_database = os.getenv('MONGODB_DATABASE', 'lemo_recommender')
    
    print("=" * 70)
    print("å¯åŠ¨å‚æ•°:")
    print(f"  - Kafka: {kafka_servers}")
    print(f"  - Redis: {redis_url}")
    print(f"  - MongoDB: {mongodb_url}")
    print(f"  - Database: {mongodb_database}")
    print("=" * 70)
    
    calculator = ItemHotScoreCalculator(
        kafka_servers=kafka_servers,
        redis_url=redis_url,
        mongodb_url=mongodb_url,
        mongodb_database=mongodb_database
    )
    
    try:
        calculator.run()
    except KeyboardInterrupt:
        print("\n\næ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œåœæ­¢ä½œä¸š...")
    except Exception as e:
        print(f"\n\nâŒ ä½œä¸šå¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
