"""
Flink Job 2: ç‰©å“çƒ­åº¦å®æ—¶è®¡ç®—
åŠŸèƒ½ï¼šä»Kafkaæ¶ˆè´¹ç”¨æˆ·è¡Œä¸ºæ•°æ®ï¼Œå®æ—¶è®¡ç®—ç‰©å“çƒ­åº¦ï¼Œå†™å…¥Redis
"""
from typing import Dict, Any
from datetime import datetime, timedelta
import math


class ItemHotScoreCalculator:
    """
    ç‰©å“çƒ­åº¦å®æ—¶è®¡ç®—
    
    æ•°æ®æµ:
    Kafka (user-behaviors) â†’ Flinkæ»‘åŠ¨çª—å£èšåˆ â†’ Redis ZSET
    
    çª—å£: 1å°æ—¶æ»‘åŠ¨çª—å£ï¼Œæ»‘åŠ¨æ­¥é•¿15åˆ†é’Ÿ
    åˆ†ç»„: tenant_id + scenario_id + item_id
    
    çƒ­åº¦ç®—æ³•:
    hot_score = (æµè§ˆé‡ * 1 + ç‚¹å‡»é‡ * 2 + ç‚¹èµé‡ * 3 + åˆ†äº«é‡ * 5) * æ—¶é—´è¡°å‡ç³»æ•°
    æ—¶é—´è¡°å‡: decay = exp(-Î» * å¤©æ•°), Î» = 0.1
    """
    
    def __init__(self, kafka_servers: str, redis_url: str):
        self.kafka_servers = kafka_servers
        self.redis_url = redis_url
        
        # è¡Œä¸ºæƒé‡
        self.action_weights = {
            'impression': 0.5,
            'view': 1.0,
            'click': 2.0,
            'like': 3.0,
            'favorite': 4.0,
            'share': 5.0,
            'comment': 4.0
        }
        
        # æ—¶é—´è¡°å‡ç³»æ•°
        self.decay_lambda = 0.1
    
    def run(self):
        """
        è¿è¡ŒFlinkä½œä¸š
        
        ä¼ªä»£ç å®ç°ï¼ˆä½¿ç”¨PyFlink APIï¼‰:
        
        ```python
        from pyflink.datastream import StreamExecutionEnvironment
        from pyflink.datastream.window import SlidingProcessingTimeWindows
        from pyflink.common import Time
        
        # 1. åˆ›å»ºæ‰§è¡Œç¯å¢ƒ
        env = StreamExecutionEnvironment.get_execution_environment()
        
        # 2. ä»Kafkaè¯»å–
        behaviors = env.add_source(
            FlinkKafkaConsumer(
                topics=['user-behaviors-*'],
                deserialization_schema=JsonDeserializationSchema(),
                properties={
                    'bootstrap.servers': self.kafka_servers,
                    'group.id': 'item-hot-score-calculator'
                }
            )
        )
        
        # 3. æŒ‰ç‰©å“åˆ†ç»„ï¼Œæ»‘åŠ¨çª—å£èšåˆ
        hot_scores = (
            behaviors
            .key_by(lambda x: (x['tenant_id'], x['scenario_id'], x['item_id']))
            .window(
                SlidingProcessingTimeWindows.of(
                    Time.hours(1),      # çª—å£å¤§å°
                    Time.minutes(15)    # æ»‘åŠ¨æ­¥é•¿
                )
            )
            .aggregate(HotScoreAggregateFunction(self.action_weights, self.decay_lambda))
        )
        
        # 4. å†™å…¥Redis ZSET
        hot_scores.add_sink(
            RedisZSetSink(
                connection_string=self.redis_url,
                key_template='hot:items:{tenant_id}:{scenario_id}',
                score_field='hot_score',
                member_field='item_id',
                max_size=1000  # åªä¿ç•™Top 1000
            )
        )
        
        # 5. å‘é€åˆ°ä¸‹æ¸¸Topic
        hot_scores.add_sink(
            FlinkKafkaProducer(
                topic='item-stats-updates',
                serialization_schema=JsonSerializationSchema()
            )
        )
        
        # 6. æ‰§è¡Œä½œä¸š
        env.execute("Item Hot Score Real-time Calculator")
        ```
        """
        print("=" * 60)
        print("  Flink Job: ç‰©å“çƒ­åº¦å®æ—¶è®¡ç®—")
        print("=" * 60)
        print()
        print("ğŸ“Š ä½œä¸šé…ç½®:")
        print(f"  - Kafka: {self.kafka_servers}")
        print(f"  - çª—å£: 1å°æ—¶æ»‘åŠ¨çª—å£ï¼ˆæ­¥é•¿15åˆ†é’Ÿï¼‰")
        print(f"  - è¾“å‡º: Redis ZSET + Kafka")
        print()
        print("ğŸ”¥ çƒ­åº¦ç®—æ³•:")
        print("  hot_score = Î£(è¡Œä¸ºæƒé‡) Ã— æ—¶é—´è¡°å‡")
        print(f"  - è¡Œä¸ºæƒé‡: {self.action_weights}")
        print(f"  - æ—¶é—´è¡°å‡: exp(-{self.decay_lambda} Ã— å¤©æ•°)")
        print()
        print("ğŸ’¡ å¾…å®ç°åŠŸèƒ½:")
        print("  1. ä»Kafkaæ¶ˆè´¹ç”¨æˆ·è¡Œä¸º")
        print("  2. æŒ‰(tenant_id, scenario_id, item_id)åˆ†ç»„")
        print("  3. 1å°æ—¶æ»‘åŠ¨çª—å£èšåˆ:")
        print("     - ç»Ÿè®¡å„ç±»è¡Œä¸ºæ•°é‡")
        print("     - è®¡ç®—åŠ æƒçƒ­åº¦åˆ†æ•°")
        print("     - åº”ç”¨æ—¶é—´è¡°å‡")
        print("  4. å†™å…¥Redis ZSET (hot:items:{tenant_id}:{scenario_id})")
        print("  5. åªä¿ç•™Top 1000çƒ­é—¨ç‰©å“")
        print("  6. å‘é€åˆ°item-stats-updates Topic")
        print()
        print("ğŸš€ å¯åŠ¨å‘½ä»¤:")
        print("  python flink_jobs/item_hot_score_calculator.py")
        print()


class HotScoreAggregateFunction:
    """ç‰©å“çƒ­åº¦èšåˆå‡½æ•°"""
    
    def __init__(self, action_weights: Dict[str, float], decay_lambda: float):
        self.action_weights = action_weights
        self.decay_lambda = decay_lambda
    
    def aggregate(self, behaviors: list[Dict[str, Any]]) -> Dict[str, Any]:
        """
        èšåˆè®¡ç®—ç‰©å“çƒ­åº¦
        
        Args:
            behaviors: çª—å£å†…çš„è¡Œä¸ºåˆ—è¡¨
            
        Returns:
            ç‰©å“çƒ­åº¦æ•°æ®
        """
        if not behaviors:
            return {}
        
        # åŸºæœ¬ä¿¡æ¯
        first_behavior = behaviors[0]
        tenant_id = first_behavior['tenant_id']
        scenario_id = first_behavior['scenario_id']
        item_id = first_behavior['item_id']
        
        # ç»Ÿè®¡å„ç±»è¡Œä¸º
        action_counts = {}
        for behavior in behaviors:
            action_type = behavior['action_type']
            action_counts[action_type] = action_counts.get(action_type, 0) + 1
        
        # è®¡ç®—åŠ æƒåˆ†æ•°
        weighted_score = sum(
            action_counts.get(action, 0) * weight
            for action, weight in self.action_weights.items()
        )
        
        # æ—¶é—´è¡°å‡ï¼ˆå‡è®¾ç‰©å“æœ€æ–°è¡Œä¸ºæ—¶é—´ï¼‰
        latest_timestamp = max(
            datetime.fromisoformat(b['timestamp'])
            for b in behaviors
        )
        age_days = (datetime.utcnow() - latest_timestamp).total_seconds() / 86400
        decay_factor = math.exp(-self.decay_lambda * age_days)
        
        # æœ€ç»ˆçƒ­åº¦åˆ†æ•°
        hot_score = weighted_score * decay_factor
        
        return {
            'tenant_id': tenant_id,
            'scenario_id': scenario_id,
            'item_id': item_id,
            'hot_score': round(hot_score, 2),
            'action_counts': action_counts,
            'window_end': datetime.utcnow().isoformat()
        }


if __name__ == '__main__':
    # é…ç½®
    kafka_servers = 'localhost:9092'
    redis_url = 'redis://:redis_password_2024@localhost:6379/0'
    
    # è¿è¡Œä½œä¸š
    calculator = ItemHotScoreCalculator(kafka_servers, redis_url)
    calculator.run()

