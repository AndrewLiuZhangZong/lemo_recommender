"""
ç®€å•çš„ Flink æµ‹è¯•ä½œä¸š
ç”¨äºéªŒè¯ PyFlink ç¯å¢ƒå’Œ JAR åŠ è½½æ˜¯å¦æ­£å¸¸
ä¸ä¾èµ– Kafka
"""
import os
from pyflink.datastream import StreamExecutionEnvironment
from pyflink.common import Types

def main():
    """æµ‹è¯• PyFlink åŸºç¡€åŠŸèƒ½"""
    print("=" * 60)
    print("ğŸ§ª Flink ç®€å•æµ‹è¯•ä½œä¸š")
    print("=" * 60)
    
    # æ£€æŸ¥ JAR æ–‡ä»¶
    import glob
    jar_files_usrlib = glob.glob("/opt/flink/usrlib/*.jar")
    jar_files_tmp = glob.glob("/tmp/flink-jars/*.jar")
    all_jars = jar_files_usrlib + jar_files_tmp
    
    if all_jars:
        print(f"âœ“ å‘ç° {len(all_jars)} ä¸ª JAR æ–‡ä»¶:")
        for jar in all_jars:
            print(f"  - {jar}")
    else:
        print("âš ï¸  æœªå‘ç°ä»»ä½• JAR æ–‡ä»¶")
    
    # åˆ›å»ºæ‰§è¡Œç¯å¢ƒ
    print("\nåˆ›å»º Flink æ‰§è¡Œç¯å¢ƒ...")
    env = StreamExecutionEnvironment.get_execution_environment()
    env.set_parallelism(1)
    
    # æ³¨æ„ï¼šä¸éœ€è¦æ˜¾å¼è°ƒç”¨ add_jars()
    # Flink ä¼šè‡ªåŠ¨åŠ è½½ /opt/flink/usrlib/ ç›®å½•çš„ JAR
    print(f"\nâœ“ Flink ä¼šè‡ªåŠ¨åŠ è½½ usrlib ç›®å½•çš„ {len([j for j in all_jars if 'usrlib' in j])} ä¸ª JAR")
    
    # åˆ›å»ºä¸€ä¸ªç®€å•çš„æ•°æ®æµ
    print("\nåˆ›å»ºæ•°æ®æµ...")
    data_stream = env.from_collection(
        collection=[
            (1, 'Hello'),
            (2, 'World'),
            (3, 'Flink'),
            (4, 'Test'),
        ],
        type_info=Types.TUPLE([Types.INT(), Types.STRING()])
    )
    
    # ç®€å•çš„mapæ“ä½œ
    result_stream = data_stream.map(
        lambda x: f"ID={x[0]}, Value={x[1]}",
        output_type=Types.STRING()
    )
    
    # æ‰“å°ç»“æœ
    result_stream.print()
    
    # æ‰§è¡Œä½œä¸š
    print("\næ‰§è¡Œä½œä¸š...")
    print("=" * 60)
    env.execute("Simple Test Job")
    
    print("\nâœ“ ä½œä¸šæ‰§è¡ŒæˆåŠŸï¼")
    print("=" * 60)

if __name__ == '__main__':
    main()

