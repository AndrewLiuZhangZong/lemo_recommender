"""
Flink Job 1: ç”¨æˆ·ç”»åƒå®æ—¶æ›´æ–°
åŠŸèƒ½ï¼šä»Kafkaæ¶ˆè´¹ç”¨æˆ·è¡Œä¸ºæ•°æ®ï¼Œå®æ—¶èšåˆè®¡ç®—ç”¨æˆ·ç”»åƒï¼Œå†™å…¥MongoDBå’ŒRedis
"""
from typing import Dict, Any
from datetime import datetime


class UserProfileUpdater:
    """
    ç”¨æˆ·ç”»åƒå®æ—¶æ›´æ–°
    
    æ•°æ®æµ:
    Kafka (user-behaviors) â†’ Flinkçª—å£èšåˆ â†’ MongoDB/Redis
    
    çª—å£: 5åˆ†é’Ÿæ»šåŠ¨çª—å£
    åˆ†ç»„: tenant_id + user_id + scenario_id
    """
    
    def __init__(self, kafka_servers: str, mongodb_url: str, redis_url: str):
        self.kafka_servers = kafka_servers
        self.mongodb_url = mongodb_url
        self.redis_url = redis_url
    
    def run(self):
        """
        è¿è¡ŒFlinkä½œä¸š
        
        ä¼ªä»£ç å®ç°ï¼ˆä½¿ç”¨PyFlink APIï¼‰:
        
        ```python
        from pyflink.datastream import StreamExecutionEnvironment
        from pyflink.datastream.window import TumblingProcessingTimeWindows
        from pyflink.common import Time
        
        # 1. åˆ›å»ºæ‰§è¡Œç¯å¢ƒ
        env = StreamExecutionEnvironment.get_execution_environment()
        env.set_parallelism(4)
        
        # 2. ä»Kafkaè¯»å–ç”¨æˆ·è¡Œä¸ºæ•°æ®
        behaviors = env.add_source(
            FlinkKafkaConsumer(
                topics=['user-behaviors-*'],  # è®¢é˜…æ‰€æœ‰ç§Ÿæˆ·çš„è¡Œä¸ºtopic
                deserialization_schema=JsonDeserializationSchema(),
                properties={
                    'bootstrap.servers': self.kafka_servers,
                    'group.id': 'user-profile-updater'
                }
            )
        )
        
        # 3. æŒ‰ç”¨æˆ·åˆ†ç»„å¹¶çª—å£èšåˆ
        user_profiles = (
            behaviors
            .key_by(lambda x: (x['tenant_id'], x['user_id'], x['scenario_id']))
            .window(TumblingProcessingTimeWindows.of(Time.minutes(5)))
            .aggregate(UserProfileAggregateFunction())
        )
        
        # 4. å†™å…¥MongoDB
        user_profiles.add_sink(
            MongoDBSink(
                connection_string=self.mongodb_url,
                database='lemo_recommender',
                collection='user_profiles'
            )
        )
        
        # 5. å†™å…¥Redisï¼ˆç¼“å­˜ï¼‰
        user_profiles.add_sink(
            RedisSink(
                connection_string=self.redis_url,
                key_template='user:profile:{tenant_id}:{user_id}:{scenario_id}',
                ttl=3600
            )
        )
        
        # 6. å‘é€åˆ°ä¸‹æ¸¸Topic
        user_profiles.add_sink(
            FlinkKafkaProducer(
                topic='user-profile-updates',
                serialization_schema=JsonSerializationSchema()
            )
        )
        
        # 7. æ‰§è¡Œä½œä¸š
        env.execute("User Profile Real-time Updater")
        ```
        """
        print("=" * 60)
        print("  Flink Job: ç”¨æˆ·ç”»åƒå®æ—¶æ›´æ–°")
        print("=" * 60)
        print()
        print("ğŸ“Š ä½œä¸šé…ç½®:")
        print(f"  - Kafka: {self.kafka_servers}")
        print(f"  - çª—å£: 5åˆ†é’Ÿæ»šåŠ¨çª—å£")
        print(f"  - è¾“å‡º: MongoDB + Redis + Kafka")
        print()
        print("ğŸ’¡ å¾…å®ç°åŠŸèƒ½:")
        print("  1. ä»Kafkaæ¶ˆè´¹ç”¨æˆ·è¡Œä¸º")
        print("  2. æŒ‰(tenant_id, user_id, scenario_id)åˆ†ç»„")
        print("  3. 5åˆ†é’Ÿçª—å£èšåˆç»Ÿè®¡:")
        print("     - è§‚çœ‹æ¬¡æ•°ã€ç‚¹èµæ¬¡æ•°")
        print("     - åå¥½åˆ†ç±»ç»Ÿè®¡")
        print("     - æ´»è·ƒæ—¶æ®µåˆ†æ")
        print("  4. å†™å…¥MongoDB user_profilesé›†åˆ")
        print("  5. å†™å…¥Redisç¼“å­˜")
        print("  6. å‘é€åˆ°user-profile-updates Topic")
        print()
        print("ğŸš€ å¯åŠ¨å‘½ä»¤:")
        print("  python flink_jobs/user_profile_updater.py")
        print()


class UserProfileAggregateFunction:
    """
    ç”¨æˆ·ç”»åƒèšåˆå‡½æ•°
    
    è¾“å…¥: ç”¨æˆ·è¡Œä¸ºæµ
    è¾“å‡º: ç”¨æˆ·ç”»åƒæ›´æ–°
    """
    
    @staticmethod
    def aggregate(behaviors: list[Dict[str, Any]]) -> Dict[str, Any]:
        """
        èšåˆç”¨æˆ·è¡Œä¸ºï¼Œè®¡ç®—ç”»åƒç‰¹å¾
        
        Args:
            behaviors: çª—å£å†…çš„ç”¨æˆ·è¡Œä¸ºåˆ—è¡¨
            
        Returns:
            ç”¨æˆ·ç”»åƒæ›´æ–°æ•°æ®
        """
        if not behaviors:
            return {}
        
        # åŸºæœ¬ä¿¡æ¯
        first_behavior = behaviors[0]
        tenant_id = first_behavior['tenant_id']
        user_id = first_behavior['user_id']
        scenario_id = first_behavior['scenario_id']
        
        # ç»Ÿè®¡ç‰¹å¾
        features = {
            'total_actions': len(behaviors),
            'action_types': {},
            'categories': {},
            'active_time_slots': {}
        }
        
        for behavior in behaviors:
            # è¡Œä¸ºç±»å‹ç»Ÿè®¡
            action_type = behavior['action_type']
            features['action_types'][action_type] = \
                features['action_types'].get(action_type, 0) + 1
            
            # åˆ†ç±»åå¥½ï¼ˆä»item metadataè·å–ï¼‰
            category = behavior.get('extra', {}).get('category')
            if category:
                features['categories'][category] = \
                    features['categories'].get(category, 0) + 1
            
            # æ´»è·ƒæ—¶æ®µ
            timestamp = datetime.fromisoformat(behavior['timestamp'])
            hour = timestamp.hour
            time_slot = 'morning' if 6 <= hour < 12 else \
                       'afternoon' if 12 <= hour < 18 else \
                       'evening' if 18 <= hour < 24 else 'night'
            features['active_time_slots'][time_slot] = \
                features['active_time_slots'].get(time_slot, 0) + 1
        
        # è®¡ç®—åå¥½åˆ†æ•°
        total_categories = sum(features['categories'].values())
        preferences = {
            'category_scores': {
                cat: count / total_categories
                for cat, count in features['categories'].items()
            }
        }
        
        return {
            'tenant_id': tenant_id,
            'user_id': user_id,
            'scenario_id': scenario_id,
            'features': features,
            'preferences': preferences,
            'updated_at': datetime.utcnow().isoformat()
        }


if __name__ == '__main__':
    # é…ç½®
    kafka_servers = 'localhost:9092'
    mongodb_url = 'mongodb://admin:password@localhost:27017'
    redis_url = 'redis://:redis_password_2024@localhost:6379/0'
    
    # è¿è¡Œä½œä¸š
    updater = UserProfileUpdater(kafka_servers, mongodb_url, redis_url)
    updater.run()

