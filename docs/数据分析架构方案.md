# 数据分析架构完整方案 v2.0

## 问题背景

当前数据分析页面存在以下问题：
1. ❌ Python服务返回空数据（推荐次数、CTR、活跃用户等全为0）
2. ❌ 前端部分图表还在使用硬编码数据
3. ❌ 没有真实的用户行为数据收集系统

## 核心设计原则 ⭐

### 职责分离
- **MongoDB**: 仅存储业务配置数据（场景、物品、模型、实验）
- **ClickHouse**: 专门存储和分析所有行为数据
- **Redis**: 实时热数据缓存

### 数据流简化
```
行为数据流：前端 → behavior-service → Kafka → Flink → ClickHouse + Redis
                                                          ↓
                                               AnalyticsService查询
配置数据流：管理后台 → MongoDB → gRPC服务
```

## 架构设计

### 整体数据流

```
┌─────────────────────────────────────────────────────────────────┐
│                     1. 数据采集层                                 │
├─────────────────────────────────────────────────────────────────┤
│  前端埋点                                                         │
│  ├─ 推荐曝光（impression）                                       │
│  ├─ 推荐点击（click）                                            │
│  ├─ 物品详情查看（view）                                         │
│  ├─ 加购/收藏（action）                                          │
│  └─ 转化（conversion）                                           │
│                    ↓                                             │
│  behavior-service (FastAPI HTTP 8003)                           │
│  ├─ 接收行为事件                                                 │
│  ├─ 数据验证（tenant_id、user_id、item_id等）                   │
│  └─ 发送到 Kafka（不写MongoDB） ⭐                               │
└─────────────────────────────────────────────────────────────────┘
                     ↓
┌─────────────────────────────────────────────────────────────────┐
│                     2. 消息队列层                                 │
├─────────────────────────────────────────────────────────────────┤
│  Kafka Topics                                                    │
│  ├─ user-behaviors (分区：12-24，保留：7天)                     │
│  └─ recommendation-metrics (分区：6，保留：3天)                  │
└─────────────────────────────────────────────────────────────────┘
                     ↓
┌─────────────────────────────────────────────────────────────────┐
│                     3. 实时计算层                                 │
├─────────────────────────────────────────────────────────────────┤
│  Flink Jobs                                                      │
│  ├─ Job1: ClickHouseSink（批量写入）                            │
│  │  └─ Kafka → ClickHouse (user_behaviors表)                   │
│  │                                                               │
│  ├─ Job2: ItemHotScoreCalculator（实时热度）                    │
│  │  └─ Kafka → Redis ZSET (hot:items:*)                        │
│  │                                                               │
│  └─ Job3: RealtimeMetricsAggregator（实时指标）                 │
│     └─ Kafka → Redis HASH (metrics:realtime:*)                  │
└─────────────────────────────────────────────────────────────────┘
                     ↓
┌─────────────────────────────────────────────────────────────────┐
│                     4. 存储层                                     │
├─────────────────────────────────────────────────────────────────┤
│  ClickHouse (行为数据专用) ⭐                                     │
│  ├─ user_behaviors: 原始行为事件（90天）                         │
│  ├─ metrics_hourly: 每小时指标聚合（物化视图）                   │
│  ├─ item_stats_daily: 物品统计（物化视图）                       │
│  └─ experiment_metrics: 实验指标（物化视图）                     │
│                                                                  │
│  MongoDB (配置数据专用) ⭐                                        │
│  ├─ scenarios: 场景配置                                          │
│  ├─ items: 物品元数据                                            │
│  ├─ models: 模型配置                                             │
│  ├─ experiments: AB实验配置                                      │
│  └─ user_profiles: 用户画像（可选）                              │
│                                                                  │
│  Redis (实时缓存)                                                │
│  ├─ hot:items:{tenant}:{scenario} → ZSET                        │
│  ├─ metrics:realtime:{tenant}:{scenario} → HASH                 │
│  └─ user:recent:{user_id} → LIST (最近浏览)                     │
└─────────────────────────────────────────────────────────────────┘
                     ↓
┌─────────────────────────────────────────────────────────────────┐
│                     5. 查询层                                     │
├─────────────────────────────────────────────────────────────────┤
│  AnalyticsService (Python)                                      │
│  ├─ getDashboard()                                              │
│  │  ├─ ClickHouse查询：推荐次数、CTR、转化率、活跃用户          │
│  │  └─ MongoDB查询：物品数、场景数（配置数据）                  │
│  │                                                               │
│  ├─ getMetricsTrend()                                           │
│  │  └─ ClickHouse查询：时序数据（按小时/天聚合）                │
│  │                                                               │
│  ├─ getItemDistribution()                                       │
│  │  └─ ClickHouse查询：物品曝光/点击分组统计                    │
│  │                                                               │
│  └─ getUserBehaviorAnalysis()                                   │
│     └─ ClickHouse查询：用户行为漏斗、转化率                      │
└─────────────────────────────────────────────────────────────────┘
```

---

## ClickHouse表设计

### 1. 用户行为事件表

```sql
CREATE TABLE IF NOT EXISTS user_behaviors (
    event_id String,              -- 事件唯一ID
    tenant_id String,              -- 租户ID
    scenario_id String,            -- 场景ID
    user_id String,                -- 用户ID
    item_id String,                -- 物品ID
    action_type Enum8(            -- 行为类型
        'impression' = 1,
        'click' = 2,
        'view' = 3,
        'like' = 4,
        'share' = 5,
        'add_cart' = 6,
        'order' = 7
    ),
    context Nested(               -- 上下文信息
        device_type String,
        os String,
        location String,
        ip String
    ),
    extra_data String,            -- JSON额外数据
    watch_duration Int32,         -- 观看时长（秒）
    completion_rate Float32,      -- 完成率
    experiment_id String,         -- AB实验ID
    experiment_group String,      -- 实验分组
    timestamp DateTime64(3),      -- 时间戳（毫秒精度）
    date Date                     -- 日期分区字段
)
ENGINE = MergeTree()
PARTITION BY toYYYYMM(date)      -- 按月分区
ORDER BY (tenant_id, scenario_id, date, user_id, timestamp)
TTL date + INTERVAL 90 DAY       -- 保留90天
SETTINGS index_granularity = 8192;
```

### 2. 实时指标聚合表（物化视图）

```sql
-- 每小时指标聚合
CREATE MATERIALIZED VIEW IF NOT EXISTS metrics_hourly
ENGINE = SummingMergeTree()
PARTITION BY toYYYYMM(date)
ORDER BY (tenant_id, scenario_id, date, hour)
AS SELECT
    tenant_id,
    scenario_id,
    toDate(timestamp) AS date,
    toHour(timestamp) AS hour,
    countIf(action_type = 'impression') AS impressions,
    countIf(action_type = 'click') AS clicks,
    countIf(action_type = 'order') AS conversions,
    uniqExact(user_id) AS active_users,
    uniqExact(item_id) AS active_items
FROM user_behaviors
GROUP BY tenant_id, scenario_id, date, hour;
```

### 3. 物品统计表（物化视图）

```sql
CREATE MATERIALIZED VIEW IF NOT EXISTS item_stats_daily
ENGINE = SummingMergeTree()
PARTITION BY toYYYYMM(date)
ORDER BY (tenant_id, scenario_id, item_id, date)
AS SELECT
    tenant_id,
    scenario_id,
    item_id,
    toDate(timestamp) AS date,
    countIf(action_type = 'impression') AS impressions,
    countIf(action_type = 'click') AS clicks,
    countIf(action_type = 'order') AS conversions,
    sum(watch_duration) AS total_watch_duration,
    avg(completion_rate) AS avg_completion_rate
FROM user_behaviors
GROUP BY tenant_id, scenario_id, item_id, date;
```

---

## API查询示例

### 1. 获取仪表板数据

```sql
-- 查询最近24小时的核心指标
SELECT
    sum(impressions) AS total_recommendations,
    sum(clicks) AS total_clicks,
    (sum(clicks) * 100.0 / sum(impressions)) AS ctr,
    sum(conversions) AS total_conversions,
    (sum(conversions) * 100.0 / sum(impressions)) AS conversion_rate,
    uniqExact(active_users) AS active_users
FROM metrics_hourly
WHERE tenant_id = '{tenant_id}'
  AND scenario_id = '{scenario_id}'
  AND date >= today() - 1
  AND hour >= toHour(now()) - 24;
```

### 2. 获取趋势数据

```sql
-- 查询最近7天每小时的趋势
SELECT
    toStartOfHour(timestamp) AS hour,
    countIf(action_type = 'impression') AS impressions,
    countIf(action_type = 'click') AS clicks,
    (countIf(action_type = 'click') * 100.0 / countIf(action_type = 'impression')) AS ctr
FROM user_behaviors
WHERE tenant_id = '{tenant_id}'
  AND scenario_id = '{scenario_id}'
  AND timestamp >= now() - INTERVAL 7 DAY
GROUP BY hour
ORDER BY hour;
```

### 3. 获取热门物品Top 10

```sql
SELECT
    item_id,
    sum(impressions) AS total_impressions,
    sum(clicks) AS total_clicks,
    (sum(clicks) * 100.0 / sum(impressions)) AS ctr
FROM item_stats_daily
WHERE tenant_id = '{tenant_id}'
  AND scenario_id = '{scenario_id}'
  AND date >= today() - 7
GROUP BY item_id
ORDER BY total_clicks DESC
LIMIT 10;
```

### 4. 获取用户行为漏斗

```sql
SELECT
    action_type,
    count() AS users,
    (count() * 100.0 / (SELECT count(DISTINCT user_id) FROM user_behaviors WHERE tenant_id = '{tenant_id}' AND date = today())) AS rate
FROM user_behaviors
WHERE tenant_id = '{tenant_id}'
  AND date = today()
GROUP BY action_type
ORDER BY action_type;
```

---

## Python服务修改

### analytics/service.py 修改方案

```python
from clickhouse_driver import Client

class AnalyticsService:
    def __init__(self, db: AsyncIOMotorDatabase, clickhouse_client: Client):
        self.db = db
        self.ch = clickhouse_client  # ClickHouse客户端
    
    async def get_dashboard_data(
        self,
        tenant_id: str,
        scenario_id: Optional[str] = None,
        start_time: Optional[datetime] = None,
        end_time: Optional[datetime] = None
    ) -> Dict[str, Any]:
        """从ClickHouse查询仪表板数据"""
        query = """
        SELECT
            sum(impressions) AS total_recommendations,
            sum(clicks) AS total_clicks,
            (sum(clicks) * 100.0 / sum(impressions)) AS ctr,
            sum(conversions) AS total_conversions,
            (sum(conversions) * 100.0 / sum(impressions)) AS conversion_rate,
            uniqExact(active_users) AS active_users
        FROM metrics_hourly
        WHERE tenant_id = %(tenant_id)s
          AND date >= %(start_date)s
          AND date <= %(end_date)s
        """
        
        if scenario_id:
            query += " AND scenario_id = %(scenario_id)s"
        
        params = {
            'tenant_id': tenant_id,
            'scenario_id': scenario_id,
            'start_date': (start_time or datetime.now() - timedelta(days=7)).date(),
            'end_date': (end_time or datetime.now()).date(),
        }
        
        result = self.ch.execute(query, params)
        
        if not result:
            return self._empty_dashboard_data()
        
        row = result[0]
        return {
            "overview": {
                "total_recommendations": int(row[0] or 0),
                "total_clicks": int(row[1] or 0),
                "ctr": float(row[2] or 0),
                "total_conversions": int(row[3] or 0),
                "conversion_rate": float(row[4] or 0),
                "active_users": int(row[5] or 0),
                # 配置数据从MongoDB获取
                "total_items": await self.items_collection.count_documents({"tenant_id": tenant_id}),
                "active_scenarios": await self.scenarios_collection.count_documents({"tenant_id": tenant_id, "status": "active"}),
            },
            "data_source": "clickhouse"
        }
```

---

## 前端修改

### 1. 修复剩余的硬编码图表

```typescript
// 推荐效果指标图 - 使用API数据
const effectMetricsOption = computed(() => {
  const ctrTrend = trendData.value?.trends?.find((t: any) => t.metric_name === 'ctr');
  const conversionTrend = trendData.value?.trends?.find((t: any) => t.metric_name === 'conversions');
  
  const timePoints = ctrTrend?.points?.map((p: any) => {
    const date = new Date(p.timestamp.seconds * 1000);
    return ['周日', '周一', '周二', '周三', '周四', '周五', '周六'][date.getDay()];
  }) || ['周一', '周二', '周三', '周四', '周五', '周六', '周日'];
  
  const ctrData = ctrTrend?.points?.map((p: any) => p.value) || [0, 0, 0, 0, 0, 0, 0];
  const conversionData = conversionTrend?.points?.map((p: any) => p.value / 1000) || [0, 0, 0, 0, 0, 0, 0];
  
  return {
    // ... ECharts配置
    xAxis: { data: timePoints },
    series: [
      { name: '点击率', data: ctrData },
      { name: '转化率', data: conversionData },
    ],
  };
});

// 热门物品图 - 使用API数据
const topItemsOption = computed(() => {
  const distribution = distributionData.value?.distribution || [];
  
  // 假设后端返回热门物品数据
  const items = distribution.slice(0, 10).reverse(); // Top 10并倒序
  const itemNames = items.map((item: any) => item.label);
  const itemCounts = items.map((item: any) => item.count);
  
  return {
    // ... ECharts配置
    yAxis: { data: itemNames.length > 0 ? itemNames : ['暂无数据'] },
    series: [{ data: itemCounts.length > 0 ? itemCounts : [0] }],
  };
});
```

---

## 实施步骤

### 第一阶段：基础架构（1-2周）

1. ✅ **部署ClickHouse**
   ```bash
   docker run -d --name clickhouse-server \
     -p 8123:8123 -p 9000:9000 \
     --ulimit nofile=262144:262144 \
     yandex/clickhouse-server
   ```

2. ✅ **创建ClickHouse表**
   - 执行上面的DDL语句
   - 创建物化视图

3. ✅ **修改behavior-service**
   - 保持MongoDB写入（配置数据）
   - 增加Kafka生产者

4. ✅ **Python服务添加ClickHouse依赖**
   ```bash
   pip install clickhouse-driver
   ```

### 第二阶段：Flink实时计算（2-3周）

1. ✅ **部署Kafka**
   - 使用KRaft模式（无需Zookeeper）
   
2. ✅ **部署Flink**
   - Flink Job: Kafka → ClickHouse
   - Flink Job: 实时指标聚合 → Redis

3. ✅ **开发Flink作业**
   - ItemHotScoreCalculator
   - RealtimeMetricsAggregator
   - ClickHouseSink

### 第三阶段：前端对接（1周）

1. ✅ **修复剩余硬编码图表**
2. ✅ **添加数据刷新机制**
3. ✅ **错误处理和加载状态**

### 第四阶段：前端埋点（1周）

1. ✅ **前端SDK开发**
   ```typescript
   // tracker.ts
   class RecommendationTracker {
     track(event: {
       action: 'impression' | 'click' | 'view';
       itemId: string;
       userId: string;
       tenantId: string;
       scenarioId: string;
     }) {
       fetch('/api/v1/behaviors', {
         method: 'POST',
         body: JSON.stringify(event),
       });
     }
   }
   ```

2. ✅ **页面集成埋点**
   - 推荐结果曝光埋点
   - 点击埋点
   - 页面停留时长

---

## 成本评估

| 组件 | 规格 | 成本 | 备注 |
|-----|------|------|------|
| ClickHouse | 2C4G | ¥200/月 | 初期足够 |
| Kafka | 2C4G | ¥200/月 | 3个broker |
| Flink | 2C4G | ¥200/月 | TaskManager |
| **总计** | | **¥600/月** | |

---

## 常见问题

### Q1: 为什么不用MongoDB做行为分析？
A: MongoDB不适合大规模OLAP查询，亿级数据聚合性能差。ClickHouse是专为OLAP设计的列式存储，查询速度快100倍+。

### Q2: 可以不用Flink吗？
A: 可以，初期可以用Python脚本 + Celery定时任务。但Flink提供：
- 精确一次语义
- 实时性更好（秒级）
- 状态管理
- 反压机制

### Q3: ClickHouse能处理多大数据量？
A: 单表百亿行没问题，配合分区和物化视图，查询毫秒级响应。

### Q4: 行为数据保留多久？
A: 建议：
- ClickHouse原始数据：90天
- 聚合表：永久保留
- MongoDB：7天（仅用于配置和最近查询）

---

## 数据存储职责对比 ⭐

### MongoDB vs ClickHouse 职责划分

| 数据类型 | 特征 | 存储位置 | 理由 |
|---------|------|---------|------|
| 场景配置 | Schema灵活、更新频繁 | MongoDB | 文档型适合嵌套配置 |
| 物品元数据 | 需要全文搜索、复杂查询 | MongoDB | 灵活Schema |
| 模型配置 | JSON配置、版本管理 | MongoDB | 文档存储 |
| 实验配置 | 分组配置、实时更新 | MongoDB | 事务支持 |
| 用户画像 | 特征字典、定期更新 | MongoDB | 文档存储 |
| **行为事件** | **海量、不可变、时序** | **ClickHouse** | **OLAP专用** |
| 实时指标 | 秒级更新、高频读写 | Redis | 内存缓存 |

### 数据量对比

| 存储 | 数据量级 | 增长速度 | 查询类型 |
|-----|---------|---------|---------|
| MongoDB | 10万-100万条 | 慢（手动配置） | 点查询、简单聚合 |
| ClickHouse | 亿级-百亿级 | 快（用户行为） | 复杂聚合、时序分析 |
| Redis | 热数据（1-7天） | 快（实时写入） | KV查询、ZSET排序 |

### 为什么行为数据不用MongoDB？

| 对比项 | MongoDB | ClickHouse |
|-------|---------|------------|
| 写入性能 | ~1K TPS | ~100K TPS（批量） |
| 查询性能 | 慢（亿级数据） | 快（列式存储） |
| 存储成本 | 高（行存） | 低（压缩率10:1） |
| 时序查询 | 不支持 | 原生支持 |
| 数据压缩 | 一般 | 优秀 |
| OLAP能力 | ❌ | ✅ |

### 架构简化收益

```
❌ 旧方案（数据重复）：
behavior-service → MongoDB → Kafka → Flink → ClickHouse
                     ↓
                 保留7天后删除（浪费存储）

✅ 新方案（单一数据源）：
behavior-service → Kafka → Flink → ClickHouse
                                      ↓
                                 统一分析查询

收益：
- 减少存储成本（不在MongoDB保留行为数据）
- 减少数据同步环节
- 降低系统复杂度
- MongoDB专注于配置数据，响应更快
```

---

## 总结

### 核心设计改进 ⭐

#### v1.0（旧方案）问题
```
behavior-service → MongoDB + Kafka → ClickHouse
                     ↓
                  数据重复存储
                  增加复杂度
```

#### v2.0（新方案）优化
```
behavior-service → Kafka → ClickHouse
                              ↓
                       单一数据源
                       架构简化
```

### 职责清晰划分

| 组件 | 职责 | 数据特征 |
|-----|------|---------|
| **MongoDB** | 配置数据 | 小数据量、灵活Schema、CRUD |
| **ClickHouse** | 行为数据 | 大数据量、时序分析、OLAP |
| **Redis** | 实时缓存 | 热数据、高频读写 |
| **Kafka** | 消息队列 | 解耦、削峰、持久化 |
| **Flink** | 实时计算 | 流处理、聚合、ETL |

### 架构收益对比

| 指标 | 旧方案（双写） | 新方案（单写） |
|-----|--------------|--------------|
| 存储成本 | MongoDB + ClickHouse | 仅ClickHouse |
| 数据一致性 | 需要保证两边同步 | 单一数据源 |
| 系统复杂度 | 高（双写逻辑） | 低（仅写Kafka） |
| MongoDB负载 | 高（行为写入） | 低（仅配置） |
| 查询性能 | ClickHouse快 | ClickHouse快 |

### 实施步骤

#### 第一阶段：基础架构（1-2周）
1. ✅ 部署ClickHouse
2. ✅ 创建表和物化视图
3. ✅ behavior-service改为仅写Kafka
4. ✅ Python添加ClickHouse客户端

#### 第二阶段：实时计算（2-3周）
1. ✅ 部署Kafka
2. ✅ 部署Flink
3. ✅ Flink Job: Kafka → ClickHouse
4. ✅ Flink Job: 实时指标 → Redis

#### 第三阶段：服务对接（1周）
1. ✅ AnalyticsService查询ClickHouse
2. ✅ 前端修复硬编码图表
3. ✅ 添加前端埋点

### 投入产出

**开发成本**：
- 时间：4-6周
- 人力：1-2人

**运维成本**：
- ClickHouse: ¥200/月（2C4G）
- Kafka: ¥200/月
- Flink: ¥200/月
- **总计：¥600/月**

**价值收益**：
- ✅ 支持亿级行为数据分析
- ✅ 秒级查询响应（聚合）
- ✅ 完整的数据分析能力
- ✅ 实验效果评估
- ✅ 实时热度榜单
- ✅ 降低MongoDB负载

### 关键要点

1. **MongoDB不是OLAP数据库**
   - 适合配置数据、文档存储
   - 不适合大规模时序分析

2. **ClickHouse是OLAP专家**
   - 列式存储，压缩率高
   - 原生支持时序查询
   - 物化视图自动聚合

3. **架构越简单越好**
   - 行为数据直接到ClickHouse
   - 减少数据流转环节
   - 降低维护成本

