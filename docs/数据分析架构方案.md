# 数据分析架构完整方案 v2.0

## 问题背景

当前数据分析页面存在以下问题：
1. ❌ Python服务返回空数据（推荐次数、CTR、活跃用户等全为0）
2. ❌ 前端部分图表还在使用硬编码数据
3. ❌ 没有真实的用户行为数据收集系统

## 核心设计原则 ⭐

### 职责分离
- **MongoDB**: 仅存储业务配置数据（场景、物品、模型、实验）
- **ClickHouse**: 专门存储和分析所有行为数据
- **Redis**: 实时热数据缓存

### 数据流简化
```
行为数据流：前端 → behavior-service → Kafka → Flink → ClickHouse + Redis
                                                          ↓
                                               AnalyticsService查询
配置数据流：管理后台 → MongoDB → gRPC服务
```

## 架构设计

### 整体数据流

```
┌─────────────────────────────────────────────────────────────────┐
│                     1. 数据采集层                                 │
├─────────────────────────────────────────────────────────────────┤
│  前端埋点                                                         │
│  ├─ 推荐曝光（impression）                                       │
│  ├─ 推荐点击（click）                                            │
│  ├─ 物品详情查看（view）                                         │
│  ├─ 加购/收藏（action）                                          │
│  └─ 转化（conversion）                                           │
│                    ↓                                             │
│  behavior-service (FastAPI HTTP 8003)                           │
│  ├─ 接收行为事件                                                 │
│  ├─ 数据验证（tenant_id、user_id、item_id等）                   │
│  └─ 发送到 Kafka（不写MongoDB） ⭐                               │
└─────────────────────────────────────────────────────────────────┘
                     ↓
┌─────────────────────────────────────────────────────────────────┐
│                     2. 消息队列层                                 │
├─────────────────────────────────────────────────────────────────┤
│  Kafka Topics                                                    │
│  ├─ user-behaviors (分区：12-24，保留：7天)                     │
│  └─ recommendation-metrics (分区：6，保留：3天)                  │
└─────────────────────────────────────────────────────────────────┘
                     ↓
┌─────────────────────────────────────────────────────────────────┐
│                     3. 实时计算层                                 │
├─────────────────────────────────────────────────────────────────┤
│  Flink Jobs                                                      │
│  ├─ Job1: ClickHouseSink（批量写入）                            │
│  │  └─ Kafka → ClickHouse (user_behaviors表)                   │
│  │                                                               │
│  ├─ Job2: ItemHotScoreCalculator（实时热度）                    │
│  │  └─ Kafka → Redis ZSET (hot:items:*)                        │
│  │                                                               │
│  └─ Job3: RealtimeMetricsAggregator（实时指标）                 │
│     └─ Kafka → Redis HASH (metrics:realtime:*)                  │
└─────────────────────────────────────────────────────────────────┘
                     ↓
┌─────────────────────────────────────────────────────────────────┐
│                     4. 存储层                                     │
├─────────────────────────────────────────────────────────────────┤
│  ClickHouse (行为数据专用) ⭐                                     │
│  ├─ user_behaviors: 原始行为事件（90天）                         │
│  ├─ metrics_hourly: 每小时指标聚合（物化视图）                   │
│  ├─ item_stats_daily: 物品统计（物化视图）                       │
│  └─ experiment_metrics: 实验指标（物化视图）                     │
│                                                                  │
│  MongoDB (配置数据专用) ⭐                                        │
│  ├─ scenarios: 场景配置                                          │
│  ├─ items: 物品元数据                                            │
│  ├─ models: 模型配置                                             │
│  ├─ experiments: AB实验配置                                      │
│  └─ user_profiles: 用户画像（可选）                              │
│                                                                  │
│  Redis (实时缓存)                                                │
│  ├─ hot:items:{tenant}:{scenario} → ZSET                        │
│  ├─ metrics:realtime:{tenant}:{scenario} → HASH                 │
│  └─ user:recent:{user_id} → LIST (最近浏览)                     │
└─────────────────────────────────────────────────────────────────┘
                     ↓
┌─────────────────────────────────────────────────────────────────┐
│                     5. 查询层                                     │
├─────────────────────────────────────────────────────────────────┤
│  AnalyticsService (Python)                                      │
│  ├─ getDashboard()                                              │
│  │  ├─ ClickHouse查询：推荐次数、CTR、转化率、活跃用户          │
│  │  └─ MongoDB查询：物品数、场景数（配置数据）                  │
│  │                                                               │
│  ├─ getMetricsTrend()                                           │
│  │  └─ ClickHouse查询：时序数据（按小时/天聚合）                │
│  │                                                               │
│  ├─ getItemDistribution()                                       │
│  │  └─ ClickHouse查询：物品曝光/点击分组统计                    │
│  │                                                               │
│  └─ getUserBehaviorAnalysis()                                   │
│     └─ ClickHouse查询：用户行为漏斗、转化率                      │
└─────────────────────────────────────────────────────────────────┘
```

---

## 不同场景的埋点数据标准 ⭐

### 埋点数据采集方式

系统支持**三种**埋点数据采集方式，针对不同使用场景：

#### 1. HTTP REST API方式（推荐：C端）
- **接口**：`POST /api/v1/behaviors/track`
- **端口**：8003
- **优点**：简单易用、浏览器友好、跨平台
- **缺点**：性能略低（~5K TPS）
- **适用场景**：
  - ✅ 前端页面埋点（浏览器）
  - ✅ 移动端App埋点（iOS/Android）
  - ✅ 第三方系统快速接入
  - ✅ 低频关键事件（点击、转化）

#### 2. gRPC方式（推荐：内部服务 + 类型安全）
- **服务**：`BehaviorService.TrackEvent`
- **端口**：9003
- **优点**：高性能（~10K TPS）、类型安全、二进制传输
- **缺点**：需要proto定义和SDK
- **适用场景**：
  - ✅ 后端服务间调用
  - ✅ 需要强类型约束
  - ✅ 中高频事件

#### 3. Kafka直接写入方式（推荐：内部服务 + 高性能）⭐
- **Topic**：`user-behaviors-{tenant_id}`
- **端口**：9092
- **优点**：**最高性能（~50K TPS）**、解耦、削峰填谷
- **缺点**：需要集成Kafka SDK、绕过统一验证
- **适用场景**：
  - ✅ **内部服务高频埋点**（推荐服务、内容服务）
  - ✅ 极高频事件（曝光、滚动、进度上报）
  - ✅ 批量数据导入、离线补录
  - ✅ 对延迟敏感的场景（<10ms）
  - ❌ **不适合C端**（不直接暴露Kafka给外网）

**架构示意图**：
```
┌─────────────────────────────────────────────────────────┐
│  C端（前端/移动端）                                        │
│    ↓ HTTP/SDK                                            │
│  API网关 → behavior-service (HTTP 8003 / gRPC 9003)      │
│                      ↓                                   │
│                   验证 + 日志                             │
│                      ↓                                   │
├─────────────────────┴───────────────────────────────────┤
│                   Kafka                                  │
│         Topic: user-behaviors-{tenant_id}               │
│                      ↑                                   │
│                      | 直接写入（高性能）⭐                │
│                      |                                   │
│  内部服务（推荐服务、内容服务等）                           │
│    ↓ Kafka SDK                                           │
└─────────────────────────────────────────────────────────┘
                      ↓
                   Flink → ClickHouse
```

### 方式选择决策表

| 场景 | 推荐方式 | 性能 | 复杂度 | 理由 |
|-----|---------|------|--------|------|
| 前端页面埋点 | HTTP | 5K TPS | ⭐ | 浏览器原生支持 |
| 移动App埋点 | HTTP | 5K TPS | ⭐ | SDK简单、跨平台 |
| 推荐服务埋点（推荐结果曝光） | **Kafka** ⭐ | **50K TPS** | ⭐⭐ | 高频、高性能 |
| 内容服务埋点（内容发布） | gRPC | 10K TPS | ⭐⭐ | 类型安全 |
| 用户服务埋点（用户行为） | Kafka | 50K TPS | ⭐⭐ | 高频、解耦 |
| 第三方系统接入 | HTTP | 5K TPS | ⭐ | 兼容性好 |
| 离线数据补录 | Kafka | 50K TPS | ⭐⭐ | 批量、高吞吐 |
| 实时监控埋点 | Kafka | 50K TPS | ⭐⭐ | 低延迟 |

### 性能对比

| 指标 | HTTP | gRPC | Kafka直接写入 |
|-----|------|------|--------------|
| **延迟（P99）** | 100ms | 50ms | **15ms** ⭐ |
| **吞吐（单机）** | 5K TPS | 10K TPS | **50K TPS** ⭐ |
| **网络开销** | 高 | 中 | **低** ⭐ |
| **依赖** | behavior-service | behavior-service | **仅Kafka** |
| **可用性** | 依赖服务 | 依赖服务 | **Kafka 3副本** |
| **类型安全** | Pydantic | **Proto** ⭐ | 客户端自行验证 |
| **适合场景** | C端 | 内部服务 | **内部高频** ⭐ |

### SaaS租户隔离规则 🔒

**强制要求**：
- ✅ 所有埋点数据**必须**携带 `tenant_id`
- ❌ 未携带 `tenant_id` 的请求**直接拒绝**（返回400）
- ✅ 在behavior-service入口处验证
- ✅ ClickHouse按 `tenant_id` 分区存储

**验证逻辑**：
```python
if not event.get('tenant_id'):
    raise ValueError("tenant_id is required for SaaS system")
```

---

### 通用埋点字段（所有场景必需）

| 字段名 | 类型 | 必填 | 说明 | 示例 |
|-------|------|------|------|------|
| `event_id` | String | ✅ | 事件唯一ID（UUID） | `evt_abc123` |
| `tenant_id` | String | ✅ | **租户ID（SaaS必需）** | `tenant_mymx` |
| `scenario_id` | String | ✅ | 场景ID | `vlog_feed` |
| `user_id` | String | ✅ | 用户ID | `user_12345` |
| `item_id` | String | ✅ | 物品ID | `item_67890` |
| `action_type` | Enum | ✅ | 行为类型 | `click` |
| `timestamp` | Int64 | ✅ | 时间戳（毫秒） | `1730000000000` |
| `context.device_type` | String | ✅ | 设备类型 | `mobile`, `pc`, `tablet` |
| `context.os` | String | 可选 | 操作系统 | `iOS`, `Android`, `Windows` |
| `context.location` | String | 可选 | 地理位置 | `Beijing` |
| `context.ip` | String | 可选 | IP地址 | `192.168.1.1` |
| `experiment_id` | String | 可选 | AB实验ID | `exp_001` |
| `experiment_group` | String | 可选 | 实验分组 | `control`, `treatment` |

---

### 场景1：短视频推荐（Vlog/抖音/快手）

#### 核心指标
- 曝光数、点击数、完播率、点赞数、分享数、评论数

#### 行为类型
| 行为 | action_type | 必需字段 | 可选字段 |
|-----|-------------|---------|---------|
| 曝光 | `impression` | `position`（排位） | `rec_reason`（推荐理由） |
| 点击 | `click` | `position` | - |
| 播放 | `play` | `duration`（视频时长） | - |
| 播放结束 | `play_end` | `watch_duration`（观看时长）<br>`completion_rate`（完播率） | `pause_count`（暂停次数） |
| 点赞 | `like` | - | - |
| 分享 | `share` | `share_to`（分享渠道） | - |
| 评论 | `comment` | `comment_id` | `comment_length` |
| 关注作者 | `follow` | `author_id` | - |

#### 额外字段（extra_data JSON）
```json
{
  "video_duration": 60,        // 视频总时长（秒）
  "watch_duration": 45,        // 实际观看时长（秒）
  "completion_rate": 0.75,     // 完播率
  "pause_count": 2,            // 暂停次数
  "replay_count": 1,           // 重播次数
  "author_id": "author_123",   // 作者ID
  "category": "entertainment", // 视频分类
  "tags": ["funny", "comedy"], // 视频标签
  "sound_on": true,            // 是否开启声音
  "full_screen": false         // 是否全屏
}
```

---

### 场景2：电商推荐（淘宝/京东/拼多多）

#### 核心指标
- 曝光数、点击数、加购率、下单率、支付率、客单价

#### 行为类型
| 行为 | action_type | 必需字段 | 可选字段 |
|-----|-------------|---------|---------|
| 曝光 | `impression` | `position`<br>`price`（价格） | `discount_rate`（折扣） |
| 点击 | `click` | `position` | - |
| 查看详情 | `view` | `stay_duration`（停留时长） | `image_count`（查看图片数） |
| 加购物车 | `add_cart` | `quantity`（数量） | `sku_id`（SKU） |
| 收藏 | `favorite` | - | - |
| 下单 | `order` | `order_id`<br>`quantity`<br>`total_amount`（总金额） | `coupon_id`（优惠券） |
| 支付 | `payment` | `order_id`<br>`payment_amount`<br>`payment_method` | - |
| 分享 | `share` | `share_to` | - |

#### 额外字段（extra_data JSON）
```json
{
  "product_name": "iPhone 15 Pro",
  "price": 7999.00,
  "original_price": 8999.00,
  "discount_rate": 0.11,
  "category": "数码产品/手机",
  "brand": "Apple",
  "sku_id": "sku_123",
  "stock": 100,
  "sales": 5000,              // 销量
  "rating": 4.8,              // 评分
  "review_count": 1200,       // 评价数
  "shipping_fee": 0,          // 运费
  "is_free_return": true,     // 是否包退
  "delivery_time": "次日达"   // 配送时效
}
```

---

### 场景3：新闻资讯（今日头条/腾讯新闻）

#### 核心指标
- 曝光数、点击数、阅读完成率、停留时长、评论数、分享数

#### 行为类型
| 行为 | action_type | 必需字段 | 可选字段 |
|-----|-------------|---------|---------|
| 曝光 | `impression` | `position` | `rec_reason` |
| 点击 | `click` | `position` | - |
| 阅读 | `read` | `stay_duration`（停留时长） | `scroll_depth`（滚动深度%） |
| 阅读完成 | `read_end` | `read_duration`<br>`completion_rate` | `scroll_depth` |
| 点赞 | `like` | - | - |
| 踩 | `dislike` | - | `dislike_reason`（不喜欢原因） |
| 评论 | `comment` | `comment_id` | - |
| 分享 | `share` | `share_to` | - |
| 关注作者 | `follow` | `author_id` | - |
| 不感兴趣 | `not_interest` | `reason`（原因） | - |

#### 额外字段（extra_data JSON）
```json
{
  "article_title": "新闻标题",
  "publish_time": 1730000000,   // 发布时间
  "author_id": "author_123",
  "category": "科技",
  "tags": ["AI", "科技"],
  "word_count": 2000,           // 字数
  "image_count": 5,             // 图片数
  "video_count": 1,             // 视频数
  "read_duration": 120,         // 阅读时长（秒）
  "scroll_depth": 0.85,         // 滚动深度（0-1）
  "is_hot": true,               // 是否热点
  "heat_score": 95.5            // 热度分数
}
```

---

### 场景4：音乐推荐（网易云/QQ音乐/Spotify）

#### 核心指标
- 曝光数、点击数、播放完成率、单曲循环率、加入歌单率

#### 行为类型
| 行为 | action_type | 必需字段 | 可选字段 |
|-----|-------------|---------|---------|
| 曝光 | `impression` | `position` | - |
| 点击播放 | `play` | `duration`（歌曲时长） | - |
| 播放结束 | `play_end` | `play_duration`<br>`completion_rate` | `skip`（是否跳过） |
| 暂停 | `pause` | `play_progress`（播放进度%） | - |
| 单曲循环 | `repeat` | - | - |
| 加入歌单 | `add_playlist` | `playlist_id` | - |
| 下载 | `download` | - | `quality`（音质） |
| 分享 | `share` | `share_to` | - |
| 点赞 | `like` | - | - |

#### 额外字段（extra_data JSON）
```json
{
  "song_name": "歌曲名",
  "artist": "歌手名",
  "album": "专辑名",
  "duration": 240,              // 歌曲时长（秒）
  "play_duration": 180,         // 实际播放时长
  "completion_rate": 0.75,
  "genre": "流行",              // 音乐类型
  "language": "中文",
  "release_year": 2024,
  "play_count": 10000000,       // 播放量
  "like_count": 50000,          // 点赞数
  "quality": "HQ",              // 音质（SQ/HQ/标准）
  "is_vip": false               // 是否VIP歌曲
}
```

---

### 场景5：在线教育（B站/得到/极客时间）

#### 核心指标
- 曝光数、点击数、学习完成率、课程购买率、互动率

#### 行为类型
| 行为 | action_type | 必需字段 | 可选字段 |
|-----|-------------|---------|---------|
| 曝光 | `impression` | `position`<br>`price`（课程价格） | - |
| 点击 | `click` | `position` | - |
| 试看 | `trial` | `watch_duration` | - |
| 学习 | `learn` | `watch_duration`<br>`completion_rate` | `speed`（播放速度） |
| 学习完成 | `complete` | `chapter_id` | - |
| 做笔记 | `note` | `note_id` | `note_length` |
| 提问 | `ask` | `question_id` | - |
| 购买 | `purchase` | `order_id`<br>`payment_amount` | `coupon_id` |
| 评价 | `review` | `rating`（评分） | `review_content` |

#### 额外字段（extra_data JSON）
```json
{
  "course_name": "Python从入门到精通",
  "teacher": "老师名",
  "category": "编程/Python",
  "difficulty": "中级",
  "duration": 36000,            // 课程总时长（秒）
  "chapter_count": 50,          // 章节数
  "student_count": 10000,       // 学员数
  "rating": 4.9,                // 评分
  "price": 199.00,
  "original_price": 299.00,
  "learning_progress": 0.35,    // 学习进度
  "speed": 1.5,                 // 播放速度
  "subtitle": true              // 是否显示字幕
}
```

---

### 行为类型枚举定义

```python
from enum import Enum

class ActionType(str, Enum):
    # 基础行为
    IMPRESSION = "impression"     # 曝光
    CLICK = "click"               # 点击
    VIEW = "view"                 # 查看详情
    
    # 内容消费
    PLAY = "play"                 # 播放
    PLAY_END = "play_end"         # 播放结束
    READ = "read"                 # 阅读
    READ_END = "read_end"         # 阅读结束
    LEARN = "learn"               # 学习
    COMPLETE = "complete"         # 完成
    
    # 互动行为
    LIKE = "like"                 # 点赞
    DISLIKE = "dislike"           # 踩
    FAVORITE = "favorite"         # 收藏
    SHARE = "share"               # 分享
    COMMENT = "comment"           # 评论
    FOLLOW = "follow"             # 关注
    
    # 交易行为
    ADD_CART = "add_cart"         # 加购物车
    ORDER = "order"               # 下单
    PAYMENT = "payment"           # 支付
    PURCHASE = "purchase"         # 购买（电商外场景）
    
    # 其他
    NOT_INTEREST = "not_interest" # 不感兴趣
    PAUSE = "pause"               # 暂停
    REPEAT = "repeat"             # 单曲循环
    DOWNLOAD = "download"         # 下载
```

---

## ClickHouse表设计

### 1. 用户行为事件表

```sql
CREATE TABLE IF NOT EXISTS user_behaviors (
    event_id String,              -- 事件唯一ID
    tenant_id String,              -- 租户ID
    scenario_id String,            -- 场景ID
    user_id String,                -- 用户ID
    item_id String,                -- 物品ID
    action_type Enum8(            -- 行为类型
        'impression' = 1,
        'click' = 2,
        'view' = 3,
        'like' = 4,
        'share' = 5,
        'add_cart' = 6,
        'order' = 7
    ),
    context Nested(               -- 上下文信息
        device_type String,
        os String,
        location String,
        ip String
    ),
    extra_data String,            -- JSON额外数据
    watch_duration Int32,         -- 观看时长（秒）
    completion_rate Float32,      -- 完成率
    experiment_id String,         -- AB实验ID
    experiment_group String,      -- 实验分组
    timestamp DateTime64(3),      -- 时间戳（毫秒精度）
    date Date                     -- 日期分区字段
)
ENGINE = MergeTree()
PARTITION BY toYYYYMM(date)      -- 按月分区
ORDER BY (tenant_id, scenario_id, date, user_id, timestamp)
TTL date + INTERVAL 90 DAY       -- 保留90天
SETTINGS index_granularity = 8192;
```

### 2. 实时指标聚合表（物化视图）

```sql
-- 每小时指标聚合
CREATE MATERIALIZED VIEW IF NOT EXISTS metrics_hourly
ENGINE = SummingMergeTree()
PARTITION BY toYYYYMM(date)
ORDER BY (tenant_id, scenario_id, date, hour)
AS SELECT
    tenant_id,
    scenario_id,
    toDate(timestamp) AS date,
    toHour(timestamp) AS hour,
    countIf(action_type = 'impression') AS impressions,
    countIf(action_type = 'click') AS clicks,
    countIf(action_type = 'order') AS conversions,
    uniqExact(user_id) AS active_users,
    uniqExact(item_id) AS active_items
FROM user_behaviors
GROUP BY tenant_id, scenario_id, date, hour;
```

### 3. 物品统计表（物化视图）

```sql
CREATE MATERIALIZED VIEW IF NOT EXISTS item_stats_daily
ENGINE = SummingMergeTree()
PARTITION BY toYYYYMM(date)
ORDER BY (tenant_id, scenario_id, item_id, date)
AS SELECT
    tenant_id,
    scenario_id,
    item_id,
    toDate(timestamp) AS date,
    countIf(action_type = 'impression') AS impressions,
    countIf(action_type = 'click') AS clicks,
    countIf(action_type = 'order') AS conversions,
    sum(watch_duration) AS total_watch_duration,
    avg(completion_rate) AS avg_completion_rate
FROM user_behaviors
GROUP BY tenant_id, scenario_id, item_id, date;
```

---

## API查询示例

### 1. 获取仪表板数据

```sql
-- 查询最近24小时的核心指标
SELECT
    sum(impressions) AS total_recommendations,
    sum(clicks) AS total_clicks,
    (sum(clicks) * 100.0 / sum(impressions)) AS ctr,
    sum(conversions) AS total_conversions,
    (sum(conversions) * 100.0 / sum(impressions)) AS conversion_rate,
    uniqExact(active_users) AS active_users
FROM metrics_hourly
WHERE tenant_id = '{tenant_id}'
  AND scenario_id = '{scenario_id}'
  AND date >= today() - 1
  AND hour >= toHour(now()) - 24;
```

### 2. 获取趋势数据

```sql
-- 查询最近7天每小时的趋势
SELECT
    toStartOfHour(timestamp) AS hour,
    countIf(action_type = 'impression') AS impressions,
    countIf(action_type = 'click') AS clicks,
    (countIf(action_type = 'click') * 100.0 / countIf(action_type = 'impression')) AS ctr
FROM user_behaviors
WHERE tenant_id = '{tenant_id}'
  AND scenario_id = '{scenario_id}'
  AND timestamp >= now() - INTERVAL 7 DAY
GROUP BY hour
ORDER BY hour;
```

### 3. 获取热门物品Top 10

```sql
SELECT
    item_id,
    sum(impressions) AS total_impressions,
    sum(clicks) AS total_clicks,
    (sum(clicks) * 100.0 / sum(impressions)) AS ctr
FROM item_stats_daily
WHERE tenant_id = '{tenant_id}'
  AND scenario_id = '{scenario_id}'
  AND date >= today() - 7
GROUP BY item_id
ORDER BY total_clicks DESC
LIMIT 10;
```

### 4. 获取用户行为漏斗

```sql
SELECT
    action_type,
    count() AS users,
    (count() * 100.0 / (SELECT count(DISTINCT user_id) FROM user_behaviors WHERE tenant_id = '{tenant_id}' AND date = today())) AS rate
FROM user_behaviors
WHERE tenant_id = '{tenant_id}'
  AND date = today()
GROUP BY action_type
ORDER BY action_type;
```

---

## Python服务修改

### analytics/service.py 修改方案

```python
from clickhouse_driver import Client

class AnalyticsService:
    def __init__(self, db: AsyncIOMotorDatabase, clickhouse_client: Client):
        self.db = db
        self.ch = clickhouse_client  # ClickHouse客户端
    
    async def get_dashboard_data(
        self,
        tenant_id: str,
        scenario_id: Optional[str] = None,
        start_time: Optional[datetime] = None,
        end_time: Optional[datetime] = None
    ) -> Dict[str, Any]:
        """从ClickHouse查询仪表板数据"""
        query = """
        SELECT
            sum(impressions) AS total_recommendations,
            sum(clicks) AS total_clicks,
            (sum(clicks) * 100.0 / sum(impressions)) AS ctr,
            sum(conversions) AS total_conversions,
            (sum(conversions) * 100.0 / sum(impressions)) AS conversion_rate,
            uniqExact(active_users) AS active_users
        FROM metrics_hourly
        WHERE tenant_id = %(tenant_id)s
          AND date >= %(start_date)s
          AND date <= %(end_date)s
        """
        
        if scenario_id:
            query += " AND scenario_id = %(scenario_id)s"
        
        params = {
            'tenant_id': tenant_id,
            'scenario_id': scenario_id,
            'start_date': (start_time or datetime.now() - timedelta(days=7)).date(),
            'end_date': (end_time or datetime.now()).date(),
        }
        
        result = self.ch.execute(query, params)
        
        if not result:
            return self._empty_dashboard_data()
        
        row = result[0]
        return {
            "overview": {
                "total_recommendations": int(row[0] or 0),
                "total_clicks": int(row[1] or 0),
                "ctr": float(row[2] or 0),
                "total_conversions": int(row[3] or 0),
                "conversion_rate": float(row[4] or 0),
                "active_users": int(row[5] or 0),
                # 配置数据从MongoDB获取
                "total_items": await self.items_collection.count_documents({"tenant_id": tenant_id}),
                "active_scenarios": await self.scenarios_collection.count_documents({"tenant_id": tenant_id, "status": "active"}),
            },
            "data_source": "clickhouse"
        }
```

---

## 前端修改

### 1. 修复剩余的硬编码图表

```typescript
// 推荐效果指标图 - 使用API数据
const effectMetricsOption = computed(() => {
  const ctrTrend = trendData.value?.trends?.find((t: any) => t.metric_name === 'ctr');
  const conversionTrend = trendData.value?.trends?.find((t: any) => t.metric_name === 'conversions');
  
  const timePoints = ctrTrend?.points?.map((p: any) => {
    const date = new Date(p.timestamp.seconds * 1000);
    return ['周日', '周一', '周二', '周三', '周四', '周五', '周六'][date.getDay()];
  }) || ['周一', '周二', '周三', '周四', '周五', '周六', '周日'];
  
  const ctrData = ctrTrend?.points?.map((p: any) => p.value) || [0, 0, 0, 0, 0, 0, 0];
  const conversionData = conversionTrend?.points?.map((p: any) => p.value / 1000) || [0, 0, 0, 0, 0, 0, 0];
  
  return {
    // ... ECharts配置
    xAxis: { data: timePoints },
    series: [
      { name: '点击率', data: ctrData },
      { name: '转化率', data: conversionData },
    ],
  };
});

// 热门物品图 - 使用API数据
const topItemsOption = computed(() => {
  const distribution = distributionData.value?.distribution || [];
  
  // 假设后端返回热门物品数据
  const items = distribution.slice(0, 10).reverse(); // Top 10并倒序
  const itemNames = items.map((item: any) => item.label);
  const itemCounts = items.map((item: any) => item.count);
  
  return {
    // ... ECharts配置
    yAxis: { data: itemNames.length > 0 ? itemNames : ['暂无数据'] },
    series: [{ data: itemCounts.length > 0 ? itemCounts : [0] }],
  };
});
```

---

## 实施步骤

### 第一阶段：基础架构（1-2周）

1. ✅ **部署ClickHouse**
   ```bash
   docker run -d --name clickhouse-server \
     -p 8123:8123 -p 9000:9000 \
     --ulimit nofile=262144:262144 \
     yandex/clickhouse-server
   ```

2. ✅ **创建ClickHouse表**
   - 执行上面的DDL语句
   - 创建物化视图

3. ✅ **修改behavior-service**
   - 保持MongoDB写入（配置数据）
   - 增加Kafka生产者

4. ✅ **Python服务添加ClickHouse依赖**
   ```bash
   pip install clickhouse-driver
   ```

### 第二阶段：Flink实时计算（2-3周）

1. ✅ **部署Kafka**
   - 使用KRaft模式（无需Zookeeper）
   
2. ✅ **部署Flink**
   - Flink Job: Kafka → ClickHouse
   - Flink Job: 实时指标聚合 → Redis

3. ✅ **开发Flink作业**
   - ItemHotScoreCalculator
   - RealtimeMetricsAggregator
   - ClickHouseSink

### 第三阶段：前端对接（1周）

1. ✅ **修复剩余硬编码图表**
2. ✅ **添加数据刷新机制**
3. ✅ **错误处理和加载状态**

### 第四阶段：前端埋点（1周）

1. ✅ **前端SDK开发**
   ```typescript
   // tracker.ts
   class RecommendationTracker {
     track(event: {
       action: 'impression' | 'click' | 'view';
       itemId: string;
       userId: string;
       tenantId: string;
       scenarioId: string;
     }) {
       fetch('/api/v1/behaviors', {
         method: 'POST',
         body: JSON.stringify(event),
       });
     }
   }
   ```

2. ✅ **页面集成埋点**
   - 推荐结果曝光埋点
   - 点击埋点
   - 页面停留时长

---

## 成本评估

| 组件 | 规格 | 成本 | 备注 |
|-----|------|------|------|
| ClickHouse | 2C4G | ¥200/月 | 初期足够 |
| Kafka | 2C4G | ¥200/月 | 3个broker |
| Flink | 2C4G | ¥200/月 | TaskManager |
| **总计** | | **¥600/月** | |

---

## 常见问题

### Q1: 为什么不用MongoDB做行为分析？
A: MongoDB不适合大规模OLAP查询，亿级数据聚合性能差。ClickHouse是专为OLAP设计的列式存储，查询速度快100倍+。

### Q2: 可以不用Flink吗？
A: 可以，初期可以用Python脚本 + Celery定时任务。但Flink提供：
- 精确一次语义
- 实时性更好（秒级）
- 状态管理
- 反压机制

### Q3: ClickHouse能处理多大数据量？
A: 单表百亿行没问题，配合分区和物化视图，查询毫秒级响应。

### Q4: 行为数据保留多久？
A: 建议：
- ClickHouse原始数据：90天
- 聚合表：永久保留
- MongoDB：7天（仅用于配置和最近查询）

---

## 数据存储职责对比 ⭐

### MongoDB vs ClickHouse 职责划分

| 数据类型 | 特征 | 存储位置 | 理由 |
|---------|------|---------|------|
| 场景配置 | Schema灵活、更新频繁 | MongoDB | 文档型适合嵌套配置 |
| 物品元数据 | 需要全文搜索、复杂查询 | MongoDB | 灵活Schema |
| 模型配置 | JSON配置、版本管理 | MongoDB | 文档存储 |
| 实验配置 | 分组配置、实时更新 | MongoDB | 事务支持 |
| 用户画像 | 特征字典、定期更新 | MongoDB | 文档存储 |
| **行为事件** | **海量、不可变、时序** | **ClickHouse** | **OLAP专用** |
| 实时指标 | 秒级更新、高频读写 | Redis | 内存缓存 |

### 数据量对比

| 存储 | 数据量级 | 增长速度 | 查询类型 |
|-----|---------|---------|---------|
| MongoDB | 10万-100万条 | 慢（手动配置） | 点查询、简单聚合 |
| ClickHouse | 亿级-百亿级 | 快（用户行为） | 复杂聚合、时序分析 |
| Redis | 热数据（1-7天） | 快（实时写入） | KV查询、ZSET排序 |

### 为什么行为数据不用MongoDB？

| 对比项 | MongoDB | ClickHouse |
|-------|---------|------------|
| 写入性能 | ~1K TPS | ~100K TPS（批量） |
| 查询性能 | 慢（亿级数据） | 快（列式存储） |
| 存储成本 | 高（行存） | 低（压缩率10:1） |
| 时序查询 | 不支持 | 原生支持 |
| 数据压缩 | 一般 | 优秀 |
| OLAP能力 | ❌ | ✅ |

### 架构简化收益

```
❌ 旧方案（数据重复）：
behavior-service → MongoDB → Kafka → Flink → ClickHouse
                     ↓
                 保留7天后删除（浪费存储）

✅ 新方案（单一数据源）：
behavior-service → Kafka → Flink → ClickHouse
                                      ↓
                                 统一分析查询

收益：
- 减少存储成本（不在MongoDB保留行为数据）
- 减少数据同步环节
- 降低系统复杂度
- MongoDB专注于配置数据，响应更快
```

---

## 总结

### 核心设计改进 ⭐

#### v1.0（旧方案）问题
```
behavior-service → MongoDB + Kafka → ClickHouse
                     ↓
                  数据重复存储
                  增加复杂度
```

#### v2.0（新方案）优化
```
behavior-service → Kafka → ClickHouse
                              ↓
                       单一数据源
                       架构简化
```

### 职责清晰划分

| 组件 | 职责 | 数据特征 |
|-----|------|---------|
| **MongoDB** | 配置数据 | 小数据量、灵活Schema、CRUD |
| **ClickHouse** | 行为数据 | 大数据量、时序分析、OLAP |
| **Redis** | 实时缓存 | 热数据、高频读写 |
| **Kafka** | 消息队列 | 解耦、削峰、持久化 |
| **Flink** | 实时计算 | 流处理、聚合、ETL |

### 架构收益对比

| 指标 | 旧方案（双写） | 新方案（单写） |
|-----|--------------|--------------|
| 存储成本 | MongoDB + ClickHouse | 仅ClickHouse |
| 数据一致性 | 需要保证两边同步 | 单一数据源 |
| 系统复杂度 | 高（双写逻辑） | 低（仅写Kafka） |
| MongoDB负载 | 高（行为写入） | 低（仅配置） |
| 查询性能 | ClickHouse快 | ClickHouse快 |

### 实施步骤

#### 第一阶段：基础架构（1-2周）
1. ✅ 部署ClickHouse
2. ✅ 创建表和物化视图
3. ✅ behavior-service改为仅写Kafka
4. ✅ Python添加ClickHouse客户端

#### 第二阶段：实时计算（2-3周）
1. ✅ 部署Kafka
2. ✅ 部署Flink
3. ✅ Flink Job: Kafka → ClickHouse
4. ✅ Flink Job: 实时指标 → Redis

#### 第三阶段：服务对接（1周）
1. ✅ AnalyticsService查询ClickHouse
2. ✅ 前端修复硬编码图表
3. ✅ 添加前端埋点

### 投入产出

**开发成本**：
- 时间：4-6周
- 人力：1-2人

**运维成本**：
- ClickHouse: ¥200/月（2C4G）
- Kafka: ¥200/月
- Flink: ¥200/月
- **总计：¥600/月**

**价值收益**：
- ✅ 支持亿级行为数据分析
- ✅ 秒级查询响应（聚合）
- ✅ 完整的数据分析能力
- ✅ 实验效果评估
- ✅ 实时热度榜单
- ✅ 降低MongoDB负载

### 关键要点

1. **MongoDB不是OLAP数据库**
   - 适合配置数据、文档存储
   - 不适合大规模时序分析

2. **ClickHouse是OLAP专家**
   - 列式存储，压缩率高
   - 原生支持时序查询
   - 物化视图自动聚合

3. **架构越简单越好**
   - 行为数据直接到ClickHouse
   - 减少数据流转环节
   - 降低维护成本

