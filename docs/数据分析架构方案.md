# 数据分析架构完整方案

## 问题背景

当前数据分析页面存在以下问题：
1. ❌ Python服务返回空数据（推荐次数、CTR、活跃用户等全为0）
2. ❌ 前端部分图表还在使用硬编码数据
3. ❌ 没有真实的用户行为数据收集系统

## 架构设计

### 整体数据流

```
┌─────────────────────────────────────────────────────────────────┐
│                     1. 数据采集层                                 │
├─────────────────────────────────────────────────────────────────┤
│  前端埋点                                                         │
│  ├─ 推荐曝光（impression）                                       │
│  ├─ 推荐点击（click）                                            │
│  ├─ 物品详情查看（view）                                         │
│  ├─ 加购/收藏（action）                                          │
│  └─ 转化（conversion）                                           │
│                    ↓                                             │
│  behavior-service (FastAPI HTTP 8003)                           │
│  ├─ 接收行为事件                                                 │
│  ├─ 数据验证                                                     │
│  └─ 双写：MongoDB + Kafka                                       │
└─────────────────────────────────────────────────────────────────┘
                     ↓
┌─────────────────────────────────────────────────────────────────┐
│                     2. 存储层                                     │
├─────────────────────────────────────────────────────────────────┤
│  MongoDB (interactions collection)                              │
│  ├─ 用途：配置数据 + 少量行为日志（7天）                         │
│  ├─ 保留时间：7天（TTL索引）                                     │
│  └─ 适用场景：最近行为查询、用户画像                             │
│                                                                  │
│  ClickHouse (OLAP数据库) ⭐ 新增                                 │
│  ├─ 用途：海量行为数据分析                                       │
│  ├─ 保留时间：90天+                                              │
│  ├─ 表设计：见下方"ClickHouse表设计"                             │
│  └─ 适用场景：趋势分析、报表查询、实验效果评估                   │
│                                                                  │
│  Redis (实时缓存)                                                │
│  ├─ hot:items:{tenant}:{scenario} → ZSET (Flink实时计算)        │
│  ├─ metrics:realtime:{tenant}:{scenario} → HASH                 │
│  └─ TTL: 1小时-24小时                                            │
└─────────────────────────────────────────────────────────────────┘
                     ↓
┌─────────────────────────────────────────────────────────────────┐
│                     3. 实时计算层                                 │
├─────────────────────────────────────────────────────────────────┤
│  Kafka Topics                                                    │
│  ├─ user-behaviors-{tenant_id}                                  │
│  │  ├─ 分区数：12-24（按tenant_id哈希）                         │
│  │  └─ 保留时间：7天                                             │
│  └─ recommendation-metrics                                       │
│                    ↓                                             │
│  Flink Jobs                                                      │
│  ├─ Job1: ItemHotScoreCalculator                                │
│  │  └─ 输出：Redis ZSET (hot:items:*)                           │
│  ├─ Job2: RealtimeMetricsAggregator                             │
│  │  └─ 输出：Redis HASH (metrics:realtime:*)                    │
│  └─ Job3: ClickHouseSink                                        │
│     └─ 输出：ClickHouse (批量写入)                               │
└─────────────────────────────────────────────────────────────────┘
                     ↓
┌─────────────────────────────────────────────────────────────────┐
│                     4. 查询层                                     │
├─────────────────────────────────────────────────────────────────┤
│  AnalyticsService (Python)                                      │
│  ├─ getDashboard() → 查询ClickHouse聚合统计                     │
│  ├─ getMetricsTrend() → 查询ClickHouse时序数据                  │
│  ├─ getItemDistribution() → 查询ClickHouse分组统计              │
│  └─ getUserBehaviorAnalysis() → 查询ClickHouse漏斗分析          │
└─────────────────────────────────────────────────────────────────┘
```

---

## ClickHouse表设计

### 1. 用户行为事件表

```sql
CREATE TABLE IF NOT EXISTS user_behaviors (
    event_id String,              -- 事件唯一ID
    tenant_id String,              -- 租户ID
    scenario_id String,            -- 场景ID
    user_id String,                -- 用户ID
    item_id String,                -- 物品ID
    action_type Enum8(            -- 行为类型
        'impression' = 1,
        'click' = 2,
        'view' = 3,
        'like' = 4,
        'share' = 5,
        'add_cart' = 6,
        'order' = 7
    ),
    context Nested(               -- 上下文信息
        device_type String,
        os String,
        location String,
        ip String
    ),
    extra_data String,            -- JSON额外数据
    watch_duration Int32,         -- 观看时长（秒）
    completion_rate Float32,      -- 完成率
    experiment_id String,         -- AB实验ID
    experiment_group String,      -- 实验分组
    timestamp DateTime64(3),      -- 时间戳（毫秒精度）
    date Date                     -- 日期分区字段
)
ENGINE = MergeTree()
PARTITION BY toYYYYMM(date)      -- 按月分区
ORDER BY (tenant_id, scenario_id, date, user_id, timestamp)
TTL date + INTERVAL 90 DAY       -- 保留90天
SETTINGS index_granularity = 8192;
```

### 2. 实时指标聚合表（物化视图）

```sql
-- 每小时指标聚合
CREATE MATERIALIZED VIEW IF NOT EXISTS metrics_hourly
ENGINE = SummingMergeTree()
PARTITION BY toYYYYMM(date)
ORDER BY (tenant_id, scenario_id, date, hour)
AS SELECT
    tenant_id,
    scenario_id,
    toDate(timestamp) AS date,
    toHour(timestamp) AS hour,
    countIf(action_type = 'impression') AS impressions,
    countIf(action_type = 'click') AS clicks,
    countIf(action_type = 'order') AS conversions,
    uniqExact(user_id) AS active_users,
    uniqExact(item_id) AS active_items
FROM user_behaviors
GROUP BY tenant_id, scenario_id, date, hour;
```

### 3. 物品统计表（物化视图）

```sql
CREATE MATERIALIZED VIEW IF NOT EXISTS item_stats_daily
ENGINE = SummingMergeTree()
PARTITION BY toYYYYMM(date)
ORDER BY (tenant_id, scenario_id, item_id, date)
AS SELECT
    tenant_id,
    scenario_id,
    item_id,
    toDate(timestamp) AS date,
    countIf(action_type = 'impression') AS impressions,
    countIf(action_type = 'click') AS clicks,
    countIf(action_type = 'order') AS conversions,
    sum(watch_duration) AS total_watch_duration,
    avg(completion_rate) AS avg_completion_rate
FROM user_behaviors
GROUP BY tenant_id, scenario_id, item_id, date;
```

---

## API查询示例

### 1. 获取仪表板数据

```sql
-- 查询最近24小时的核心指标
SELECT
    sum(impressions) AS total_recommendations,
    sum(clicks) AS total_clicks,
    (sum(clicks) * 100.0 / sum(impressions)) AS ctr,
    sum(conversions) AS total_conversions,
    (sum(conversions) * 100.0 / sum(impressions)) AS conversion_rate,
    uniqExact(active_users) AS active_users
FROM metrics_hourly
WHERE tenant_id = '{tenant_id}'
  AND scenario_id = '{scenario_id}'
  AND date >= today() - 1
  AND hour >= toHour(now()) - 24;
```

### 2. 获取趋势数据

```sql
-- 查询最近7天每小时的趋势
SELECT
    toStartOfHour(timestamp) AS hour,
    countIf(action_type = 'impression') AS impressions,
    countIf(action_type = 'click') AS clicks,
    (countIf(action_type = 'click') * 100.0 / countIf(action_type = 'impression')) AS ctr
FROM user_behaviors
WHERE tenant_id = '{tenant_id}'
  AND scenario_id = '{scenario_id}'
  AND timestamp >= now() - INTERVAL 7 DAY
GROUP BY hour
ORDER BY hour;
```

### 3. 获取热门物品Top 10

```sql
SELECT
    item_id,
    sum(impressions) AS total_impressions,
    sum(clicks) AS total_clicks,
    (sum(clicks) * 100.0 / sum(impressions)) AS ctr
FROM item_stats_daily
WHERE tenant_id = '{tenant_id}'
  AND scenario_id = '{scenario_id}'
  AND date >= today() - 7
GROUP BY item_id
ORDER BY total_clicks DESC
LIMIT 10;
```

### 4. 获取用户行为漏斗

```sql
SELECT
    action_type,
    count() AS users,
    (count() * 100.0 / (SELECT count(DISTINCT user_id) FROM user_behaviors WHERE tenant_id = '{tenant_id}' AND date = today())) AS rate
FROM user_behaviors
WHERE tenant_id = '{tenant_id}'
  AND date = today()
GROUP BY action_type
ORDER BY action_type;
```

---

## Python服务修改

### analytics/service.py 修改方案

```python
from clickhouse_driver import Client

class AnalyticsService:
    def __init__(self, db: AsyncIOMotorDatabase, clickhouse_client: Client):
        self.db = db
        self.ch = clickhouse_client  # ClickHouse客户端
    
    async def get_dashboard_data(
        self,
        tenant_id: str,
        scenario_id: Optional[str] = None,
        start_time: Optional[datetime] = None,
        end_time: Optional[datetime] = None
    ) -> Dict[str, Any]:
        """从ClickHouse查询仪表板数据"""
        query = """
        SELECT
            sum(impressions) AS total_recommendations,
            sum(clicks) AS total_clicks,
            (sum(clicks) * 100.0 / sum(impressions)) AS ctr,
            sum(conversions) AS total_conversions,
            (sum(conversions) * 100.0 / sum(impressions)) AS conversion_rate,
            uniqExact(active_users) AS active_users
        FROM metrics_hourly
        WHERE tenant_id = %(tenant_id)s
          AND date >= %(start_date)s
          AND date <= %(end_date)s
        """
        
        if scenario_id:
            query += " AND scenario_id = %(scenario_id)s"
        
        params = {
            'tenant_id': tenant_id,
            'scenario_id': scenario_id,
            'start_date': (start_time or datetime.now() - timedelta(days=7)).date(),
            'end_date': (end_time or datetime.now()).date(),
        }
        
        result = self.ch.execute(query, params)
        
        if not result:
            return self._empty_dashboard_data()
        
        row = result[0]
        return {
            "overview": {
                "total_recommendations": int(row[0] or 0),
                "total_clicks": int(row[1] or 0),
                "ctr": float(row[2] or 0),
                "total_conversions": int(row[3] or 0),
                "conversion_rate": float(row[4] or 0),
                "active_users": int(row[5] or 0),
                # 配置数据从MongoDB获取
                "total_items": await self.items_collection.count_documents({"tenant_id": tenant_id}),
                "active_scenarios": await self.scenarios_collection.count_documents({"tenant_id": tenant_id, "status": "active"}),
            },
            "data_source": "clickhouse"
        }
```

---

## 前端修改

### 1. 修复剩余的硬编码图表

```typescript
// 推荐效果指标图 - 使用API数据
const effectMetricsOption = computed(() => {
  const ctrTrend = trendData.value?.trends?.find((t: any) => t.metric_name === 'ctr');
  const conversionTrend = trendData.value?.trends?.find((t: any) => t.metric_name === 'conversions');
  
  const timePoints = ctrTrend?.points?.map((p: any) => {
    const date = new Date(p.timestamp.seconds * 1000);
    return ['周日', '周一', '周二', '周三', '周四', '周五', '周六'][date.getDay()];
  }) || ['周一', '周二', '周三', '周四', '周五', '周六', '周日'];
  
  const ctrData = ctrTrend?.points?.map((p: any) => p.value) || [0, 0, 0, 0, 0, 0, 0];
  const conversionData = conversionTrend?.points?.map((p: any) => p.value / 1000) || [0, 0, 0, 0, 0, 0, 0];
  
  return {
    // ... ECharts配置
    xAxis: { data: timePoints },
    series: [
      { name: '点击率', data: ctrData },
      { name: '转化率', data: conversionData },
    ],
  };
});

// 热门物品图 - 使用API数据
const topItemsOption = computed(() => {
  const distribution = distributionData.value?.distribution || [];
  
  // 假设后端返回热门物品数据
  const items = distribution.slice(0, 10).reverse(); // Top 10并倒序
  const itemNames = items.map((item: any) => item.label);
  const itemCounts = items.map((item: any) => item.count);
  
  return {
    // ... ECharts配置
    yAxis: { data: itemNames.length > 0 ? itemNames : ['暂无数据'] },
    series: [{ data: itemCounts.length > 0 ? itemCounts : [0] }],
  };
});
```

---

## 实施步骤

### 第一阶段：基础架构（1-2周）

1. ✅ **部署ClickHouse**
   ```bash
   docker run -d --name clickhouse-server \
     -p 8123:8123 -p 9000:9000 \
     --ulimit nofile=262144:262144 \
     yandex/clickhouse-server
   ```

2. ✅ **创建ClickHouse表**
   - 执行上面的DDL语句
   - 创建物化视图

3. ✅ **修改behavior-service**
   - 保持MongoDB写入（配置数据）
   - 增加Kafka生产者

4. ✅ **Python服务添加ClickHouse依赖**
   ```bash
   pip install clickhouse-driver
   ```

### 第二阶段：Flink实时计算（2-3周）

1. ✅ **部署Kafka**
   - 使用KRaft模式（无需Zookeeper）
   
2. ✅ **部署Flink**
   - Flink Job: Kafka → ClickHouse
   - Flink Job: 实时指标聚合 → Redis

3. ✅ **开发Flink作业**
   - ItemHotScoreCalculator
   - RealtimeMetricsAggregator
   - ClickHouseSink

### 第三阶段：前端对接（1周）

1. ✅ **修复剩余硬编码图表**
2. ✅ **添加数据刷新机制**
3. ✅ **错误处理和加载状态**

### 第四阶段：前端埋点（1周）

1. ✅ **前端SDK开发**
   ```typescript
   // tracker.ts
   class RecommendationTracker {
     track(event: {
       action: 'impression' | 'click' | 'view';
       itemId: string;
       userId: string;
       tenantId: string;
       scenarioId: string;
     }) {
       fetch('/api/v1/behaviors', {
         method: 'POST',
         body: JSON.stringify(event),
       });
     }
   }
   ```

2. ✅ **页面集成埋点**
   - 推荐结果曝光埋点
   - 点击埋点
   - 页面停留时长

---

## 成本评估

| 组件 | 规格 | 成本 | 备注 |
|-----|------|------|------|
| ClickHouse | 2C4G | ¥200/月 | 初期足够 |
| Kafka | 2C4G | ¥200/月 | 3个broker |
| Flink | 2C4G | ¥200/月 | TaskManager |
| **总计** | | **¥600/月** | |

---

## 常见问题

### Q1: 为什么不用MongoDB做行为分析？
A: MongoDB不适合大规模OLAP查询，亿级数据聚合性能差。ClickHouse是专为OLAP设计的列式存储，查询速度快100倍+。

### Q2: 可以不用Flink吗？
A: 可以，初期可以用Python脚本 + Celery定时任务。但Flink提供：
- 精确一次语义
- 实时性更好（秒级）
- 状态管理
- 反压机制

### Q3: ClickHouse能处理多大数据量？
A: 单表百亿行没问题，配合分区和物化视图，查询毫秒级响应。

### Q4: 行为数据保留多久？
A: 建议：
- ClickHouse原始数据：90天
- 聚合表：永久保留
- MongoDB：7天（仅用于配置和最近查询）

---

## 技术选型对比

| 需求 | MongoDB | ClickHouse | Redis | 选型结果 |
|-----|---------|-----------|-------|---------|
| 配置数据 | ✅ 灵活Schema | ❌ | ❌ | MongoDB |
| 行为日志 | ⚠️ 查询慢 | ✅ OLAP专用 | ❌ | ClickHouse |
| 实时热度 | ❌ | ❌ | ✅ 快速读写 | Redis |
| 趋势分析 | ❌ 不支持 | ✅ 时序查询 | ❌ | ClickHouse |
| 用户画像 | ✅ 文档存储 | ❌ | ✅ 缓存 | MongoDB + Redis |

---

## 总结

### 当前问题
- ✅ behavior-service已存在，可直接使用
- ❌ 缺少ClickHouse（需要新增）
- ❌ 缺少Kafka+Flink（需要新增）
- ❌ 前端有硬编码数据（需要修复）

### 核心改动
1. **新增ClickHouse** - 存储海量行为数据
2. **behavior-service增加Kafka发送** - 实时数据流
3. **新增Flink作业** - 实时计算和数据同步
4. **修改AnalyticsService** - 从ClickHouse查询
5. **修复前端硬编码** - 全部使用API数据

### 投入产出
- 开发时间：4-6周
- 运维成本：¥600/月
- 价值：完整的数据分析能力，支持亿级行为数据分析

