# Worker/Beat/Consumer 服务依赖检查报告

## 📊 检查概览

| 服务 | 代码状态 | 依赖组件 | Docker 部署状态 | 问题 |
|------|---------|---------|----------------|------|
| Celery Worker | ✅ 正常 | Redis, MongoDB, Kafka, Milvus | ✅ 已部署 | ⚠️ 缺 redbeat |
| Celery Beat | ✅ 正常 | Redis | ✅ 已部署 | ❌ 缺 redbeat 库 |
| Kafka Consumer | ✅ 正常 | Kafka, MongoDB | ✅ 已部署 | ✅ 无问题 |

---

## 🔍 详细分析

### 1️⃣ Celery Worker 服务

#### 代码检查 ✅
**文件**: `app/tasks/celery_app.py`, `app/tasks/*_tasks.py`

**依赖组件**：
- ✅ **Redis**（Broker + Backend）
  - Broker: `redis://:redis_password_2024@111.228.39.41:6379/1`
  - Backend: `redis://:redis_password_2024@111.228.39.41:6379/2`
  - Docker 部署：✅ 已部署（端口 6379）

- ✅ **MongoDB**（数据存储）
  - 连接：`mongodb://admin:password@111.228.39.41:27017`
  - Docker 部署：✅ 已部署（端口 27017）

- ✅ **Kafka**（消息队列）
  - 连接：`111.228.39.41:9092`
  - Docker 部署：✅ 已部署（端口 9092）

- ⚠️ **Milvus**（向量数据库，可选）
  - 连接：`111.228.39.41:19530`
  - Docker 部署：✅ 已部署（端口 19530）
  - 使用场景：物品向量生成任务

**执行的任务**：
1. 模型训练（`model_tasks.py`）- 每天凌晨3点
2. 物品相似度计算（`item_tasks.py`）- 每小时
3. 物品向量生成（`item_tasks.py`）
4. 用户画像更新（`user_tasks.py`）- 每2小时
5. 推荐预计算（`recommendation_tasks.py`）- 每4小时
6. 缓存清理（`recommendation_tasks.py`）- 每天凌晨4点

**问题**：✅ 代码无问题，依赖组件已全部部署

---

### 2️⃣ Celery Beat 服务

#### 代码检查 ✅
**文件**: `app/tasks/celery_app.py`

**依赖组件**：
- ✅ **Redis**（Broker + 调度状态存储）
  - Broker: `redis://:redis_password_2024@111.228.39.41:6379/1`
  - Backend: `redis://:redis_password_2024@111.228.39.41:6379/2`
  - Docker 部署：✅ 已部署

**调度器配置**：
```yaml
command:
  - "celery"
  - "-A"
  - "app.tasks.celery_app"
  - "beat"
  - "--scheduler"
  - "redbeat.RedBeatScheduler"  # ❌ 使用了 RedBeat，但未安装
```

**定时任务清单**：
1. `compute-item-similarity-hourly` - 每小时
2. `update-user-profiles-2hours` - 每2小时
3. `train-model-daily` - 每天凌晨3点
4. `precompute-recommendations-4hours` - 每4小时
5. `cleanup-expired-cache-daily` - 每天凌晨4点

**问题**：❌ **严重问题**
- K8s 配置中使用了 `redbeat.RedBeatScheduler`
- 但 `pyproject.toml` 中**没有安装 redbeat 库**
- 启动时会报错：`ModuleNotFoundError: No module named 'redbeat'`

**解决方案**：
```toml
# pyproject.toml 中添加
celery-redbeat = "^2.2.0"
```

或者，不使用 RedBeat，改用默认调度器（但 Pod 重启会丢失调度状态）：
```yaml
# 简化版（使用默认调度器）
command: ["celery", "-A", "app.tasks.celery_app", "beat", "-l", "info"]
```

---

### 3️⃣ Kafka Consumer 服务

#### 代码检查 ✅
**文件**: `app/services/item/kafka_consumer.py`

**依赖组件**：
- ✅ **Kafka**（消息队列）
  - 连接：`111.228.39.41:9092`
  - Topics: `settings.kafka_item_ingest_topics` (默认: items-ingest, vlog-items, news-items)
  - Consumer Group: `lemo-recommender-group`
  - Docker 部署：✅ 已部署

- ✅ **MongoDB**（物品数据存储）
  - 连接：`mongodb://admin:password@111.228.39.41:27017`
  - Docker 部署：✅ 已部署

**功能**：
1. 消费 Kafka 物品事件
2. 写入 MongoDB
3. 触发物品向量生成（调用 Celery 任务）

**问题**：✅ 无问题，所有依赖已部署

---

## 🚨 缺失的依赖组件

### ❌ ClickHouse（可选，但强烈推荐）

**用途**：
- 行为数据 OLAP 分析
- 推荐指标统计（CTR、转化率等）
- 数据分析页面数据源

**当前状态**：
- Docker Compose：❌ 未部署
- 代码依赖：⚠️ 已引用但降级处理

**影响**：
- 数据分析页面无法显示真实数据
- Flink Jobs 无法将行为数据写入 ClickHouse

**是否必须**：
- 短期：❌ 不必须（可用 MongoDB 替代，性能较差）
- 长期：✅ 强烈推荐（行为数据量大时必须）

**Docker 部署命令**：
```yaml
# 添加到 docker-compose.yml
clickhouse:
  image: clickhouse/clickhouse-server:24.1
  container_name: lemo-clickhouse
  ports:
    - "8123:8123"  # HTTP
    - "9000:9000"  # Native
  environment:
    CLICKHOUSE_USER: default
    CLICKHOUSE_PASSWORD: clickhouse_2024
  volumes:
    - clickhouse_data:/var/lib/clickhouse
  networks:
    - lemo-network
```

---

## 📋 Python 依赖修复

### 必须添加的依赖

```toml
# pyproject.toml

[tool.poetry.dependencies]
# Celery Beat 调度器（必须！）
celery-redbeat = "^2.2.0"
```

### 可选添加的依赖

```toml
# ClickHouse 客户端（如果部署 ClickHouse）
clickhouse-driver = "^0.2.7"

# Flink 相关（如果使用 Flink）
apache-flink = "^1.18.0"  # 可选，独立部署时不需要
```

---

## ✅ Docker Compose 完整性检查

### 已部署的服务 ✅

| 服务 | 镜像 | 端口 | 状态 | Worker/Beat/Consumer 依赖 |
|------|------|------|------|-------------------------|
| MongoDB | mongo:7.0 | 27017 | ✅ | ✅✅✅ Worker + Consumer |
| Redis | redis:7.2-alpine | 6379 | ✅ | ✅✅✅ Worker + Beat |
| Kafka | apache/kafka:3.8.1 | 9092 | ✅ | ✅✅✅ Worker + Consumer |
| Milvus | milvusdb/milvus:v2.4.1 | 19530 | ✅ | ✅ Worker（向量任务）|
| Etcd | quay.io/coreos/etcd:v3.5.5 | 2379 | ✅ | Milvus 依赖 |
| MinIO | minio/minio | 9000 | ✅ | Milvus 依赖 |
| Prometheus | prom/prometheus | 9090 | ✅ | 监控（可选）|
| Grafana | grafana/grafana | 3000 | ✅ | 监控（可选）|

### 缺失的服务 ❌

| 服务 | 状态 | 影响 | 优先级 |
|------|------|------|--------|
| ClickHouse | ❌ 未部署 | 数据分析不可用 | ⭐⭐⭐ 高 |

---

## 🔧 修复建议

### 优先级 1：修复 Beat 服务（必须）⭐⭐⭐⭐⭐

**问题**：Beat 使用了未安装的 `redbeat` 库

**方案 A（推荐）**：安装 redbeat
```bash
# 1. 更新 pyproject.toml
poetry add celery-redbeat

# 2. 重新构建镜像
docker build -t lemo-service-recommender:latest .

# 3. 推送镜像
docker push registry.cn-beijing.aliyuncs.com/lemo_zls/lemo-service-recommender:latest
```

**方案 B（临时）**：不使用 RedBeat，改用默认调度器
```yaml
# k8s-deployment-beat.yaml
command: ["celery", "-A", "app.tasks.celery_app", "beat", "-l", "info"]
# 移除 --scheduler redbeat.RedBeatScheduler
```

**注意**：方案 B 会导致 Pod 重启后丢失调度状态（任务可能重复执行）

---

### 优先级 2：部署 ClickHouse（推荐）⭐⭐⭐

**步骤**：

1. **更新 docker-compose.yml**
```yaml
# 添加 ClickHouse 服务
clickhouse:
  image: clickhouse/clickhouse-server:24.1
  container_name: lemo-clickhouse
  ports:
    - "8123:8123"  # HTTP
    - "9000:9000"  # Native
  environment:
    CLICKHOUSE_USER: default
    CLICKHOUSE_PASSWORD: clickhouse_2024
  volumes:
    - clickhouse_data:/var/lib/clickhouse
  ulimits:
    nofile:
      soft: 262144
      hard: 262144
  networks:
    - lemo-network
  healthcheck:
    test: ["CMD", "clickhouse-client", "--query", "SELECT 1"]
    interval: 30s
    timeout: 10s
    retries: 3

# 添加 volume
volumes:
  clickhouse_data:
```

2. **重新部署 Docker Compose**
```bash
# SSH 到服务器 111.228.39.41
docker-compose up -d clickhouse
```

3. **添加 Python 依赖**
```bash
poetry add clickhouse-driver
```

4. **创建 ClickHouse 表**（参考 `docs/数据分析架构方案.md`）

---

### 优先级 3：验证服务连接

**验证脚本**：
```python
# scripts/check_dependencies.py
import redis
from pymongo import MongoClient
from kafka import KafkaProducer

# 检查 Redis
try:
    r = redis.Redis.from_url("redis://:redis_password_2024@111.228.39.41:6379/1")
    r.ping()
    print("✅ Redis 连接成功")
except Exception as e:
    print(f"❌ Redis 连接失败: {e}")

# 检查 MongoDB
try:
    client = MongoClient("mongodb://admin:password@111.228.39.41:27017")
    client.admin.command("ping")
    print("✅ MongoDB 连接成功")
except Exception as e:
    print(f"❌ MongoDB 连接失败: {e}")

# 检查 Kafka
try:
    producer = KafkaProducer(bootstrap_servers="111.228.39.41:9092")
    producer.close()
    print("✅ Kafka 连接成功")
except Exception as e:
    print(f"❌ Kafka 连接失败: {e}")
```

---

## 📝 总结

### Worker 服务
- ✅ 代码无问题
- ✅ 所有依赖已部署
- ✅ 可以直接启动

### Beat 服务
- ✅ 代码无问题
- ❌ **缺少 redbeat 库**（必须修复）
- ⚠️ 需要选择：安装 redbeat 或使用默认调度器

### Consumer 服务
- ✅ 代码无问题
- ✅ 所有依赖已部署
- ✅ 可以直接启动

### 可选组件
- ⚠️ ClickHouse - 强烈推荐部署（数据分析必需）
- ⚠️ Flink - 可选（实时处理，可用 Celery 定时聚合替代）

---

## 🚀 快速修复行动计划

### 立即执行（必须）

```bash
# 1. 添加 redbeat 依赖
cd /Users/edy/PycharmProjects/lemo_recommender
poetry add celery-redbeat

# 2. 重新构建镜像（本地 Mac）
docker buildx build --platform linux/amd64 -t registry.cn-beijing.aliyuncs.com/lemo_zls/lemo-service-recommender:$(date +%Y-%m-%d-%H-%M-%S) .

# 3. 推送镜像
# (通过 deploy-all-services.sh 自动处理)

# 4. 部署所有服务
./k8s-deploy/deploy-all-services.sh
```

### 后续执行（推荐）

```bash
# SSH 到服务器 111.228.39.41
ssh user@111.228.39.41

# 在 docker-compose.yml 中添加 ClickHouse
vim docker-compose.yml
# (添加上面的 ClickHouse 配置)

# 部署 ClickHouse
docker-compose up -d clickhouse

# 验证部署
docker ps | grep clickhouse
```

---

## 📞 相关文档

- [K8s 部署指南](../k8s-deploy/README.md)
- [数据分析架构方案](./数据分析架构方案.md)
- [服务拆分方案](./服务拆分方案.md)

