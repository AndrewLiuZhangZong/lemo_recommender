# 多场景SaaS推荐系统 - 系统设计文档

## 目录
- [1. 技术栈](#1-技术栈)
- [2. 系统架构](#2-系统架构)
- [3. 数据模型](#3-数据模型)
- [4. 场景配置](#4-场景配置)
- [5. 服务对接](#5-服务对接)

---

# 1. 技术栈

## 1.1 后端核心框架

### Web框架
- **FastAPI**
  - 高性能异步框架
  - 自动生成API文档 (OpenAPI/Swagger)
  - 类型提示支持，便于维护
  - 支持依赖注入

### 推荐算法库
- **scikit-learn**: 经典机器学习算法
- **LightGBM/XGBoost**: 梯度提升模型
- **TensorFlow/PyTorch**: 深度学习模型
- **Surprise**: 协同过滤算法库
- **Implicit**: 隐式反馈推荐算法
- **Faiss**: Facebook的向量相似度搜索库（高性能）

### 特征工程
- **Pandas**: 数据处理
- **NumPy**: 数值计算
- **scipy**: 科学计算

## 1.2 数据存储

### 文档数据库
- **MongoDB**
  - 存储所有业务数据（场景配置、物品、用户画像、行为日志）
  - 灵活Schema，适合多场景的异构数据
  - 支持水平扩展（分片）
  - 4.0+版本支持ACID事务

**为什么选MongoDB而不是PostgreSQL？**
1. 租户/用户数据由外部服务管理，无需关系型约束
2. 场景配置、物品元数据Schema灵活多变，适合文档存储
3. 简化架构，降低维护成本

### 缓存层
- **Redis**
  - 热数据缓存（用户画像、热门物品）
  - 实时推荐结果缓存
  - 分布式锁
  - 计数器（曝光、点击等）

### 向量数据库
- **Milvus** 或 **Weaviate**
  - 存储物品和用户的向量表示
  - 高效相似度检索

## 1.3 消息队列与流处理

### 消息队列
- **Apache Kafka**
  - 处理实时行为数据流
  - 高吞吐量、低延迟
  - 解耦服务模块
  - 持久化消息存储

### 流处理
- **Apache Flink**
  - 实时特征计算
  - 实时数据聚合
  - 复杂事件处理（CEP）
  - 支持精确一次语义（Exactly-Once）

## 1.4 任务调度

- **Celery** + **Redis**
  - 模型训练任务
  - 批量推荐预计算
  - 定时数据同步
  - 异步任务处理

## 1.5 监控与运维

### 监控
- **Prometheus** + **Grafana**
  - 系统性能监控
  - 业务指标监控
  - 推荐效果监控

### 日志
- **ELK Stack**（可选）
  - 日志收集与分析

### 链路追踪
- **Jaeger** 或 **Zipkin**
  - 分布式追踪
  - 性能分析

## 1.6 容器化

- **Docker**: 服务容器化
- **Docker Compose**: 本地开发环境
- **Kubernetes**: 生产环境编排（可选）

## 1.7 技术栈分阶段实施

### 第一阶段（MVP）
- FastAPI + MongoDB + Redis + Celery
- Docker + Docker Compose
- 基础推荐算法（协同过滤、内容推荐）
- 与网关/租户服务对接

### 第二阶段（扩展）
- Milvus（向量检索）
- Kafka + Flink（实时数据流处理）
- 深度学习模型
- gRPC服务间通信

### 第三阶段（完善）
- Kubernetes
- 完整监控体系
- AB测试平台
- 管理后台

---

# 2. 系统架构

## 2.1 整体架构

```
┌─────────────────────────────────────────────────────────────┐
│                    外部服务（已有）                           │
│  ┌──────────────────┐  ┌──────────────────┐                │
│  │  API网关服务      │  │  租户/用户服务    │                │
│  │  (Golang+Kratos) │  │  (Golang+Kratos) │                │
│  │  • 鉴权           │  │  • 租户管理       │                │
│  │  • 限流           │  │  • 用户管理       │                │
│  │  • 路由           │  │  • 权限控制       │                │
│  └──────────────────┘  └──────────────────┘                │
└─────────────────────────────────────────────────────────────┘
                              ▼
┌─────────────────────────────────────────────────────────────┐
│                    推荐系统（本项目）                         │
│                                                               │
│  ┌────────────────────  应用服务层  ──────────────────────┐  │
│  │  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐ │  │
│  │  │  场景管理服务  │  │  物品管理服务  │  │  行为采集服务  │ │  │
│  │  └──────────────┘  └──────────────┘  └──────────────┘ │  │
│  │  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐ │  │
│  │  │  推荐服务     │  │  特征服务     │  │  模型服务     │ │  │
│  │  └──────────────┘  └──────────────┘  └──────────────┘ │  │
│  │  ┌──────────────┐                                      │  │
│  │  │  实验服务     │                                      │  │
│  │  └──────────────┘                                      │  │
│  └──────────────────────────────────────────────────────────┘  │
│                              ▼                                  │
│  ┌────────────────────  推荐引擎层  ──────────────────────┐  │
│  │  ┌────────────┐  ┌────────────┐  ┌────────────┐      │  │
│  │  │  召回层     │  │  排序层     │  │  重排层     │      │  │
│  │  │            │  │            │  │            │      │  │
│  │  │ • 协同过滤  │  │ • LightGBM │  │ • 多样性   │      │  │
│  │  │ • 向量召回  │  │ • DeepFM   │  │ • 业务规则 │      │  │
│  │  │ • 热门召回  │  │ • Wide&Deep│  │ • AB测试   │      │  │
│  │  └────────────┘  └────────────┘  └────────────┘      │  │
│  └──────────────────────────────────────────────────────────┘  │
└─────────────────────────────────────────────────────────────┘
                              ▼
┌─────────────────────────────────────────────────────────────┐
│                        数据层 ⭐ v2.0架构                      │
├─────────────────────────────────────────────────────────────┤
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐      │
│  │   MongoDB    │  │  ClickHouse  │  │    Redis     │      │
│  │  (配置数据)  │  │  (行为数据)  │  │   (缓存)     │      │
│  ├──────────────┤  ├──────────────┤  ├──────────────┤      │
│  │• 场景配置    │  │• 用户行为    │  │• 热门物品    │      │
│  │• 物品元数据  │  │• 曝光点击    │  │• 实时指标    │      │
│  │• 模型配置    │  │• 转化数据    │  │• 用户画像    │      │
│  │• 实验配置    │  │• 时序分析    │  │• 推荐缓存    │      │
│  │• 用户画像    │  │• OLAP查询    │  │              │      │
│  └──────────────┘  └──────────────┘  └──────────────┘      │
│                                                              │
│  ┌──────────┐                                               │
│  │  Milvus  │   (可选：向量检索)                            │
│  │  (向量)  │                                               │
│  └──────────┘                                               │
└─────────────────────────────────────────────────────────────┘
                              ▼
┌─────────────────────────────────────────────────────────────┐
│                     实时计算层                                │
│  ┌──────────────────────────────────────────────────┐       │
│  │              Kafka 消息队列                       │       │
│  │  Topic: user-behaviors-{tenant_id} 🔒             │       │
│  │  ┌──────────────────────────────────────┐        │       │
│  │  │ 行为事件流（按租户隔离）              │        │       │
│  │  │ • impression, click, view            │        │       │
│  │  │ • play, read, learn                  │        │       │
│  │  │ • like, share, comment               │        │       │
│  │  │ • add_cart, order, payment           │        │       │
│  │  └──────────────────────────────────────┘        │       │
│  └──────────────────────────────────────────────────┘       │
│                          ▼                                   │
│  ┌──────────────────────────────────────────────────┐       │
│  │           Flink 流处理引擎                        │       │
│  │  Job1: ClickHouseSink (Kafka → ClickHouse)       │       │
│  │  Job2: 实时物品热度 (→ Redis ZSET)               │       │
│  │  Job3: 实时指标聚合 (→ Redis HASH)               │       │
│  │  Job4: 用户画像更新 (→ MongoDB)                  │       │
│  └──────────────────────────────────────────────────┘       │
│                          ▼                                   │
│         写入 ClickHouse(主) / Redis(缓存) / MongoDB(画像)    │
└─────────────────────────────────────────────────────────────┘
                              ▼
┌─────────────────────────────────────────────────────────────┐
│                     离线计算层                                │
│  ┌─────────────────┐         ┌─────────────────┐           │
│  │   Celery任务队列 │  ──────▶ │  离线计算       │           │
│  │  • 模型训练      │         │  • 相似度计算   │           │
│  │  • 批量预计算    │         │  • 画像离线更新 │           │
│  └─────────────────┘         └─────────────────┘           │
└─────────────────────────────────────────────────────────────┘
```

## 2.2 微服务拆分（支持K8s独立部署）

### 服务列表（v2.0架构更新）

| 服务名称 | 端口 | 协议 | 职责 | 独立部署 | v2.0变更 |
|---------|------|------|------|---------|---------|
| scenario-service | 8001/9001 | HTTP + gRPC | 场景CRUD、配置管理 | ✅ | - |
| item-service | 8002/9002 | HTTP + gRPC | 物品CRUD、批量导入 | ✅ | - |
| **behavior-service** | **8003/9003** | **HTTP + gRPC** | **行为采集、Kafka发送** | ✅ | **⭐ 不写MongoDB** |
| recommendation-service | 8004 | HTTP | 推荐接口、流程编排 | ✅ | - |
| feature-service | 9005 | gRPC | 特征提取、特征服务 | ✅ | - |
| model-service | 9006 | gRPC | 模型加载、在线预测 | ✅ | - |
| **analytics-service** | **9007** | **gRPC** | **数据分析查询** | ✅ | **⭐ 新增（ClickHouse查询）** |

**behavior-service v2.0变更：**
- ✅ 强制tenant_id验证（SaaS隔离）
- ✅ 直接发送到Kafka（不写MongoDB）
- ✅ 支持HTTP和gRPC双协议
- ✅ 批量采集支持（高吞吐）
- ✅ 异步非阻塞（不影响性能）

**analytics-service（新增）：**
- ✅ 从ClickHouse查询行为数据
- ✅ 仪表板、趋势、分布、漏斗分析
- ✅ 支持多租户数据隔离
- ✅ 聚合查询优化（物化视图）

### 服务间调用方式

**对外API（客户端）**: HTTP REST API
- scenario-service, item-service, behavior-service, recommendation-service

**内部调用（服务间）**: gRPC
- recommendation-service → feature-service/model-service
- 优势：高性能、强类型、内置负载均衡

**服务发现**: Kubernetes Service Discovery
- 开发环境：docker-compose DNS
- 生产环境：K8s Service名称

### 服务依赖关系

```
无依赖（可最先部署）:
├─ scenario-service
├─ item-service  
├─ behavior-service
├─ feature-service
└─ model-service

有依赖（最后部署）:
└─ recommendation-service
   ├─ depends: scenario-service (获取配置)
   ├─ depends: feature-service (特征提取)
   ├─ depends: model-service (模型预测)
   └─ depends: item-service (物品详情)
```

## 2.3 推荐流程

```
用户请求
   ↓
场景配置加载
   ↓
用户画像获取 (Redis/MongoDB)
   ↓
召回层（多路召回并行）
   ├─ 协同过滤召回
   ├─ 向量召回
   ├─ 热门召回（从Redis获取Flink实时计算的热度）
   └─ 场景特定召回
   ↓
候选集合并&去重
   ↓
特征提取
   ↓
排序层（模型打分）
   ↓
重排层（多样性、业务规则）
   ↓
AB测试分流
   ↓
结果缓存
   ↓
返回推荐结果
```

## 2.4 Kafka + Flink 实时计算架构

### Kafka Topics 设计（v2.0架构 - SaaS多租户隔离）

```
推荐系统的Kafka Topic规划：

1. user-behaviors-{tenant_id} 🔒 (核心Topic，按租户隔离)
   - 用户行为原始数据（所有埋点事件）
   - 命名规则：user-behaviors-{tenant_id}
     例如：user-behaviors-mymx
           user-behaviors-tenant_abc
   - 分区数：12-24（根据租户流量）
   - 保留时间：7天
   - Key: user_id（保证同一用户事件有序）
   - Value: JSON格式埋点数据
   - SaaS隔离：每个租户独立Topic，防止数据混淆
   
2. user-profile-updates
   - 用户画像更新事件（Flink计算产出）
   - 写入MongoDB user_profiles
   
3. item-stats-updates
   - 物品统计更新事件（Flink计算产出）
   - 实时热度、点击率等
   - 写入Redis ZSET (hot:items:{tenant_id}:{scenario_id})
   
4. recommendation-metrics
   - 推荐系统指标（Flink计算产出）
   - CTR、曝光、点击等
   - 写入Redis HASH (metrics:realtime:{tenant_id}:{scenario_id})
```

**SaaS租户隔离策略：**
- ✅ Topic按tenant_id隔离（user-behaviors-{tenant_id}）
- ✅ behavior-service强制验证tenant_id，无tenant_id拒绝
- ✅ Flink消费时按tenant_id分组处理
- ✅ ClickHouse存储时按tenant_id分区
- ✅ 防止租户间数据泄露和混淆

### Flink 任务设计（v2.0架构 - ClickHouse优先）

#### 1. ClickHouseSink（核心，最高优先级）⭐
```
Kafka (user-behaviors-{tenant_id})
   → Flink Job: ClickHouseSink
   → 批量消费（每1000条或5秒）
   → 数据清洗和验证
   → 批量写入 ClickHouse (user_behaviors表)
   → 物化视图自动聚合（metrics_hourly, item_stats_daily）
   
作用：行为数据持久化到ClickHouse（主存储）
性能：批量写入，吞吐量10万TPS+
```

#### 2. 用户画像实时更新
```
Kafka (user-behaviors-{tenant_id})
   → Flink Job: UserProfileAggregator
   → 按 tenant_id + user_id 分组
   → 时间窗口聚合（5分钟滚动窗口）
   → 计算：观看次数、偏好分类、活跃时段
   → 输出到 Kafka (user-profile-updates)
   → 异步写入 MongoDB (user_profiles)
   
作用：实时更新用户画像，用于推荐算法
存储：MongoDB（文档型，灵活Schema）
```

#### 3. 物品热度实时计算
```
Kafka (user-behaviors-{tenant_id})
   → Flink Job: ItemHotScoreCalculator
   → 按 tenant_id + item_id 分组
   → 时间窗口聚合（1小时滑动窗口）
   → 计算：浏览量、点击量、时间衰减热度
   → 输出到 Redis ZSET (hot:items:{tenant_id}:{scenario_id})
   
作用：实时热度榜单，用于热门召回
存储：Redis（内存，低延迟）
TTL：24小时
```

#### 4. 实时指标统计
```
Kafka (user-behaviors-{tenant_id})
   → Flink Job: RecommendationMetrics
   → 按 tenant_id + scenario_id + experiment_id 分组
   → 计算：CTR、平均观看时长、转化率
   → 输出到 Redis HASH (metrics:realtime:{tenant_id}:{scenario_id})
   → 可选：输出到 Prometheus (通过Pushgateway)
   
作用：实时指标监控，展示在数据分析页面
存储：Redis（快速读取）
TTL：1小时
```

### Flink 作业示例

```python
# 伪代码示例：用户画像实时更新
from pyflink.datastream import StreamExecutionEnvironment
from pyflink.datastream.window import TumblingProcessingTimeWindows
from pyflink.common import Time

env = StreamExecutionEnvironment.get_execution_environment()

# 从Kafka读取
behaviors = env.add_source(
    FlinkKafkaConsumer(
        topics=['user-behaviors'],
        deserialization_schema=JsonDeserializationSchema(),
        properties={'bootstrap.servers': 'kafka:9092'}
    )
)

# 处理逻辑
user_profiles = (
    behaviors
    .key_by(lambda x: (x['tenant_id'], x['user_id']))
    .window(TumblingProcessingTimeWindows.of(Time.minutes(5)))
    .aggregate(UserProfileAggregateFunction())
)

# 写入Sink
user_profiles.add_sink(
    FlinkKafkaSink(
        topic='user-profile-updates',
        serialization_schema=JsonSerializationSchema()
    )
)

env.execute("User Profile Real-time Updater")
```

### 数据流向（v2.0架构 - 简化版）

```
用户行为上报（前端埋点）
   ↓
FastAPI behavior-service (行为采集服务)
   ├─ 强制验证tenant_id（SaaS隔离）🔒
   ├─ 数据验证（必填字段、格式）
   └─ 直接发送到 Kafka ⭐ (不写MongoDB)
   
   ↓ Kafka (user-behaviors-{tenant_id})
   
Flink 消费 Kafka（4个并行Job）
   ├─ Job1: ClickHouseSink → ClickHouse (user_behaviors) ⭐ 主存储
   ├─ Job2: UserProfileAggregator → MongoDB (user_profiles)
   ├─ Job3: ItemHotScoreCalculator → Redis (hot:items:*)
   └─ Job4: RecommendationMetrics → Redis (metrics:realtime:*)
   
   ↓
数据读取（多个服务）
   ├─ AnalyticsService → ClickHouse查询（趋势、报表）
   ├─ RecommendationService → Redis读取（热度、实时指标）
   └─ FeatureService → MongoDB读取（用户画像）
```

**v1.0 vs v2.0对比：**
```
❌ v1.0（旧方案）：
   behavior-service → MongoDB + Kafka
                        ↓        ↓
                     数据重复    Flink → ClickHouse
                     
✅ v2.0（新方案）：
   behavior-service → Kafka → Flink → ClickHouse
                                ↓
                         单一行为数据源
                         
收益：
- 减少50%存储成本（不在MongoDB存行为）
- 降低系统复杂度（无双写逻辑）
- 提升性能（异步非阻塞）
- MongoDB专注配置数据，响应更快
```

---

# 3. 数据模型

## 3.1 MongoDB Collections（v2.0架构 - 仅存配置数据）

**⚠️ 重要变更：MongoDB不再存储行为数据（interactions），所有行为数据直接到ClickHouse**

### scenarios（场景配置）
```javascript
{
  _id: ObjectId,
  tenant_id: "tenant_123",
  scenario_id: "vlog_001",
  scenario_type: "vlog",
  name: "短视频推荐",
  config: {
    features: {...},
    recall: {...},
    rank: {...},
    rerank: {...}
  },
  status: "active",
  created_at: ISODate,
  updated_at: ISODate
}

// 索引
db.scenarios.createIndex({tenant_id: 1, scenario_id: 1}, {unique: true})
```

### items（物品元数据）
```javascript
{
  _id: ObjectId,
  tenant_id: "tenant_123",
  scenario_id: "vlog_001",
  item_id: "item_001",
  metadata: {
    title: "视频标题",
    duration: 120,
    category: "entertainment",
    tags: ["funny", "comedy"],
    // 场景特有字段...
  },
  embedding: [0.1, 0.2, ...],  // 可选
  status: "active",
  created_at: ISODate,
  updated_at: ISODate
}

// 索引
db.items.createIndex({tenant_id: 1, scenario_id: 1, item_id: 1}, {unique: true})
db.items.createIndex({"metadata.category": 1})
```

### user_profiles（用户画像）
```javascript
{
  _id: ObjectId,
  tenant_id: "tenant_123",
  user_id: "user_001",
  scenario_id: "vlog_001",
  features: {
    total_watch_count: 100,
    favorite_categories: ["entertainment"],
    // ...
  },
  preferences: {
    category_scores: {"entertainment": 0.8}
  },
  embedding: [0.1, 0.2, ...],
  updated_at: ISODate
}

// 索引
db.user_profiles.createIndex({tenant_id: 1, user_id: 1, scenario_id: 1}, {unique: true})
```

### ~~interactions（行为日志）~~ ❌ v2.0已废弃
**不再使用！所有行为数据存储到ClickHouse**

理由：
- ❌ MongoDB不适合大规模OLAP查询
- ❌ 行为数据增长快（亿级），MongoDB性能差
- ✅ ClickHouse专为OLAP设计，查询速度快100倍+
- ✅ 列式存储，压缩率高（节省10倍存储空间）

数据流：
```
旧方案（v1.0）：
behavior-service → MongoDB + Kafka → Flink → ClickHouse
                     ↓ 数据重复

新方案（v2.0）：
behavior-service → Kafka → Flink → ClickHouse
                              ↓ 单一数据源
```

### model_configs（模型配置）
```javascript
{
  _id: ObjectId,
  scenario_id: "vlog_001",
  model_type: "rank",
  model_name: "deepfm",
  model_version: "v1.0",
  model_path: "s3://models/deepfm_v1.0.pt",
  config: {...},
  metrics: {auc: 0.85},
  status: "active",
  created_at: ISODate
}
```

### experiments（AB实验）
```javascript
{
  _id: ObjectId,
  tenant_id: "tenant_123",
  scenario_id: "vlog_001",
  experiment_id: "exp_001",
  name: "测试新排序模型",
  groups: [
    {group_id: "control", traffic_ratio: 0.5, config: {...}},
    {group_id: "treatment", traffic_ratio: 0.5, config: {...}}
  ],
  status: "running",
  start_time: ISODate,
  end_time: ISODate
}
```

## 3.2 Redis数据结构

```
# 租户配置缓存
tenant:config:{tenant_id} → JSON (TTL: 1小时)

# 用户信息缓存
user:info:{tenant_id}:{user_id} → JSON (TTL: 30分钟)

# 用户画像缓存
user:profile:{tenant_id}:{user_id}:{scenario_id} → JSON (TTL: 1小时)

# 推荐结果缓存
recommend:{tenant_id}:{scenario_id}:{user_id}:{hash} → JSON (TTL: 10分钟)

# 场景配置缓存
scenario:config:{tenant_id}:{scenario_id} → JSON (TTL: 1小时)

# 热门物品
hot:items:{tenant_id}:{scenario_id} → ZSET (score=热度)

# 物品曝光去重
exposed:{tenant_id}:{user_id}:{scenario_id} → SET (TTL: 24小时)

# 实时计数
item:stats:{tenant_id}:{item_id} → HASH (view_count, like_count等)
```

---

# 4. 场景配置

## 4.1 配置化设计理念

**核心思想**：统一的推荐引擎框架 + 灵活的场景配置 = 支持多场景

```
┌─────────────────────────────┐
│   统一的推荐引擎（代码）      │
│   • 可插拔的召回策略         │
│   • 可配置的排序模型         │
│   • 可配置的重排规则         │
└──────────────┬──────────────┘
               │ 读取
               ▼
┌─────────────────────────────┐
│     场景配置（数据）          │
│   • vlog配置                 │
│   • 新闻配置                 │
│   • 电商配置                 │
└─────────────────────────────┘
```

## 4.2 场景配置结构

### Vlog场景示例
```json
{
  "scenario_id": "vlog_main_feed",
  "scenario_type": "vlog",
  "config": {
    "features": {
      "item_features": [
        {"name": "duration", "type": "numeric", "weight": 1.0},
        {"name": "completion_rate", "type": "numeric", "weight": 2.0},
        {"name": "category", "type": "categorical", "weight": 1.5}
      ],
      "user_features": [
        {"name": "age", "type": "categorical"},
        {"name": "favorite_categories", "type": "multi_categorical"}
      ]
    },
    "recall": {
      "strategies": [
        {"name": "user_cf", "weight": 0.25, "limit": 100},
        {"name": "vector_search", "weight": 0.3, "limit": 150},
        {"name": "hot_items", "weight": 0.2, "limit": 50}
      ]
    },
    "rank": {
      "model": "deepfm",
      "version": "v1.0",
      "objective": "watch_time"
    },
    "rerank": {
      "rules": [
        {"name": "diversity", "weight": 0.3},
        {"name": "freshness", "weight": 0.2, "params": {"decay_days": 7}}
      ]
    }
  }
}
```

### 新闻场景示例
```json
{
  "scenario_id": "news_main_feed",
  "scenario_type": "news",
  "config": {
    "features": {
      "item_features": [
        {"name": "publish_time", "type": "timestamp", "weight": 3.0},
        {"name": "hot_score", "type": "numeric", "weight": 2.5},
        {"name": "location", "type": "categorical", "weight": 1.5}
      ]
    },
    "recall": {
      "strategies": [
        {"name": "hot_news", "weight": 0.5, "limit": 200},
        {"name": "content_based", "weight": 0.3, "limit": 150},
        {"name": "user_cf", "weight": 0.2, "limit": 100}
      ]
    },
    "rank": {
      "model": "lightgbm",
      "version": "v2.0",
      "objective": "click_rate"
    },
    "rerank": {
      "rules": [
        {"name": "freshness", "weight": 0.5, "params": {"decay_hours": 6}},
        {"name": "location_match", "weight": 0.2}
      ]
    }
  }
}
```

## 4.3 配置如何驱动推荐

```python
async def recommend(tenant_id: str, user_id: str, scenario_id: str, count: int):
    # 1. 加载场景配置
    config = await load_scenario_config(tenant_id, scenario_id)
    
    # 2. 召回（根据配置）
    recall_results = []
    for strategy_config in config["recall"]["strategies"]:
        strategy = get_recall_strategy(strategy_config["name"])
        items = await strategy.recall(
            user_id=user_id,
            limit=strategy_config["limit"],
            params=strategy_config.get("params", {})
        )
        weighted_items = [(item, strategy_config["weight"]) for item in items]
        recall_results.extend(weighted_items)
    
    # 3. 排序（根据配置选择模型）
    rank_config = config["rank"]
    model = load_model(rank_config["model"], rank_config["version"])
    scores = model.predict(candidate_items)
    
    # 4. 重排（根据配置应用规则）
    for rule_config in config["rerank"]["rules"]:
        rule = get_rerank_rule(rule_config["name"])
        ranked_items = rule.apply(ranked_items, rule_config)
    
    return ranked_items[:count]
```

## 4.4 配置优势

✅ **无需改代码**：调整权重、新增特征只需改配置  
✅ **快速迭代**：配置变更立即生效  
✅ **AB测试友好**：不同实验组使用不同配置  
✅ **多租户定制**：同一套代码，不同租户不同配置

---

# 5. 服务对接

## 5.1 与API网关对接

### 请求头规范

网关转发请求时携带：

| Header | 必填 | 说明 | 示例 |
|--------|------|------|------|
| `X-Tenant-Id` | 是 | 租户ID | `tenant_123` |
| `X-User-Id` | 是 | 用户ID | `user_456` |
| `X-Request-Id` | 是 | 请求追踪ID | `req_001` |
| `Authorization` | 是 | Bearer Token | `Bearer xxx` |

### 推荐API示例

```http
POST /api/v1/recommend
X-Tenant-Id: tenant_123
X-User-Id: user_456
X-Request-Id: req_001
Authorization: Bearer xxx

{
  "scenario_id": "vlog_001",
  "count": 20,
  "context": {
    "device_type": "mobile"
  }
}
```

## 5.2 与租户/用户服务对接

### gRPC接口定义

#### 获取租户配置
```protobuf
service TenantService {
  rpc GetTenantConfig (GetTenantConfigRequest) returns (GetTenantConfigResponse);
}

message GetTenantConfigRequest {
  string tenant_id = 1;
}

message GetTenantConfigResponse {
  string tenant_id = 1;
  string tenant_name = 2;
  TenantQuota quota = 3;
  string status = 4;
}
```

#### 获取用户信息
```protobuf
service UserService {
  rpc GetUserInfo (GetUserInfoRequest) returns (GetUserInfoResponse);
}

message GetUserInfoRequest {
  string tenant_id = 1;
  string user_id = 2;
}

message GetUserInfoResponse {
  string user_id = 1;
  map<string, string> profile = 2;  // age, gender, location
  string status = 3;
}
```

### 调用示例

```python
# gRPC客户端
class TenantServiceClient:
    async def get_tenant_config(self, tenant_id: str):
        request = GetTenantConfigRequest(tenant_id=tenant_id)
        response = await self.stub.GetTenantConfig(request, timeout=5.0)
        return response

# 使用
tenant_config = await tenant_service.get_tenant_config("tenant_123")
user_info = await user_service.get_user_info("tenant_123", "user_456")
```

## 5.3 缓存策略

- **租户配置**：缓存1小时，从租户服务获取后缓存
- **用户信息**：缓存30分钟，LRU淘汰
- **场景配置**：缓存1小时，MongoDB读取后缓存

## 5.4 错误处理

- 外部服务不可用时使用缓存数据
- 超时设置3-5秒
- 自动重试1-2次（指数退避）

---

## 附录

### 相关文档
- [开发计划](./开发计划.md) - 详细的开发路线图和任务分解
- [K8s部署](../k8s/README.md) - Kubernetes部署配置和说明

### 关键技术决策
| 决策点 | 选型 | 理由 |
|-------|------|------|
| 数据库 | MongoDB | 灵活Schema，适合多场景异构数据 |
| 消息队列 | Kafka (KRaft) | 无需Zookeeper，简化架构 |
| 服务间调用 | gRPC | 高性能、强类型、内置负载均衡 |
| 场景实现 | 配置化 | 快速迭代，无需改代码 |
| 服务拆分 | 微服务 | 支持K8s独立部署和扩缩容 |

