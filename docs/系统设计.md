# 多场景SaaS推荐系统 - 系统设计文档

## 目录
- [1. 技术栈](#1-技术栈)
- [2. 系统架构](#2-系统架构)
- [3. 数据模型](#3-数据模型)
- [4. 场景配置](#4-场景配置)
- [5. 服务对接](#5-服务对接)

---

# 1. 技术栈

## 1.1 后端核心框架

### Web框架
- **FastAPI**
  - 高性能异步框架
  - 自动生成API文档 (OpenAPI/Swagger)
  - 类型提示支持，便于维护
  - 支持依赖注入

### 推荐算法库
- **scikit-learn**: 经典机器学习算法
- **LightGBM/XGBoost**: 梯度提升模型
- **TensorFlow/PyTorch**: 深度学习模型
- **Surprise**: 协同过滤算法库
- **Implicit**: 隐式反馈推荐算法
- **Faiss**: Facebook的向量相似度搜索库（高性能）

### 特征工程
- **Pandas**: 数据处理
- **NumPy**: 数值计算
- **scipy**: 科学计算

## 1.2 数据存储

### 文档数据库
- **MongoDB**
  - 存储所有业务数据（场景配置、物品、用户画像、行为日志）
  - 灵活Schema，适合多场景的异构数据
  - 支持水平扩展（分片）
  - 4.0+版本支持ACID事务

**为什么选MongoDB而不是PostgreSQL？**
1. 租户/用户数据由外部服务管理，无需关系型约束
2. 场景配置、物品元数据Schema灵活多变，适合文档存储
3. 简化架构，降低维护成本

### 缓存层
- **Redis**
  - 热数据缓存（用户画像、热门物品）
  - 实时推荐结果缓存
  - 分布式锁
  - 计数器（曝光、点击等）

### 向量数据库
- **Milvus** 或 **Weaviate**
  - 存储物品和用户的向量表示
  - 高效相似度检索

## 1.3 消息队列与流处理

### 消息队列
- **Apache Kafka**
  - 处理实时行为数据流
  - 高吞吐量、低延迟
  - 解耦服务模块
  - 持久化消息存储

### 流处理
- **Apache Flink**
  - 实时特征计算
  - 实时数据聚合
  - 复杂事件处理（CEP）
  - 支持精确一次语义（Exactly-Once）

## 1.4 任务调度

- **Celery** + **Redis**
  - 模型训练任务
  - 批量推荐预计算
  - 定时数据同步
  - 异步任务处理

## 1.5 监控与运维

### 监控
- **Prometheus** + **Grafana**
  - 系统性能监控
  - 业务指标监控
  - 推荐效果监控

### 日志
- **ELK Stack**（可选）
  - 日志收集与分析

### 链路追踪
- **Jaeger** 或 **Zipkin**
  - 分布式追踪
  - 性能分析

## 1.6 容器化

- **Docker**: 服务容器化
- **Docker Compose**: 本地开发环境
- **Kubernetes**: 生产环境编排（可选）

## 1.7 技术栈分阶段实施

### 第一阶段（MVP）
- FastAPI + MongoDB + Redis + Celery
- Docker + Docker Compose
- 基础推荐算法（协同过滤、内容推荐）
- 与网关/租户服务对接

### 第二阶段（扩展）
- Milvus（向量检索）
- Kafka + Flink（实时数据流处理）
- 深度学习模型
- gRPC服务间通信

### 第三阶段（完善）
- Kubernetes
- 完整监控体系
- AB测试平台
- 管理后台

---

# 2. 系统架构

## 2.1 整体架构

```
┌─────────────────────────────────────────────────────────────┐
│                    外部服务（已有）                           │
│  ┌──────────────────┐  ┌──────────────────┐                │
│  │  API网关服务      │  │  租户/用户服务    │                │
│  │  (Golang+Kratos) │  │  (Golang+Kratos) │                │
│  │  • 鉴权           │  │  • 租户管理       │                │
│  │  • 限流           │  │  • 用户管理       │                │
│  │  • 路由           │  │  • 权限控制       │                │
│  └──────────────────┘  └──────────────────┘                │
└─────────────────────────────────────────────────────────────┘
                              ▼
┌─────────────────────────────────────────────────────────────┐
│                    推荐系统（本项目）                         │
│                                                               │
│  ┌────────────────────  应用服务层  ──────────────────────┐  │
│  │  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐ │  │
│  │  │  场景管理服务  │  │  物品管理服务  │  │  行为采集服务  │ │  │
│  │  └──────────────┘  └──────────────┘  └──────────────┘ │  │
│  │  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐ │  │
│  │  │  推荐服务     │  │  特征服务     │  │  模型服务     │ │  │
│  │  └──────────────┘  └──────────────┘  └──────────────┘ │  │
│  │  ┌──────────────┐                                      │  │
│  │  │  实验服务     │                                      │  │
│  │  └──────────────┘                                      │  │
│  └──────────────────────────────────────────────────────────┘  │
│                              ▼                                  │
│  ┌────────────────────  推荐引擎层  ──────────────────────┐  │
│  │  ┌────────────┐  ┌────────────┐  ┌────────────┐      │  │
│  │  │  召回层     │  │  排序层     │  │  重排层     │      │  │
│  │  │            │  │            │  │            │      │  │
│  │  │ • 协同过滤  │  │ • LightGBM │  │ • 多样性   │      │  │
│  │  │ • 向量召回  │  │ • DeepFM   │  │ • 业务规则 │      │  │
│  │  │ • 热门召回  │  │ • Wide&Deep│  │ • AB测试   │      │  │
│  │  └────────────┘  └────────────┘  └────────────┘      │  │
│  └──────────────────────────────────────────────────────────┘  │
└─────────────────────────────────────────────────────────────┘
                              ▼
┌─────────────────────────────────────────────────────────────┐
│                        数据层                                 │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐                  │
│  │ MongoDB  │  │  Redis   │  │  Milvus  │                  │
│  │(业务数据) │  │(缓存)    │  │(向量)    │                  │
│  └──────────┘  └──────────┘  └──────────┘                  │
└─────────────────────────────────────────────────────────────┘
                              ▼
┌─────────────────────────────────────────────────────────────┐
│                     实时计算层                                │
│  ┌──────────────────────────────────────────────────┐       │
│  │              Kafka 消息队列                       │       │
│  │  ┌──────────┐  ┌──────────┐  ┌──────────┐       │       │
│  │  │行为事件流│  │特征流    │  │指标流    │       │       │
│  │  └──────────┘  └──────────┘  └──────────┘       │       │
│  └──────────────────────────────────────────────────┘       │
│                          ▼                                   │
│  ┌──────────────────────────────────────────────────┐       │
│  │           Flink 流处理引擎                        │       │
│  │  • 实时用户画像更新                               │       │
│  │  • 实时物品热度计算                               │       │
│  │  • 实时特征聚合                                   │       │
│  │  • 实时指标统计                                   │       │
│  └──────────────────────────────────────────────────┘       │
│                          ▼                                   │
│           写回 MongoDB / Redis / Metrics                     │
└─────────────────────────────────────────────────────────────┘
                              ▼
┌─────────────────────────────────────────────────────────────┐
│                     离线计算层                                │
│  ┌─────────────────┐         ┌─────────────────┐           │
│  │   Celery任务队列 │  ──────▶ │  离线计算       │           │
│  │  • 模型训练      │         │  • 相似度计算   │           │
│  │  • 批量预计算    │         │  • 画像离线更新 │           │
│  └─────────────────┘         └─────────────────┘           │
└─────────────────────────────────────────────────────────────┘
```

## 2.2 微服务拆分（支持K8s独立部署）

### 服务列表

| 服务名称 | 端口 | 协议 | 职责 | 独立部署 |
|---------|------|------|------|---------|
| scenario-service | 8001/9001 | HTTP + gRPC | 场景CRUD、配置管理 | ✅ |
| item-service | 8002/9002 | HTTP + gRPC | 物品CRUD、批量导入 | ✅ |
| behavior-service | 8003 | HTTP | 行为采集、写Kafka | ✅ |
| recommendation-service | 8004 | HTTP | 推荐接口、流程编排 | ✅ |
| feature-service | 9005 | gRPC | 特征提取、特征服务 | ✅ |
| model-service | 9006 | gRPC | 模型加载、在线预测 | ✅ |

### 服务间调用方式

**对外API（客户端）**: HTTP REST API
- scenario-service, item-service, behavior-service, recommendation-service

**内部调用（服务间）**: gRPC
- recommendation-service → feature-service/model-service
- 优势：高性能、强类型、内置负载均衡

**服务发现**: Kubernetes Service Discovery
- 开发环境：docker-compose DNS
- 生产环境：K8s Service名称

### 服务依赖关系

```
无依赖（可最先部署）:
├─ scenario-service
├─ item-service  
├─ behavior-service
├─ feature-service
└─ model-service

有依赖（最后部署）:
└─ recommendation-service
   ├─ depends: scenario-service (获取配置)
   ├─ depends: feature-service (特征提取)
   ├─ depends: model-service (模型预测)
   └─ depends: item-service (物品详情)
```

## 2.3 推荐流程

```
用户请求
   ↓
场景配置加载
   ↓
用户画像获取 (Redis/MongoDB)
   ↓
召回层（多路召回并行）
   ├─ 协同过滤召回
   ├─ 向量召回
   ├─ 热门召回（从Redis获取Flink实时计算的热度）
   └─ 场景特定召回
   ↓
候选集合并&去重
   ↓
特征提取
   ↓
排序层（模型打分）
   ↓
重排层（多样性、业务规则）
   ↓
AB测试分流
   ↓
结果缓存
   ↓
返回推荐结果
```

## 2.4 Kafka + Flink 实时计算架构

### Kafka Topics 设计

```
推荐系统的Kafka Topic规划：

1. user-behaviors-{tenant_id}
   - 用户行为原始数据
   - 分区数：根据租户规模（建议12-24）
   - 保留时间：7天
   
2. user-profile-updates
   - 用户画像更新事件
   - 由Flink计算后产出
   
3. item-stats-updates
   - 物品统计更新事件
   - 实时热度、点击率等
   
4. recommendation-metrics
   - 推荐系统指标
   - CTR、曝光、点击等
```

### Flink 任务设计

#### 1. 用户画像实时更新
```
Kafka (user-behaviors) 
   → Flink Job: UserProfileAggregator
   → 按 tenant_id + user_id 分组
   → 时间窗口聚合（5分钟滚动窗口）
   → 计算：观看次数、偏好分类、活跃时段
   → 输出到 Kafka (user-profile-updates)
   → 异步写入 MongoDB + Redis
```

#### 2. 物品热度实时计算
```
Kafka (user-behaviors)
   → Flink Job: ItemHotScoreCalculator
   → 按 tenant_id + item_id 分组
   → 时间窗口聚合（1小时滑动窗口）
   → 计算：浏览量、点击量、时间衰减热度
   → 输出到 Redis ZSET (hot:items:{tenant_id}:{scenario_id})
```

#### 3. 实时指标统计
```
Kafka (user-behaviors)
   → Flink Job: RecommendationMetrics
   → 按场景/实验组分组
   → 计算：CTR、平均观看时长、转化率
   → 输出到 Prometheus (通过Pushgateway)
```

### Flink 作业示例

```python
# 伪代码示例：用户画像实时更新
from pyflink.datastream import StreamExecutionEnvironment
from pyflink.datastream.window import TumblingProcessingTimeWindows
from pyflink.common import Time

env = StreamExecutionEnvironment.get_execution_environment()

# 从Kafka读取
behaviors = env.add_source(
    FlinkKafkaConsumer(
        topics=['user-behaviors'],
        deserialization_schema=JsonDeserializationSchema(),
        properties={'bootstrap.servers': 'kafka:9092'}
    )
)

# 处理逻辑
user_profiles = (
    behaviors
    .key_by(lambda x: (x['tenant_id'], x['user_id']))
    .window(TumblingProcessingTimeWindows.of(Time.minutes(5)))
    .aggregate(UserProfileAggregateFunction())
)

# 写入Sink
user_profiles.add_sink(
    FlinkKafkaSink(
        topic='user-profile-updates',
        serialization_schema=JsonSerializationSchema()
    )
)

env.execute("User Profile Real-time Updater")
```

### 数据流向

```
用户行为上报
   ↓
FastAPI (行为采集服务)
   ↓
写入 MongoDB (持久化) + 发送到 Kafka
   ↓
Flink 消费 Kafka
   ├─ Job1: 用户画像更新 → MongoDB + Redis
   ├─ Job2: 物品热度计算 → Redis
   └─ Job3: 实时指标统计 → Prometheus
   ↓
推荐服务读取 Redis/MongoDB 中的实时数据
```

---

# 3. 数据模型

## 3.1 MongoDB Collections

### scenarios（场景配置）
```javascript
{
  _id: ObjectId,
  tenant_id: "tenant_123",
  scenario_id: "vlog_001",
  scenario_type: "vlog",
  name: "短视频推荐",
  config: {
    features: {...},
    recall: {...},
    rank: {...},
    rerank: {...}
  },
  status: "active",
  created_at: ISODate,
  updated_at: ISODate
}

// 索引
db.scenarios.createIndex({tenant_id: 1, scenario_id: 1}, {unique: true})
```

### items（物品）
```javascript
{
  _id: ObjectId,
  tenant_id: "tenant_123",
  scenario_id: "vlog_001",
  item_id: "item_001",
  metadata: {
    title: "视频标题",
    duration: 120,
    category: "entertainment",
    tags: ["funny", "comedy"],
    // 场景特有字段...
  },
  embedding: [0.1, 0.2, ...],  // 可选
  status: "active",
  created_at: ISODate,
  updated_at: ISODate
}

// 索引
db.items.createIndex({tenant_id: 1, scenario_id: 1, item_id: 1}, {unique: true})
db.items.createIndex({"metadata.category": 1})
```

### user_profiles（用户画像）
```javascript
{
  _id: ObjectId,
  tenant_id: "tenant_123",
  user_id: "user_001",
  scenario_id: "vlog_001",
  features: {
    total_watch_count: 100,
    favorite_categories: ["entertainment"],
    // ...
  },
  preferences: {
    category_scores: {"entertainment": 0.8}
  },
  embedding: [0.1, 0.2, ...],
  updated_at: ISODate
}

// 索引
db.user_profiles.createIndex({tenant_id: 1, user_id: 1, scenario_id: 1}, {unique: true})
```

### interactions（行为日志）
```javascript
{
  _id: ObjectId,
  tenant_id: "tenant_123",
  scenario_id: "vlog_001",
  user_id: "user_001",
  item_id: "item_001",
  action_type: "click",
  context: {
    device_type: "mobile",
    location: "Beijing"
  },
  extra: {
    watch_duration: 90,
    completion_rate: 0.75
  },
  timestamp: ISODate
}

// 索引
db.interactions.createIndex({tenant_id: 1, user_id: 1, timestamp: -1})
db.interactions.createIndex({tenant_id: 1, item_id: 1, timestamp: -1})
```

### model_configs（模型配置）
```javascript
{
  _id: ObjectId,
  scenario_id: "vlog_001",
  model_type: "rank",
  model_name: "deepfm",
  model_version: "v1.0",
  model_path: "s3://models/deepfm_v1.0.pt",
  config: {...},
  metrics: {auc: 0.85},
  status: "active",
  created_at: ISODate
}
```

### experiments（AB实验）
```javascript
{
  _id: ObjectId,
  tenant_id: "tenant_123",
  scenario_id: "vlog_001",
  experiment_id: "exp_001",
  name: "测试新排序模型",
  groups: [
    {group_id: "control", traffic_ratio: 0.5, config: {...}},
    {group_id: "treatment", traffic_ratio: 0.5, config: {...}}
  ],
  status: "running",
  start_time: ISODate,
  end_time: ISODate
}
```

## 3.2 Redis数据结构

```
# 租户配置缓存
tenant:config:{tenant_id} → JSON (TTL: 1小时)

# 用户信息缓存
user:info:{tenant_id}:{user_id} → JSON (TTL: 30分钟)

# 用户画像缓存
user:profile:{tenant_id}:{user_id}:{scenario_id} → JSON (TTL: 1小时)

# 推荐结果缓存
recommend:{tenant_id}:{scenario_id}:{user_id}:{hash} → JSON (TTL: 10分钟)

# 场景配置缓存
scenario:config:{tenant_id}:{scenario_id} → JSON (TTL: 1小时)

# 热门物品
hot:items:{tenant_id}:{scenario_id} → ZSET (score=热度)

# 物品曝光去重
exposed:{tenant_id}:{user_id}:{scenario_id} → SET (TTL: 24小时)

# 实时计数
item:stats:{tenant_id}:{item_id} → HASH (view_count, like_count等)
```

---

# 4. 场景配置

## 4.1 配置化设计理念

**核心思想**：统一的推荐引擎框架 + 灵活的场景配置 = 支持多场景

```
┌─────────────────────────────┐
│   统一的推荐引擎（代码）      │
│   • 可插拔的召回策略         │
│   • 可配置的排序模型         │
│   • 可配置的重排规则         │
└──────────────┬──────────────┘
               │ 读取
               ▼
┌─────────────────────────────┐
│     场景配置（数据）          │
│   • vlog配置                 │
│   • 新闻配置                 │
│   • 电商配置                 │
└─────────────────────────────┘
```

## 4.2 场景配置结构

### Vlog场景示例
```json
{
  "scenario_id": "vlog_main_feed",
  "scenario_type": "vlog",
  "config": {
    "features": {
      "item_features": [
        {"name": "duration", "type": "numeric", "weight": 1.0},
        {"name": "completion_rate", "type": "numeric", "weight": 2.0},
        {"name": "category", "type": "categorical", "weight": 1.5}
      ],
      "user_features": [
        {"name": "age", "type": "categorical"},
        {"name": "favorite_categories", "type": "multi_categorical"}
      ]
    },
    "recall": {
      "strategies": [
        {"name": "user_cf", "weight": 0.25, "limit": 100},
        {"name": "vector_search", "weight": 0.3, "limit": 150},
        {"name": "hot_items", "weight": 0.2, "limit": 50}
      ]
    },
    "rank": {
      "model": "deepfm",
      "version": "v1.0",
      "objective": "watch_time"
    },
    "rerank": {
      "rules": [
        {"name": "diversity", "weight": 0.3},
        {"name": "freshness", "weight": 0.2, "params": {"decay_days": 7}}
      ]
    }
  }
}
```

### 新闻场景示例
```json
{
  "scenario_id": "news_main_feed",
  "scenario_type": "news",
  "config": {
    "features": {
      "item_features": [
        {"name": "publish_time", "type": "timestamp", "weight": 3.0},
        {"name": "hot_score", "type": "numeric", "weight": 2.5},
        {"name": "location", "type": "categorical", "weight": 1.5}
      ]
    },
    "recall": {
      "strategies": [
        {"name": "hot_news", "weight": 0.5, "limit": 200},
        {"name": "content_based", "weight": 0.3, "limit": 150},
        {"name": "user_cf", "weight": 0.2, "limit": 100}
      ]
    },
    "rank": {
      "model": "lightgbm",
      "version": "v2.0",
      "objective": "click_rate"
    },
    "rerank": {
      "rules": [
        {"name": "freshness", "weight": 0.5, "params": {"decay_hours": 6}},
        {"name": "location_match", "weight": 0.2}
      ]
    }
  }
}
```

## 4.3 配置如何驱动推荐

```python
async def recommend(tenant_id: str, user_id: str, scenario_id: str, count: int):
    # 1. 加载场景配置
    config = await load_scenario_config(tenant_id, scenario_id)
    
    # 2. 召回（根据配置）
    recall_results = []
    for strategy_config in config["recall"]["strategies"]:
        strategy = get_recall_strategy(strategy_config["name"])
        items = await strategy.recall(
            user_id=user_id,
            limit=strategy_config["limit"],
            params=strategy_config.get("params", {})
        )
        weighted_items = [(item, strategy_config["weight"]) for item in items]
        recall_results.extend(weighted_items)
    
    # 3. 排序（根据配置选择模型）
    rank_config = config["rank"]
    model = load_model(rank_config["model"], rank_config["version"])
    scores = model.predict(candidate_items)
    
    # 4. 重排（根据配置应用规则）
    for rule_config in config["rerank"]["rules"]:
        rule = get_rerank_rule(rule_config["name"])
        ranked_items = rule.apply(ranked_items, rule_config)
    
    return ranked_items[:count]
```

## 4.4 配置优势

✅ **无需改代码**：调整权重、新增特征只需改配置  
✅ **快速迭代**：配置变更立即生效  
✅ **AB测试友好**：不同实验组使用不同配置  
✅ **多租户定制**：同一套代码，不同租户不同配置

---

# 5. 服务对接

## 5.1 与API网关对接

### 请求头规范

网关转发请求时携带：

| Header | 必填 | 说明 | 示例 |
|--------|------|------|------|
| `X-Tenant-Id` | 是 | 租户ID | `tenant_123` |
| `X-User-Id` | 是 | 用户ID | `user_456` |
| `X-Request-Id` | 是 | 请求追踪ID | `req_001` |
| `Authorization` | 是 | Bearer Token | `Bearer xxx` |

### 推荐API示例

```http
POST /api/v1/recommend
X-Tenant-Id: tenant_123
X-User-Id: user_456
X-Request-Id: req_001
Authorization: Bearer xxx

{
  "scenario_id": "vlog_001",
  "count": 20,
  "context": {
    "device_type": "mobile"
  }
}
```

## 5.2 与租户/用户服务对接

### gRPC接口定义

#### 获取租户配置
```protobuf
service TenantService {
  rpc GetTenantConfig (GetTenantConfigRequest) returns (GetTenantConfigResponse);
}

message GetTenantConfigRequest {
  string tenant_id = 1;
}

message GetTenantConfigResponse {
  string tenant_id = 1;
  string tenant_name = 2;
  TenantQuota quota = 3;
  string status = 4;
}
```

#### 获取用户信息
```protobuf
service UserService {
  rpc GetUserInfo (GetUserInfoRequest) returns (GetUserInfoResponse);
}

message GetUserInfoRequest {
  string tenant_id = 1;
  string user_id = 2;
}

message GetUserInfoResponse {
  string user_id = 1;
  map<string, string> profile = 2;  // age, gender, location
  string status = 3;
}
```

### 调用示例

```python
# gRPC客户端
class TenantServiceClient:
    async def get_tenant_config(self, tenant_id: str):
        request = GetTenantConfigRequest(tenant_id=tenant_id)
        response = await self.stub.GetTenantConfig(request, timeout=5.0)
        return response

# 使用
tenant_config = await tenant_service.get_tenant_config("tenant_123")
user_info = await user_service.get_user_info("tenant_123", "user_456")
```

## 5.3 缓存策略

- **租户配置**：缓存1小时，从租户服务获取后缓存
- **用户信息**：缓存30分钟，LRU淘汰
- **场景配置**：缓存1小时，MongoDB读取后缓存

## 5.4 错误处理

- 外部服务不可用时使用缓存数据
- 超时设置3-5秒
- 自动重试1-2次（指数退避）

---

## 附录

### 相关文档
- [开发计划](./开发计划.md) - 详细的开发路线图和任务分解
- [K8s部署](../k8s/README.md) - Kubernetes部署配置和说明

### 关键技术决策
| 决策点 | 选型 | 理由 |
|-------|------|------|
| 数据库 | MongoDB | 灵活Schema，适合多场景异构数据 |
| 消息队列 | Kafka (KRaft) | 无需Zookeeper，简化架构 |
| 服务间调用 | gRPC | 高性能、强类型、内置负载均衡 |
| 场景实现 | 配置化 | 快速迭代，无需改代码 |
| 服务拆分 | 微服务 | 支持K8s独立部署和扩缩容 |

