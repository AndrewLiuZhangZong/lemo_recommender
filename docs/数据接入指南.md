# 数据接入指南

本文档说明如何将业务系统的物品数据接入推荐系统。

---

## 🎯 支持的接入方式

推荐系统支持**两种**数据接入方式：

| 方式 | 适用场景 | 实时性 | 复杂度 |
|------|---------|--------|--------|
| **API推送** | 小规模、实时发布 | ⚡️ 秒级 | ⭐ 简单 |
| **Kafka消费** | 大规模、高吞吐 | ⚡️ 秒级 | ⭐⭐ 中等 |

---

## 方式1：API推送（推荐✅）

### 适用场景

- vlog发布后立即推荐
- 新闻发布后实时展示
- 中小规模数据量（< 10万/天）
- 业务系统支持HTTP调用

### 接入步骤

#### 1. 获取API凭证

- **租户ID**: `tenant_id`（由推荐系统分配）
- **API地址**: `http://recommender-api:8080/api/v1`

#### 2. 调用批量导入接口

**接口地址**:
```
POST /api/v1/items/batch
```

**请求头**:
```http
Content-Type: application/json
X-Tenant-Id: your_tenant_id
X-User-Id: system
```

**请求体**:
```json
{
  "scenario_id": "vlog_main_feed",
  "items": [
    {
      "item_id": "vlog_20241022_001",
      "metadata": {
        "title": "北京旅行Vlog",
        "author": "旅行博主",
        "author_id": "user_123",
        "duration": 180,
        "cover_url": "https://cdn.example.com/cover.jpg",
        "video_url": "https://cdn.example.com/video.mp4",
        "tags": ["旅行", "北京", "美食"],
        "category": "travel",
        "publish_time": "2024-10-22T10:00:00Z"
      }
    },
    {
      "item_id": "vlog_20241022_002",
      "metadata": {
        "title": "上海美食探店",
        "author": "美食达人",
        "duration": 240,
        "tags": ["美食", "上海"]
      }
    }
  ]
}
```

**响应示例**:
```json
{
  "success": true,
  "message": "成功创建2个物品，后续处理已启动",
  "data": {
    "count": 2,
    "processing": {
      "processed": 2,
      "source": "api",
      "tasks": {
        "kafka_sent": 2,
        "vector_queued": 2,
        "cache_updated": true
      },
      "timestamp": "2024-10-22T10:00:00.000Z"
    }
  }
}
```

#### 3. 后续处理（自动）

接口调用成功后，系统会自动：
1. ✅ 写入MongoDB
2. ✅ 发送Kafka事件（通知下游）
3. ✅ 触发向量生成（用于相似推荐）
4. ✅ 失效相关缓存

#### 4. 示例代码

**Python**:
```python
import requests

def publish_vlog_to_recommender(vlog_data):
    """vlog发布后调用推荐系统"""
    
    url = "http://recommender-api:8080/api/v1/items/batch"
    headers = {
        "Content-Type": "application/json",
        "X-Tenant-Id": "vlog_platform",
        "X-User-Id": "system"
    }
    
    payload = {
        "scenario_id": "vlog_main_feed",
        "items": [
            {
                "item_id": vlog_data["id"],
                "metadata": {
                    "title": vlog_data["title"],
                    "author": vlog_data["author"],
                    "duration": vlog_data["duration"],
                    "cover_url": vlog_data["cover_url"],
                    "tags": vlog_data["tags"]
                }
            }
        ]
    }
    
    response = requests.post(url, json=payload, headers=headers)
    
    if response.status_code == 200:
        result = response.json()
        print(f"✅ 推荐系统接入成功: {result}")
    else:
        print(f"❌ 推荐系统接入失败: {response.text}")
```

**Go**:
```go
func publishVlogToRecommender(vlog VlogData) error {
    url := "http://recommender-api:8080/api/v1/items/batch"
    
    payload := map[string]interface{}{
        "scenario_id": "vlog_main_feed",
        "items": []map[string]interface{}{
            {
                "item_id": vlog.ID,
                "metadata": map[string]interface{}{
                    "title":  vlog.Title,
                    "author": vlog.Author,
                    "tags":   vlog.Tags,
                },
            },
        },
    }
    
    body, _ := json.Marshal(payload)
    req, _ := http.NewRequest("POST", url, bytes.NewBuffer(body))
    req.Header.Set("Content-Type", "application/json")
    req.Header.Set("X-Tenant-Id", "vlog_platform")
    req.Header.Set("X-User-Id", "system")
    
    client := &http.Client{Timeout: 10 * time.Second}
    resp, err := client.Do(req)
    
    if err != nil {
        return err
    }
    defer resp.Body.Close()
    
    if resp.StatusCode == 200 {
        fmt.Println("✅ 推荐系统接入成功")
        return nil
    }
    
    return fmt.Errorf("推荐系统接入失败: %d", resp.StatusCode)
}
```

---

## 方式2：Kafka消费

### 适用场景

- 大规模数据接入（> 10万/天）
- 已有Kafka基础设施
- 需要削峰填谷
- 需要异步解耦

### 接入步骤

#### 1. 发送消息到Kafka

业务系统将物品数据发送到指定Topic。

**Topic命名规范**:
- `items-ingest` - 统一接入Topic（推荐）
- `vlog-items` - vlog专用Topic
- `news-items` - 新闻专用Topic
- `{业务}-items` - 自定义Topic（需配置）

**消息格式**:
```json
{
  "tenant_id": "vlog_platform",
  "scenario_id": "vlog_main_feed",
  "items": [
    {
      "item_id": "vlog_20241022_001",
      "metadata": {
        "title": "北京旅行Vlog",
        "author": "旅行博主",
        "duration": 180,
        "tags": ["旅行", "北京"]
      }
    }
  ]
}
```

**消息Key**（可选）:
- 使用 `tenant_id` 作为key，确保同一租户的消息有序

#### 2. 启动Kafka消费者（推荐系统侧）

推荐系统提供守护进程消费Kafka消息。

```bash
# 后台启动
nohup poetry run python scripts/run_item_consumer.py > logs/item_consumer.log 2>&1 &

# 或使用systemd
systemctl start recommender-item-consumer
```

#### 3. 监控消费状态

查看日志：
```bash
tail -f logs/item_consumer.log
```

输出示例：
```
[ItemKafkaConsumer] 收到消息: Topic=vlog-items, Tenant=vlog_platform, Scenario=vlog_main_feed, Items=10
[ItemKafkaConsumer] ✅ 写入MongoDB: 10个物品
[ItemKafkaConsumer] ✅ 处理完成: {'processed': 10, 'source': 'kafka', ...}
```

#### 4. 示例代码

**Python (使用aiokafka)**:
```python
from aiokafka import AIOKafkaProducer
import json

async def send_vlogs_to_kafka():
    producer = AIOKafkaProducer(
        bootstrap_servers='localhost:9092',
        value_serializer=lambda v: json.dumps(v).encode('utf-8')
    )
    
    await producer.start()
    
    message = {
        "tenant_id": "vlog_platform",
        "scenario_id": "vlog_main_feed",
        "items": [
            {
                "item_id": "vlog_001",
                "metadata": {"title": "旅行Vlog"}
            }
        ]
    }
    
    await producer.send('items-ingest', value=message, key=b'vlog_platform')
    await producer.stop()
```

**Go (使用sarama)**:
```go
func sendVlogsToKafka(vlogs []Vlog) error {
    config := sarama.NewConfig()
    config.Producer.Return.Successes = true
    
    producer, err := sarama.NewSyncProducer([]string{"localhost:9092"}, config)
    if err != nil {
        return err
    }
    defer producer.Close()
    
    message := map[string]interface{}{
        "tenant_id":   "vlog_platform",
        "scenario_id": "vlog_main_feed",
        "items":       vlogs,
    }
    
    msgBytes, _ := json.Marshal(message)
    
    _, _, err = producer.SendMessage(&sarama.ProducerMessage{
        Topic: "items-ingest",
        Key:   sarama.StringEncoder("vlog_platform"),
        Value: sarama.ByteEncoder(msgBytes),
    })
    
    return err
}
```

---

## 📊 两种方式对比

| 特性 | API推送 | Kafka消费 |
|------|--------|----------|
| **延迟** | 秒级 | 秒级 |
| **吞吐量** | 中等 | 极高 |
| **可靠性** | 同步确认 | 异步持久化 |
| **实现复杂度** | ⭐ 简单 | ⭐⭐ 中等 |
| **依赖组件** | 无 | Kafka集群 |
| **适合规模** | < 10万/天 | > 10万/天 |
| **削峰填谷** | ❌ 不支持 | ✅ 支持 |
| **消息回溯** | ❌ 不支持 | ✅ 支持 |

---

## 🚀 最佳实践

### 1. 混合使用

- **实时发布**：使用API推送（低延迟）
- **批量导入**：使用Kafka消费（高吞吐）

### 2. 元数据规范

必填字段：
- `item_id` - 物品唯一ID
- `tenant_id` - 租户ID
- `scenario_id` - 场景ID

推荐字段（提升推荐效果）：
- `title` - 标题（用于向量生成）
- `tags` - 标签（用于相似召回）
- `category` - 分类（用于过滤）
- `author` / `author_id` - 作者（用于作者推荐）
- `publish_time` - 发布时间（用于时间衰减）

### 3. 错误处理

- API推送：实现重试机制（3次，指数退避）
- Kafka消费：消息会自动重试，无需业务方处理

### 4. 监控告警

关键指标：
- API成功率 > 99.9%
- Kafka消费延迟 < 1秒
- 向量生成完成率 > 99%

---

## ❓ 常见问题

### Q1: API推送失败怎么办？

A: 实现重试机制。如果持续失败，检查：
- 租户ID是否正确
- 网络连接是否正常
- 推荐系统服务是否启动

### Q2: Kafka消息积压怎么办？

A: 
- 增加消费者实例数（水平扩展）
- 检查MongoDB写入性能
- 查看向量生成队列是否阻塞

### Q3: 如何确认数据接入成功？

A:
- API方式：查看响应中的 `processing` 字段
- Kafka方式：查看消费者日志
- 通用：调用查询接口验证

```bash
# 查询物品
curl -H "X-Tenant-Id: vlog_platform" \
  "http://recommender-api:8080/api/v1/items?scenario_id=vlog_main_feed&page=1"
```

### Q4: 如何新增自定义Topic？

A: 修改配置文件：

```bash
# config/prod.env
KAFKA_ITEM_INGEST_TOPICS=items-ingest,vlog-items,news-items,your-custom-topic
```

重启消费者即可。

---

## 📞 技术支持

- 文档：[系统设计.md](./系统设计.md)
- API文档：http://recommender-api:8080/api/v1/docs
- 问题反馈：GitHub Issues

