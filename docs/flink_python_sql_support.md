# Flink Python å’Œ SQL ä½œä¸šæ”¯æŒé…ç½®æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£ä»‹ç»å¦‚ä½•åœ¨å·²éƒ¨ç½²çš„ Flink é›†ç¾¤ä¸­å¯ç”¨ Python å’Œ SQL ä½œä¸šæ”¯æŒã€‚

**å½“å‰çŠ¶æ€ï¼š**
- âœ… Flink é›†ç¾¤å·²éƒ¨ç½²ï¼ˆDocker/K8sï¼‰
- âŒ ä¸æ”¯æŒ Python ä½œä¸š
- âŒ ä¸æ”¯æŒ SQL ä½œä¸š

**ç›®æ ‡ï¼š**
- âœ… æ”¯æŒ PyFlink ä½œä¸šæäº¤
- âœ… æ”¯æŒ Flink SQL ä½œä¸šæäº¤

---

## ğŸ æ–¹æ¡ˆä¸€ï¼šå¯ç”¨ PyFlink æ”¯æŒ

### 1.1 äº†è§£ PyFlink

PyFlink æ˜¯ Flink çš„ Python APIï¼Œå…è®¸ä½¿ç”¨ Python ç¼–å†™ Flink ä½œä¸šã€‚

**æ¶æ„ï¼š**
```
ç”¨æˆ· Python è„šæœ¬
    â†“
PyFlink API
    â†“
Flink Python Runtime (Java Process)
    â†“
Flink JobManager/TaskManager
```

### 1.2 ç¯å¢ƒè¦æ±‚

- Python 3.7, 3.8, 3.9, æˆ– 3.10
- Java 11 æˆ– Java 8
- Apache Flink 1.19.x

### 1.3 Docker é•œåƒé…ç½®

**æ–¹å¼ Aï¼šä½¿ç”¨å®˜æ–¹ Flink Python é•œåƒ**

ä¿®æ”¹ `docker-compose.yml`ï¼š

```yaml
flink:
  # ä½¿ç”¨åŒ…å« Python æ”¯æŒçš„é•œåƒ
  image: flink:1.19-scala_2.12-java11-python
  # æˆ–è€…è‡ªå®šä¹‰æ„å»º
  # build:
  #   context: .
  #   dockerfile: Dockerfile.flink-python
  ...
```

**æ–¹å¼ Bï¼šè‡ªå®šä¹‰ Dockerfileï¼ˆæ¨èï¼‰**

åˆ›å»º `Dockerfile.flink-python`ï¼š

```dockerfile
FROM flink:1.19-scala_2.12-java11

# å®‰è£… Python å’Œä¾èµ–
RUN apt-get update && \
    apt-get install -y python3 python3-pip python3-dev && \
    ln -s /usr/bin/python3 /usr/bin/python && \
    rm -rf /var/lib/apt/lists/*

# å®‰è£… PyFlink
RUN pip3 install --no-cache-dir apache-flink==1.19.0

# å®‰è£…å¸¸ç”¨ Python åº“
RUN pip3 install --no-cache-dir \
    pandas \
    numpy \
    kafka-python \
    pymongo \
    redis

# åˆ›å»ºä½œä¸šç›®å½•
RUN mkdir -p /opt/flink/usrlib

WORKDIR /opt/flink
```

æ„å»ºé•œåƒï¼š

```bash
docker build -f Dockerfile.flink-python -t flink-python:1.19 .
```

æ›´æ–° `docker-compose.yml`ï¼š

```yaml
flink:
  image: flink-python:1.19
  volumes:
    - ./flink_jobs:/opt/flink/usrlib  # æŒ‚è½½ä½œä¸šç›®å½•
  ...
```

### 1.4 K8s éƒ¨ç½²é…ç½®

ä¿®æ”¹ `k8s-deploy/k8s-deployment-http-grpc.yaml` ä¸­çš„ Flink é…ç½®ï¼š

```yaml
# æ·»åŠ  Flink Python ç¯å¢ƒé…ç½®
apiVersion: v1
kind: ConfigMap
metadata:
  name: flink-python-config
  namespace: lemo-dev
data:
  # Python ç¯å¢ƒé…ç½®
  PYTHON_VERSION: "3.9"
  PYFLINK_CLIENT_EXECUTABLE: "python3"
---
# å¯é€‰ï¼šåˆ›å»º Flink Python ä½œä¸šçš„ PVC
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: flink-python-jobs
  namespace: lemo-dev
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 10Gi
```

### 1.5 æäº¤ Python ä½œä¸šçš„æ–¹å¼

#### æ–¹å¼ 1ï¼šé€šè¿‡ CLI å‘½ä»¤ï¼ˆæ¨èï¼‰

åœ¨ Flink JobManager Pod ä¸­æ‰§è¡Œï¼š

```bash
# è¿›å…¥ Flink JobManager Pod
kubectl exec -it <flink-jobmanager-pod> -n lemo-dev -- /bin/bash

# æäº¤ Python ä½œä¸š
flink run -py /opt/flink/usrlib/my_job.py \
    --jarfile /opt/flink/opt/flink-python_*.jar \
    --parallelism 2

# å¸¦ä¾èµ–çš„ä½œä¸š
flink run -py /opt/flink/usrlib/my_job.py \
    --pyFiles file:///opt/flink/usrlib/utils.py,file:///opt/flink/usrlib/config.py \
    --pyArchives /opt/flink/usrlib/venv.zip#venv \
    --parallelism 2
```

#### æ–¹å¼ 2ï¼šé€šè¿‡ REST APIï¼ˆéœ€è¦é¢å¤–å¤„ç†ï¼‰

Flink REST API ä¸ç›´æ¥æ”¯æŒ Python è„šæœ¬ï¼Œéœ€è¦ï¼š

**æ­¥éª¤ 1ï¼š** å°† Python è„šæœ¬å’Œä¾èµ–æ‰“åŒ…æˆ ZIP

```bash
# åˆ›å»ºå·¥ä½œç›®å½•
mkdir -p my_job
cd my_job

# å¤åˆ¶è„šæœ¬
cp my_job.py .

# å®‰è£…ä¾èµ–åˆ°æœ¬åœ°
pip install -r requirements.txt -t ./packages

# æ‰“åŒ…
zip -r my_job.zip my_job.py packages/
```

**æ­¥éª¤ 2ï¼š** ä¸Šä¼  ZIP åˆ° Flinkï¼ˆå°† ZIP å½“ä½œ JAR ä¸Šä¼ ï¼‰

```bash
curl -X POST -H "Expect:" \
    -F "jarfile=@my_job.zip" \
    http://flink-jobmanager:8081/jars/upload
```

**æ­¥éª¤ 3ï¼š** è¿è¡Œä½œä¸š

```bash
curl -X POST \
    http://flink-jobmanager:8081/jars/<jar-id>/run \
    -H "Content-Type: application/json" \
    -d '{
        "programArgs": "-py my_job.py",
        "parallelism": 2
    }'
```

#### æ–¹å¼ 3ï¼šé€šè¿‡ Kubernetes Jobï¼ˆæ¨èç”¨äºæˆ‘ä»¬çš„åœºæ™¯ï¼‰

åˆ›å»º K8s Job æ¥æäº¤ Flink ä½œä¸šï¼š

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: flink-python-job-{{ job_id }}
  namespace: lemo-dev
spec:
  template:
    spec:
      containers:
      - name: flink-submitter
        image: flink-python:1.19
        command:
        - /bin/bash
        - -c
        - |
          # ä¸‹è½½ Python è„šæœ¬ï¼ˆä» OSSï¼‰
          wget -O /tmp/job.py {{ script_url }}
          
          # æäº¤åˆ° Flink é›†ç¾¤
          flink run \
            -m {{ flink_jobmanager_address }}:8081 \
            -py /tmp/job.py \
            --parallelism {{ parallelism }}
        env:
        - name: FLINK_REST_URL
          value: "http://flink-jobmanager:8081"
      restartPolicy: Never
```

---

## ğŸ—ƒï¸ æ–¹æ¡ˆäºŒï¼šå¯ç”¨ Flink SQL æ”¯æŒ

### 2.1 äº†è§£ Flink SQL

Flink SQL å…è®¸ä½¿ç”¨æ ‡å‡† SQL è¯­å¥è¿›è¡Œæµå¼å’Œæ‰¹å¤„ç†ã€‚

**ç»„ä»¶ï¼š**
- **Flink SQL Client**: äº¤äº’å¼ SQL å‘½ä»¤è¡Œå·¥å…·
- **Flink SQL Gateway**: REST API æœåŠ¡ï¼ˆæ¨èï¼‰

### 2.2 æ–¹å¼ Aï¼šä½¿ç”¨ Flink SQL Clientï¼ˆç®€å•ï¼‰

#### å®‰è£…é…ç½®

Flink å·²å†…ç½® SQL Clientï¼Œç›´æ¥ä½¿ç”¨ï¼š

```bash
# è¿›å…¥ Flink JobManager Pod
kubectl exec -it <flink-jobmanager-pod> -n lemo-dev -- /bin/bash

# å¯åŠ¨ SQL Client
./bin/sql-client.sh
```

#### æäº¤ SQL ä½œä¸š

**æ–¹å¼ 1ï¼šäº¤äº’å¼**

```sql
-- åœ¨ SQL Client ä¸­æ‰§è¡Œ
CREATE TABLE my_table (
    id INT,
    name STRING,
    created_at TIMESTAMP(3)
) WITH (
    'connector' = 'kafka',
    'topic' = 'my-topic',
    'properties.bootstrap.servers' = 'kafka:9092',
    'format' = 'json'
);

INSERT INTO my_table VALUES (1, 'test', NOW());
```

**æ–¹å¼ 2ï¼šæ‰§è¡Œ SQL æ–‡ä»¶**

```bash
# å‡†å¤‡ SQL æ–‡ä»¶
cat > /tmp/my_job.sql << EOF
CREATE TABLE ...;
INSERT INTO ...;
EOF

# æ‰§è¡Œ
./bin/sql-client.sh -f /tmp/my_job.sql
```

### 2.3 æ–¹å¼ Bï¼šä½¿ç”¨ Flink SQL Gatewayï¼ˆæ¨èï¼‰

SQL Gateway æä¾› REST APIï¼Œé€‚åˆç¨‹åºåŒ–è°ƒç”¨ã€‚

#### éƒ¨ç½² SQL Gateway

**Docker Compose æ–¹å¼ï¼š**

ä¿®æ”¹ `docker-compose.yml`ï¼š

```yaml
services:
  flink-sql-gateway:
    image: flink:1.19-scala_2.12-java11
    container_name: flink-sql-gateway
    command: >
      bash -c "
      ./bin/sql-gateway.sh start -Dsql-gateway.endpoint.rest.address=0.0.0.0 &&
      tail -f /opt/flink/log/flink-*-sql-gateway-*.log
      "
    ports:
      - "8083:8083"  # SQL Gateway REST API
    environment:
      FLINK_PROPERTIES: |
        jobmanager.rpc.address: flink
        sql-gateway.endpoint.rest.address: 0.0.0.0
        sql-gateway.endpoint.rest.port: 8083
    networks:
      - lemo-network
    depends_on:
      - flink
```

**Kubernetes æ–¹å¼ï¼š**

åˆ›å»º `k8s-deploy/flink-sql-gateway-deployment.yaml`ï¼š

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: flink-sql-gateway
  namespace: lemo-dev
spec:
  replicas: 1
  selector:
    matchLabels:
      app: flink-sql-gateway
  template:
    metadata:
      labels:
        app: flink-sql-gateway
    spec:
      containers:
      - name: sql-gateway
        image: flink:1.19-scala_2.12-java11
        command:
        - /bin/bash
        - -c
        - |
          ./bin/sql-gateway.sh start \
            -Dsql-gateway.endpoint.rest.address=0.0.0.0 \
            -Djobmanager.rpc.address=flink-jobmanager &&
          tail -f /opt/flink/log/*.log
        ports:
        - containerPort: 8083
          name: rest
        env:
        - name: FLINK_PROPERTIES
          value: |
            jobmanager.rpc.address: flink-jobmanager
            sql-gateway.endpoint.rest.address: 0.0.0.0
            sql-gateway.endpoint.rest.port: 8083
---
apiVersion: v1
kind: Service
metadata:
  name: flink-sql-gateway
  namespace: lemo-dev
spec:
  selector:
    app: flink-sql-gateway
  ports:
  - port: 8083
    targetPort: 8083
    name: rest
```

éƒ¨ç½²ï¼š

```bash
kubectl apply -f k8s-deploy/flink-sql-gateway-deployment.yaml
```

#### ä½¿ç”¨ SQL Gateway API

**åˆ›å»ºä¼šè¯ï¼š**

```bash
curl -X POST http://flink-sql-gateway:8083/v1/sessions \
    -H "Content-Type: application/json" \
    -d '{
        "properties": {
            "execution.runtime-mode": "streaming"
        }
    }'

# è¿”å›ï¼š{"sessionHandle":"..."}
```

**æ‰§è¡Œ SQLï¼š**

```bash
SESSION_HANDLE="<ä»ä¸Šé¢è·å–>"

curl -X POST http://flink-sql-gateway:8083/v1/sessions/$SESSION_HANDLE/statements \
    -H "Content-Type: application/json" \
    -d '{
        "statement": "CREATE TABLE my_table ...; INSERT INTO my_table ...;"
    }'
```

**æŸ¥è¯¢ç»“æœï¼š**

```bash
OPERATION_HANDLE="<ä»æ‰§è¡Œè¿”å›>"

curl -X GET http://flink-sql-gateway:8083/v1/sessions/$SESSION_HANDLE/operations/$OPERATION_HANDLE/result/0
```

---

## ğŸ”§ åœ¨æ¨èç³»ç»Ÿä¸­é›†æˆ

### 3.1 æ›´æ–°åç«¯ä»£ç 

ä¿®æ”¹ `app/services/flink/job_manager.py`ï¼š

```python
async def _submit_python_script(self, template: JobTemplate, request: FlinkJobSubmitRequest) -> str:
    """
    é€šè¿‡ Kubernetes Job æäº¤ Python ä½œä¸š
    """
    script_path = template.config.get("script_path")
    parallelism = request.job_config.get("parallelism", template.parallelism)
    
    # åˆ›å»º K8s Job
    job_manifest = {
        "apiVersion": "batch/v1",
        "kind": "Job",
        "metadata": {
            "name": f"flink-python-{request.job_id}",
            "namespace": "lemo-dev"
        },
        "spec": {
            "template": {
                "spec": {
                    "containers": [{
                        "name": "flink-submitter",
                        "image": "flink-python:1.19",
                        "command": [
                            "/bin/bash",
                            "-c",
                            f"""
                            wget -O /tmp/job.py {script_path}
                            flink run -m {self.flink_rest_url.replace('http://', '').replace(':8081', '')}:8081 \
                                -py /tmp/job.py \
                                --parallelism {parallelism}
                            """
                        ]
                    }],
                    "restartPolicy": "Never"
                }
            }
        }
    }
    
    # ä½¿ç”¨ Kubernetes API åˆ›å»º Job
    from kubernetes import client, config
    config.load_incluster_config()  # åœ¨ K8s Pod ä¸­è¿è¡Œ
    
    batch_api = client.BatchV1Api()
    batch_api.create_namespaced_job(
        namespace="lemo-dev",
        body=job_manifest
    )
    
    logger.info(f"å·²åˆ›å»º K8s Job: flink-python-{request.job_id}")
    return request.job_id


async def _submit_sql(self, template: JobTemplate, request: FlinkJobSubmitRequest) -> str:
    """
    é€šè¿‡ SQL Gateway æäº¤ SQL ä½œä¸š
    """
    sql = template.config.get("sql")
    
    # 1. åˆ›å»º SQL Gateway ä¼šè¯
    session_response = await self.client.post(
        f"{self.sql_gateway_url}/v1/sessions",
        json={
            "properties": {
                "execution.runtime-mode": "streaming"
            }
        }
    )
    session_handle = session_response.json()["sessionHandle"]
    
    # 2. æ‰§è¡Œ SQL
    stmt_response = await self.client.post(
        f"{self.sql_gateway_url}/v1/sessions/{session_handle}/statements",
        json={"statement": sql}
    )
    operation_handle = stmt_response.json()["operationHandle"]
    
    logger.info(f"SQL ä½œä¸šå·²æäº¤: session={session_handle}, operation={operation_handle}")
    return operation_handle
```

### 3.2 æ›´æ–°é…ç½®

ä¿®æ”¹ `app/core/config.py`ï¼š

```python
class Settings(BaseSettings):
    # ... ç°æœ‰é…ç½® ...
    
    # Flink é…ç½®
    flink_rest_url: str = "http://111.228.39.41:8081"
    flink_sql_gateway_url: str = "http://flink-sql-gateway:8083"  # æ–°å¢
    
    # Kubernetes é…ç½®ï¼ˆç”¨äºåˆ›å»º Jobï¼‰
    k8s_namespace: str = "lemo-dev"
    k8s_in_cluster: bool = True  # æ˜¯å¦åœ¨ K8s é›†ç¾¤å†…è¿è¡Œ
```

### 3.3 æ·»åŠ  Python ä¾èµ–

ä¿®æ”¹ `pyproject.toml`ï¼š

```toml
[tool.poetry.dependencies]
# ... ç°æœ‰ä¾èµ– ...
kubernetes = "^28.1.0"  # K8s API å®¢æˆ·ç«¯
```

å®‰è£…ï¼š

```bash
poetry add kubernetes
```

---

## ğŸ“Š æµ‹è¯•éªŒè¯

### 4.1 æµ‹è¯• PyFlink æ”¯æŒ

**åˆ›å»ºæµ‹è¯•è„šæœ¬** `test_pyflink.py`ï¼š

```python
from pyflink.datastream import StreamExecutionEnvironment
from pyflink.common.typeinfo import Types
from pyflink.datastream.functions import MapFunction

class MyMapFunction(MapFunction):
    def map(self, value):
        return value * 2

def main():
    env = StreamExecutionEnvironment.get_execution_environment()
    env.set_parallelism(1)
    
    data = env.from_collection([1, 2, 3, 4, 5], type_info=Types.INT())
    data.map(MyMapFunction()).print()
    
    env.execute("PyFlink Test Job")

if __name__ == '__main__':
    main()
```

**æäº¤æµ‹è¯•ï¼š**

```bash
# è¿›å…¥ Flink Pod
kubectl exec -it <flink-jobmanager-pod> -n lemo-dev -- /bin/bash

# æ‰§è¡Œ
flink run -py /tmp/test_pyflink.py
```

### 4.2 æµ‹è¯• SQL Gateway

```bash
# åˆ›å»ºä¼šè¯
curl -X POST http://flink-sql-gateway:8083/v1/sessions

# æ‰§è¡Œç®€å• SQL
curl -X POST http://flink-sql-gateway:8083/v1/sessions/<session-handle>/statements \
    -H "Content-Type: application/json" \
    -d '{"statement": "SELECT 1"}'
```

---

## ğŸ¯ æ¨èå®æ–½æ­¥éª¤

### é˜¶æ®µ 1ï¼šåŸºç¡€ç¯å¢ƒå‡†å¤‡ï¼ˆ1-2 å¤©ï¼‰

1. âœ… æ„å»º Flink Python é•œåƒ
2. âœ… æ›´æ–° Docker Compose / K8s é…ç½®
3. âœ… éªŒè¯ PyFlink åŸºç¡€åŠŸèƒ½

### é˜¶æ®µ 2ï¼šPython ä½œä¸šæ”¯æŒï¼ˆ2-3 å¤©ï¼‰

1. âœ… å®ç° K8s Job æäº¤æ–¹å¼
2. âœ… æ›´æ–°åç«¯ API
3. âœ… æµ‹è¯•ç«¯åˆ°ç«¯æµç¨‹
4. âœ… æ›´æ–°å‰ç«¯ç•Œé¢

### é˜¶æ®µ 3ï¼šSQL Gateway é›†æˆï¼ˆ2-3 å¤©ï¼‰

1. âœ… éƒ¨ç½² SQL Gateway
2. âœ… å®ç° SQL ä½œä¸šæäº¤
3. âœ… æ·»åŠ  SQL ç¼–è¾‘å™¨ï¼ˆå‰ç«¯ï¼‰
4. âœ… æµ‹è¯•éªŒè¯

### é˜¶æ®µ 4ï¼šç”Ÿäº§ä¼˜åŒ–ï¼ˆæŒç»­ï¼‰

1. âœ… ä¾èµ–ç®¡ç†ä¼˜åŒ–
2. âœ… ä½œä¸šç›‘æ§å‘Šè­¦
3. âœ… æ€§èƒ½è°ƒä¼˜
4. âœ… æ–‡æ¡£å®Œå–„

---

## ğŸ“š å‚è€ƒèµ„æ–™

- [Apache Flink Python API å®˜æ–¹æ–‡æ¡£](https://nightlies.apache.org/flink/flink-docs-release-1.19/docs/dev/python/overview/)
- [Flink SQL Gateway æ–‡æ¡£](https://nightlies.apache.org/flink/flink-docs-release-1.19/docs/dev/table/sql-gateway/overview/)
- [PyFlink å®‰è£…æŒ‡å—](https://nightlies.apache.org/flink/flink-docs-release-1.19/docs/dev/python/installation/)
- [Flink Kubernetes Operator](https://nightlies.apache.org/flink/flink-kubernetes-operator-docs-main/)

---

## â“ å¸¸è§é—®é¢˜

### Q1: ä¸ºä»€ä¹ˆä¸èƒ½ç›´æ¥ä¸Šä¼  Python è„šæœ¬åˆ° `/jars/upload`ï¼Ÿ

**A:** Flink REST API çš„ `/jars/upload` ç«¯ç‚¹è®¾è®¡ç”¨äº JAR æ–‡ä»¶ã€‚Python è„šæœ¬éœ€è¦é€šè¿‡ CLI å·¥å…·ï¼ˆ`flink run -py`ï¼‰æˆ–æ‰“åŒ…æˆç‰¹æ®Šæ ¼å¼æ‰èƒ½æäº¤ã€‚

### Q2: Python ä¾èµ–æ€ä¹ˆç®¡ç†ï¼Ÿ

**A:** ä¸‰ç§æ–¹å¼ï¼š
1. åœ¨ Flink é•œåƒä¸­é¢„è£…å¸¸ç”¨åº“
2. ä½¿ç”¨ `--pyArchives` ä¸Šä¼ è™šæ‹Ÿç¯å¢ƒ ZIP
3. ä½¿ç”¨ `--pyRequirements` æŒ‡å®š requirements.txt

### Q3: SQL Gateway æ˜¯å¿…éœ€çš„å—ï¼Ÿ

**A:** ä¸æ˜¯ã€‚å¦‚æœåªéœ€è¦åŸºç¡€ SQL åŠŸèƒ½ï¼Œå¯ä»¥ä½¿ç”¨ SQL Clientã€‚SQL Gateway æä¾› REST APIï¼Œé€‚åˆç¨‹åºåŒ–é›†æˆã€‚

### Q4: æ€§èƒ½ä¼šå—å½±å“å—ï¼Ÿ

**A:** PyFlink ä½¿ç”¨ Python UDF æ—¶ä¼šæœ‰é¢å¤–å¼€é”€ã€‚çº¯ SQL æˆ– Java/Scala ä½œä¸šæ€§èƒ½æ›´å¥½ã€‚å»ºè®®ï¼š
- è®¡ç®—å¯†é›†å‹ä»»åŠ¡ç”¨ Java/Scala
- æ•°æ®å¤„ç†å’Œä¸šåŠ¡é€»è¾‘ç”¨ Python
- ç®€å•æŸ¥è¯¢ç”¨ SQL

---

**æ–‡æ¡£ç‰ˆæœ¬ï¼š** v1.0  
**æ›´æ–°æ—¶é—´ï¼š** 2025-11-01  
**ç»´æŠ¤è€…ï¼š** æ¨èç³»ç»Ÿå›¢é˜Ÿ

