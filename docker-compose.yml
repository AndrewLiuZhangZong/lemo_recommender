version: '3.8'

services:
  # MongoDB
  mongodb:
    image: mongo:7.0
    container_name: lemo-mongodb
    ports:
      - "27017:27017"
    environment:
      MONGO_INITDB_ROOT_USERNAME: admin
      MONGO_INITDB_ROOT_PASSWORD: password
      MONGO_INITDB_DATABASE: lemo_recommender
    volumes:
      - mongodb_data:/data/db
      # - ./scripts/init-mongo.js:/docker-entrypoint-initdb.d/init-mongo.js:ro  # 如需自动初始化，请创建此文件
    networks:
      - lemo-network
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis (缓存/队列)
  redis:
    image: redis:7.2-alpine
    container_name: lemo-redis
    ports:
      - "6379:6379"
    command: redis-server --requirepass redis_password_2024 --appendonly yes
    volumes:
      - redis_data:/data
    networks:
      - lemo-network
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5

  # Kafka (消息队列 - KRaft模式，无需Zookeeper)
  kafka:
    image: apache/kafka:3.8.1
    container_name: lemo-kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://111.228.39.41:9092  # 使用外网IP，支持远程访问
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@localhost:9093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_NUM_PARTITIONS: 3
      CLUSTER_ID: MkU3OEVBNTcwNTJENDM2Qk
    volumes:
      - kafka_data:/var/lib/kafka/data
    networks:
      - lemo-network
    healthcheck:
      test: ["CMD-SHELL", "/opt/kafka/bin/kafka-broker-api-versions.sh --bootstrap-server localhost:9092"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Etcd (Milvus依赖)
  etcd:
    image: quay.io/coreos/etcd:v3.5.5
    container_name: lemo-etcd
    ports:
      - "2379:2379"
    environment:
      - ETCD_AUTO_COMPACTION_MODE=revision
      - ETCD_AUTO_COMPACTION_RETENTION=1000
      - ETCD_QUOTA_BACKEND_BYTES=4294967296
      - ETCD_SNAPSHOT_COUNT=50000
    command: etcd -advertise-client-urls=http://127.0.0.1:2379 -listen-client-urls http://0.0.0.0:2379 --data-dir /etcd
    volumes:
      - etcd_data:/etcd
    networks:
      - lemo-network
    healthcheck:
      test: ["CMD", "etcdctl", "endpoint", "health"]
      interval: 30s
      timeout: 10s
      retries: 5

  # MinIO (对象存储 - Milvus依赖)
  minio:
    image: minio/minio:RELEASE.2023-11-20T22-40-07Z
    container_name: lemo-minio
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    command: minio server /minio_data --console-address ":9001"
    volumes:
      - minio_data:/minio_data
    networks:
      - lemo-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3

  # Milvus (向量数据库)
  milvus:
    image: milvusdb/milvus:v2.4.1
    container_name: lemo-milvus
    ports:
      - "19530:19530"
      - "9091:9091"
    environment:
      ETCD_ENDPOINTS: etcd:2379
      MINIO_ADDRESS: minio:9000
      MINIO_ACCESS_KEY_ID: minioadmin
      MINIO_SECRET_ACCESS_KEY: minioadmin
    command: milvus run standalone
    volumes:
      - milvus_data:/var/lib/milvus
    depends_on:
      - etcd
      - minio
    networks:
      - lemo-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9091/healthz"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Attu (Milvus管理界面)
  attu:
    image: zilliz/attu:v2.4
    container_name: lemo-attu
    ports:
      - "8000:3000"
    environment:
      MILVUS_URL: milvus:19530
    depends_on:
      - milvus
    networks:
      - lemo-network

  # Prometheus (监控)
  prometheus:
    image: prom/prometheus:latest
    container_name: lemo-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./config/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    networks:
      - lemo-network

  # Grafana (可视化)
  grafana:
    image: grafana/grafana:latest
    container_name: lemo-grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana_data:/var/lib/grafana
    depends_on:
      - prometheus
    networks:
      - lemo-network

  # ClickHouse (OLAP 数据库，用于行为数据分析)
  clickhouse:
    image: clickhouse/clickhouse-server:24.1
    container_name: lemo-clickhouse
    ports:
      - "8123:8123"  # HTTP 接口
      - "9900:9000"  # Native TCP 接口（避免与 MinIO 9000 端口冲突）
    environment:
      CLICKHOUSE_USER: default
      CLICKHOUSE_PASSWORD: clickhouse_2024
      CLICKHOUSE_DB: lemo_analytics
    volumes:
      - clickhouse_data:/var/lib/clickhouse
      - clickhouse_logs:/var/log/clickhouse-server
    ulimits:
      nofile:
        soft: 262144
        hard: 262144
    networks:
      - lemo-network
    healthcheck:
      test: ["CMD", "clickhouse-client", "--query", "SELECT 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Apache Flink (流处理引擎)
  # Standalone 模式：单容器包含 JobManager 和 TaskManager
  flink:
    # 使用 ACR 镜像（推荐生产环境）
    image: registry.cn-beijing.aliyuncs.com/lemo_zls/flink-python:1.19
    # 或本地构建（开发环境）
    # build:
    #   context: .
    #   dockerfile: Dockerfile.flink-python
    container_name: lemo-flink
    user: root  # 必须使用 root 才能修改配置
    ports:
      - "8081:8081"  # Flink Web UI
      - "6123:6123"  # JobManager RPC
    volumes:
      - flink_data:/opt/flink/data
      - flink_checkpoints:/opt/flink/checkpoints
      - flink_savepoints:/opt/flink/savepoints
      - ./flink_jobs:/opt/flink/usrlib  # 挂载 Python 作业目录
    entrypoint: /bin/bash
    command:
      - -c
      - |
        # 创建自定义配置文件（在临时目录）
        cat > /tmp/flink-conf-custom.yaml <<'FLINKCONF'
        jobmanager.rpc.address: flink
        jobmanager.memory.process.size: 1600m
        taskmanager.memory.process.size: 1728m
        taskmanager.numberOfTaskSlots: 4
        parallelism.default: 2
        python.client.executable: python3
        python.executable: python3
        FLINKCONF
        
        # 合并原配置和自定义配置
        cat /opt/flink/conf/flink-conf.yaml /tmp/flink-conf-custom.yaml > /tmp/flink-conf-merged.yaml
        
        # 替换配置文件
        cp /tmp/flink-conf-merged.yaml /opt/flink/conf/flink-conf.yaml
        
        # 启动集群
        /opt/flink/bin/start-cluster.sh
        
        # 保持运行
        tail -f /opt/flink/log/*.log 2>/dev/null || sleep infinity
    networks:
      - lemo-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8081/overview || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  flink-sql-gateway:
    image: flink:1.19-scala_2.12-java11
    container_name: lemo-flink-sql-gateway
    user: root
    ports:
      - "8083:8083"  # SQL Gateway REST API
    environment:
      FLINK_PROPERTIES: |
        jobmanager.rpc.address: flink
        rest.address: flink
        rest.port: 8081
    command:
      - /bin/bash
      - -c
      - |
        cat > /opt/flink/conf/sql-gateway-defaults.yaml <<'EOFCONFIG'
        sql-gateway:
          endpoint:
            rest:
              address: 0.0.0.0
              port: 8083
          session:
            idle-timeout: 10min
            max-num: 100
        EOFCONFIG
        chmod 644 /opt/flink/conf/sql-gateway-defaults.yaml
        ./bin/sql-gateway.sh start-foreground \
          -Dsql-gateway.endpoint.rest.address=0.0.0.0 \
          -Dsql-gateway.endpoint.rest.port=8083 \
          -Djobmanager.rpc.address=flink \
          -Drest.address=flink \
          -Drest.port=8081
    networks:
      - lemo-network
    depends_on:
      - flink
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8083/v1/info || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

volumes:
  mongodb_data:
  redis_data:
  kafka_data:
  etcd_data:
  minio_data:
  milvus_data:
  prometheus_data:
  grafana_data:
  clickhouse_data:
  clickhouse_logs:
  flink_data:
  flink_checkpoints:
  flink_savepoints:

networks:
  lemo-network:
    driver: bridge

